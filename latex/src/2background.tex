\chapter{Notation and Terminology}\label{chap:notation}

\inlinetodo{This section has to be done}
Let \(A\) be an operator, then \(A^\ast\) is the adjoint operation. class of linear bounded
operators from two vector spaces.
Hilbert space, Real numbers, matrix, vector, approx linear bounded operators, transpose

\chapter{Imaging Modalities}\label{chap:imaging_modalities}

Numerous different fields boil down to a very similar problem statement. Based on a given
measurement, how can one retrieve the original measured object, assuming the measurement process is
known. This is also often referred to as reconstruction form projections~\cite{herman_basis_2015}.
This is precisely, the definition of reconstruction used throughout this thesis.

These fields include, but are not limited to, variation methods in imaging (e.g.\ image denoising,
inpainting, super resolution and more~\cite{scherzer_variational_2009}), X-ray attenuation CT,
differential phase-contrast CT, X-ray dark-field contrast CT, light-field tomography, seismic
imaging, nondestructive material testing~\cite{carpio_inverse_2008}. All of these problems are part
of the class of so-called \textit{inverse problems}.

A little detour to motivate the importance of inverse problems: The Hubble Space Telescope was
launched into space in 1990. However, it initially had an issue with the spherical aberration in
its optics. A hardware fix was deployed in 1993. But due to the cost of the operation in general,
the images of the telescope were still used and a lot of processing went into the images. A lot of
different techniques were used to recover as much information as possible. This includes techniques
involving the solution of inverse problem similar as discussed in this thesis. The details are out
of scope, but the interested reader can look into~\cite{white_restoration_1992,adorf_hubble_1995}.

\begin{definition}[Inverse Problem]\label{def:inverse_problem}
	Loosely speaking, the solution to inverse problems is the cause of an effect. Turning this
	into the mathematical setting, let \(H\) and \(K\) be Hilbert spaces (i.e.\ a vector space,
	which has a scalar product and is complete), then let \(m \in K\) the measurements and \(f
	\in H\) the original cause. The system which causes the effect can be modeled by a
	linear bounded operator \(A \in \mathscr{L}(H, K)\). Then the problem is formulated as
	\[ A f = m \]
	The inverse problem is to retrieve \(f\) (the cause) given \(m\) (the measurements) and \(A\)
	(the physical model).
\end{definition}

I want to point out a minor, but important detail. Different imaging modalities, which vary
drastically in scope of physical properties, can be mathematically reduces to a common concept. This
enables reasoning on common ground. Improvements in one field, can benefit other fields. Further, a
common language can be used. This, I personally find very much fascinating and is one of my
motivations to keep learning.

Back to the inverse problems. Broadly speaking, problems in math can be categorized in two
categories. Problems are either \textit{well-posed} or they are \textit{ill-posed}. Following the
definition of Hadamard~\cite{hadamard_sur_1902} a problem is well posed if all the following
properties are fulfilled:

\begin{itemize}
	\item \textbf{Existence}: The exists a solution.
	\item \textbf{Uniqueness}: It is the only solution.
	\item \textbf{Stability}: The solution depends continuously on the data.
\end{itemize}

If any of these conditions doesn't hold it is ill-posed. An example for well-posed problems is the
heat equation with specified initial conditions. Inverse problems are basically all
ill-posed~\cite{hansen_discrete_2010}, at least the ones considered in this thesis.

For an ill-posed inverse problem, either the inverse \(A^{-1}\) does not exist, the solution does
not lie in \(K\), or is not continuous (c.f.~\cite[Chapter~4]{natterer_mathematics_1986}). From a
practical standpoint the first two properties can be solved quite easily. If no solution exists, one
can substitute it by a different problem, e.g.\ the looking for the solution to the least squares
problem. If multiple or infinitely many solutions exists, one can choose the one with minimal norm.
However, if the third property is violated, the solutions to a system with two close measurements
\(g\) and \(g^\epsilon\) need not be close.

From a practical point this is quite important. Imagine two blurred images of the same scene, that
only differ slightly from one another. If the stability criterion is violated, the solution to the
inverse problem trying to deblur the images, need not be close to each other. Hence, proper care
needs to be taken in the development of algorithms, that search for solutions for the inverse
problem. See \citeauthor{hansen_discrete_2010}\cite{hansen_discrete_2010} for some nice illustrative
examples for each property.

In the specific field of tomographic reconstruction, the challenge is to reconstruction an image
from a finite set of projections. Specifically, most of the applications considered are projections
from X-ray sources. However, other imaging modalities such as light field microscopy exists.

An essential aspect of tomographic reconstruction is the so called \textit{forward model}. It is
the mathematical abstraction of the physical measuring process (\(A\) in
\autoref{def:inverse_problem}). Throughout this thesis, X-rays are treated as infinitely thin rays,
and therefore, mathematically a single X-ray going through the object can be model using a line.
Along its path through the object interacts with the matter and once it passed through it will hit
some kind of detector \todo{Add figure for idea of line integral}. This can either measure the
attenuation of the X-ray, the refraction or the scattering, but the mathematical abstraction is very
similar.

This idea was already studied by \citeauthor{radon_uber_1917}. Hence, the resulting transformation
modeling the projection of an object to its projection is often referred to as the \textit{Radon
	Transform}. For two-dimensional reconstructions this holds true, but for higher dimensions,
this is not necessarily true anymore. Other transformations, such as the \textit{X-ray
	Transform}~\cite{solmon_x-ray_1976}, have been presented. An overview of both the Radon
Transformation and the X-ray Transformation is given in \autoref{chap:radon_transform_and_related}.

Again, note how the mathematical description closes the gap between different concepts of
measuring X-ray attenuation, refraction and scattering.

The remainder of this chapter will mainly introduce X-ray attenuation CT. This mostly involves the
derivation of the forward model, but it also includes the basic physical aspect necessary to
understand the derivation. Further, differential X-ray phase-contrast CT is introduced and the
common aspects of the forward model both modalities share are highlighted. This should also help to
gain an (visual) intuition for the mathematical introduction and definitions in the following
chapters.

Out of scope are physical details. Rather, they will be striped down and simplified to what is
necessary and useful for the scope of this thesis and the concepts presented. However, as much as
possible, resources for the interested reader are cited in the corresponding sections.

\section{X-ray Attenuation CT}\label{sec:xray_attenuation_ct}

The discovery of X-rays by Wilhelm Conrad RÃ¶ntgen~\cite{rontgen_uber_1895} and its impact in medical
diagnostics have are tremendous. For the first time it was possible to 'look inside` an object
without opening it. As touched on in the introduction (\ref{chap:introduction}), this was used
to find and plan the removal of metal objects in bodies.

\citeauthor*{cormack_representation_1963}~\cite{cormack_representation_1963} laid the mathematical
foundations for X-ray attenuation CT. However, the breakthrough of X-ray attenuation CT scanners
only happened with the publication series of
\citeauthor{hounsfield_computerized_1973}\cite{hounsfield_computerized_1973},
\citeauthor{ambrose_computerized_1973}\cite{ambrose_computerized_1973} and
~\citeauthor{perry_computerized_1973}\cite{perry_computerized_1973}.

X-ray attenuation CT is an easy principle. The projections of the CT scanner are acquired using a
simple setup. The object one wants to scan is between the X-ray source and the detector. Without
going into details, X-ray sources for common CT scanners are vacuum tubes, which convert electrical
power to radiation. The detector consists of an array of pixels, which reacts sensitive to X-rays.
Then for each projection a `photo' is taken, the object is rotated in relation to the source and
detector, and then the next acquisitions is performed and so on. It is of no importance for the
reconstruction, if the object of interested is rotated or the source and detector are rotated. For a
detailed overview see \citeauthor{buzug_computed_2008}~\cite[Chapter~2]{buzug_computed_2008}.

The objectiv of tomographic reconstruction for X-ray attenuation, is the retrieval of the
attenuation coefficient for the complete object of interest. To achieve this, numouers projections
are necessary. Each projection is the X-ray shadow of the measured object.
\autoref{fig:sinogram_example_abdomen} shows three different projections for such an object. In this
specific case, the object of interest was rotated relative to the X-ray source and detector.
The graph on the right of each subimage, shows the measured projections values. The higher this
value is, the larger the attenuation (i.e.\ the darker the X-ray shadow) of the line hitting the
projection plane at this position.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_0.png}
				\label{fig:sinogram_example_0_degree}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_45.png}
				\label{fig:sinogram_example_45_degree}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_90.png}
				\label{fig:sinogram_example_90_degree}
			\end{subfigure}%
		}}%
	\caption{Three different projections of an object. In this case the X-ray source would be on
		the far left and generating parallel X-rays. From left to right: A projection from
		\(0^\circ\), \(45^\circ\) and \(90^\circ\). A single projection is the X-ray shadow
		of the desired object. It is also the sum of the attenuation coefficient of the
		integral along the infinite set of lines perpendicular to the projection plane (the
		line showing the attenuation values on the right)}\label{fig:sinogram_example_abdomen}
\end{figure}

For a simple study of the physical process in X-ray attenuation CT, one can start with the analysis
of a single X-ray going through an object with a homogeneous (i.e.\ single constant) attenuation
coefficient (see \autoref{fig:x-ray_homogeneous_attenuation}). The object one desires to
investigate, is between a X-ray source and a detector. The X-ray source generates X-rays with a
certain intensity \(I_0\). After the X-ray traverses the object, the detector measures a reduced
intensity denoted as \(I_1\). The connection between \(I_0\) and \(I_1\) is determined by the
attenuation coefficient \(\mu\) and the distance traveled through the matter \(s\). It is given by
\[ I_1 = I_0 e^{-\mu s} \]

\begin{figure}
	\centering
	\def\svgwidth{0.75\textwidth}
	\import{./figures/homogeneous_attenuation}{homogeneous_attenuation.pdf_tex}
	\caption{Simplified model of a single X-ray (red line) going through a material with
		homogeneous attenuation coefficient \(\mu\) (gray rectangle). \(I_0\) is the initial
		intensity of the X-ray, \(I_1\) is the measured intensity, given by attenuation
		coefficient \(\mu\) and the distance \(s\) the ray travels through the
		object.}\label{fig:x-ray_homogeneous_attenuation}
\end{figure}

Extending this model to accommodate changing or varying attenuation coefficients, one needs to
replace the constant coefficient \(\mu\), by a function \(\mu: \mathbb{R}^2 \mapsto \mathbb{R}\)
(for now, this is kept in the two-dimensional case). Then the measured intensity is given by the
integral along the line the ray travels along \(L\) of the function \(\mu\), see
\autoref{fig:x-ray_nonhomogeneous_attenuation} for an illustration.

\begin{figure}
	\centering
	\def\svgwidth{0.75\textwidth}
	\import{./figures/nonhomogeneous_attenuation}{nonhomogeneous_attenuation.pdf_tex}
	\caption{Model of a single X-ray (red line) going through a material with
		homogeneous attenuation coefficient \(\mu(x)\) (abdominal section). Again \(I_0\) is
		the initial intensity of the X-ray, \(I_1\) is the measured intensity, given
		by the integral along the line \(L\) (i.e.\ the ray given in red) of the
		attenuation coefficient function \(mu(x)\), where \(x\) is each point along the
		line \(L\).}\label{fig:x-ray_nonhomogeneous_attenuation}
\end{figure}

% Some help from https://www.fips.fi/slides/Bubba_SummerSchoolVFIP2019_1.pdf
Then the connection between the initial intensity, and measured intensity is connected by the
\textit{Beer-Lambert law}~\cite{buzug_computed_2008}:
\begin{equation}\label{eq:beer-Lambert-law}
	- \ln \frac{I}{I_0} = \int_L \mu (x) \, \mathrm{d}x
\end{equation}
The right-hand side of \autoref{eq:beer-Lambert-law} is the line integral of the attenuation
coefficient function \(\mu\) along the line \(L\). The line integrals for all lines which are
parallel to each other, are preceisly the above mentioned projections. This is what is examplenary
shown in \autoref{fig:sinogram_example_abdomen} for 3 different projection angles.

To successfully reconstruct an object from its projection one needs many projections from different
angles. The resulting measruments can be stacked together to an image. This is referred to as
\textit{sinogram}. The name originates from the sinoadial pattern a point draws in such an image,
see \autoref{fig:sinogram_simple_complete} for an example. There the sinogram for a single point in
the phantom is shown (together with the simple phantom) on the left. Further, the sinogram for the
abdomen used throughout this chapter can be seen in \autoref{fig:sinogram_complete}. The vertical
lines mark the projections taken in \autoref{fig:sinogram_example_abdomen}.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/simple_phatom.png}
				\caption{}\label{fig:sinogram_simple_phantom}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/simple_sinogram.png}
				\caption{}\label{fig:sinogram_simple_complete}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_512.png}
				\caption{}\label{fig:sinogram_abdomen_phantom}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram.png}
				\caption{}\label{fig:sinogram_abdomen_complete}
			\end{subfigure}
		}}
	\caption{Examples of sinograms. The name originates from the pattern a single points draw in
		the sinogram. This can be seen in
		\subref{fig:sinogram_simple_phantom}--\subref{fig:sinogram_simple_complete}. The
		sinogram for the abdomen data used throughout the chapter
		\subref{fig:sinogram_abdomen_phantom} can be in
		\subref{fig:sinogram_abdomen_complete}. The vertical lines mark the projections
		depicted in \autoref{fig:sinogram_example_abdomen}.
	}\label{fig:sinogram_complete}
\end{figure}

The first to proof that a function (in this case the \(\mu\)) can be described via its line
integral, was first shown by \textit{Radon Transform}~\cite{radon_uber_1917}
(see~\cite{radon_determination_1986} for the English translation). Further details on the Radon
Transform can be found in \autoref{chap:radon_transform_and_related}. However, for here it should be
noted, that the line integral of a function is the basis of many different imaging modalites.

Stepping back, to again a more practical approach. CT scanners evolves over time. Hence there do
exists many different, so-called, generations of CT scanners. The first, and mostly interesting ones
because a lot of the theory is build for those initially, are CT scanners, with a parallel beam
geometry (see \autoref{fig:parallel_beam_geometry}. There all rays are generated in parallel to each
other and hit the detector. This is achieved by having a X-ray source and the detector shift
perpendicular to the projection direction.

Another, common setting is the fan-bean geometry as shown in \autoref{fig:fan_beam_geometry}. It is
a two-dimensional setting, where the X-rays are emitted from a point-source and are not parallel to
each other, but rather (as the name suggest) have a fan like pattern. Further, the detector is often
curved. Other common geometry setups include inherently three-dimensional setup using a cone-line
beam shape and a two-dimensional detector. Newer CT scanners, also rely on multiple sources. A
detailed discussion is given in e.g.\ \cite{buzug_computed_2008}. Most of the geometric setups are
introduced to either reduce the acquisition time or increase the spatial resolution of the
reconstruction.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.6\textwidth}
				\incfigmaybe{./figures/parallel_beam_setup}
				\caption{Parallel Beam Setup}\label{fig:parallel_beam_geometry}
			\end{subfigure}%
			\begin{subfigure}{0.6\textwidth}
				\incfigmaybe{./figures/fan_beam_setup}
				\caption{Fan Beam Setup}\label{fig:fan_beam_geometry}
			\end{subfigure}%
		}}%
	\caption{Geometry setup of CT scanners}\label{fig:ct_geometry_setup}
\end{figure}

\section{Phase-Contrast CT}\label{sec:phasecontrast_ct}

In the X-ray attenuation CT setup, X-rays are only considered exhibiting attenuation. However, as
visible light, X-rays are also refracted and scattered. Methods based on refraction can measure the
phase-shift of the X-ray. These phase-contrast imaging modalities in general provide a general
advantage in soft-tissue contrast, as the difference in refraction index is higher for soft-tissues
than for the attenuation coefficient. This chapter aims to introduce basic concepts on the retrieval
of phase-contrast based imaging modules and derive the forward model used in such imaging
modalities. Specifically, emphasise is put on the similarities in the forward model regarding X-ray
attenuation CT\@.

\inlinetodo{Other methods to measure phase: Diffraction-Enhanved imaging, crystal-interferometer
	phase-contrast imaging, propagation-based phase-contrast imaging}

There are different ways to measure the refractions and thus the phase-contrast. A setup, which
gained a lot of trackion lately is the setup proposed by
~\cite{pfeiffer_phase_2006,pfeiffer_hard-x-ray_2008}. The setup is based on Talbot-Lau
interferometry. It allows both the retrieval of the X-ray refraction and scattering information
(which can be used for dark-field imaging). The setup consists as with conventional X-ray
attenuation imaging of the X-ray source and the detector. Additionally, 3 gratings are placed in the
setup: the \textit{source grating} G0, the \textit{phase-grating} G1 and the \textit{analyzer
	grating} G2. G1 is placed between the X-ray source and the object, the other two are placed between
the object and the detector. The source grating creates sufficiently high coherence, which allows
for a periodic interference behind the phase grating. Using the analyzer grating allows for
conventional X-ray detectors to be used. For a detailed discussion about the exact placement of the
gratings, see~\cite{donath_inverse_2009}.

A key advantage of this grating based setup is the usage of conventional X-ray sources. This makes
this setup suitable for (bio-) medical applications. Only recently this setup was incorporated in a
medical grate CT scanner~\cite{viermetz_dark-field_2022}.

The important observation in the grating-based setup, an object placed in the X-ray beam causes a
refraction of the beam by an angle \(\alpha\) (following~\cite{donath_inverse_2009}) in the
\(x\)-direction. The refraction angle is connected to the differential phase-shift \(\frac{\partial
	\Phi}{\partial x}\) by:
\[ \alpha = \frac{\lambda}{2 \pi} \frac{\partial \Phi}{\partial x} \]
\(\lambda\) is the X-ray wavelength, and the beam propagates along the \(z\)-axis.
Simplified, placing an object in the beam, causes a refraction, which results in a displacement of
the interference pattern created by the gratings. And by the above formula is connect to the
phase-shift introduced by the object. However, the interference patterns can not be spatially
resolved by the detector. However, performing multiple measurements with a later shifted analyzer
grating, creates a intensity modulation of the detector read-out. This is referred to as
\textit{phase stepping}. Apart from the additional stepping necessary, the process of acquiring
measurements is similar to the one in conventional X-ray attenuation CT\@. The different possible
values measured using phase-stepping are illustrated in \autoref{fig:grating_setup_what_happens}.
In this setup attenuation is reflected by drop of the average intensity. Compared to that,
phase-shifts, leads to a lateral displacement of the interferometer pattern, and scattering reduces
the amplitude of the oscillation.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_attenuation.png}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_phase.png}
			\end{subfigure}
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_scattered.png}
			\end{subfigure}
		}}
	\caption{Visualization of the measured intensity changing measured at the detector, when
		performing phase-stepping. Attenuation is measured by a drop of the average
		intensity value (left most plot). Phase-shift leads to a lateral shift of the
		intensity signal (center plot). And scattering drops in amplitude (left plot)}%
	\label{fig:grating_setup_what_happens}
\end{figure}


The intensity signal \(I(x, y)\) measured in each pixel \((x, y)\) oscillates as a function of the
stepping direction. The phases \(\varphi(x, y)\) of the intensity oscillations in each pixel are
connected to the refraction angle \(\alpha(x, y)\), the distance \(d\) between G1 and G2 and the
period \(p_2\) of the analyzer grating G2 by~\cite{weitkamp_x-ray_2005}
\[ \varphi = 2 \pi \alpha \frac{d}{p_2} = \frac{\lambda d}{p_2} \frac{\partial \Phi}{\partial x} \]

Using the phenomenological notion of a complex index of refraction, a combined description of
refraction and attenuation can be given. It is defined as
\[ n = 1 - \delta + i \beta\]
The real part describes scattering and refraction, and the imaginary part describes attenuation.
A wave propagating with a wave vector \(\mvec{k}\) thoruhg a medium with refractive index \(n\), can
be described as
\[ \Psi(\mvec{r}) = \Psi_0 \cdot e^{i n \mvec{k} \cdot \mvec{r}} = \Psi_0 \cdot
	e^{i(1-\delta)\mvec{k} \cdot \mvec{r}} \cdot e^{-\beta \mvec{k} \cdot \mvec{r}}\]
Here the first exponential on the right hand side represents a phase factor and the second an
attenuation of the wave's amplitute. This model can be used to derive the Beer-Lambert law as it was
shown in \autoref{eq:beer-Lambert-law} (compare~\cite[Chapter~2.1]{hahn_statistical_2014}). If one
looks only at the phase related term, it can be reformualted to
\[ \Psi_P(\mvec{r}) \coloneq \Psi_0 \cdot e^{i \mvec{k} \cdot \mvec{r}} \cdot e^{-i\delta \mvec{k}
			\cdot \mvec{r}} \]
Using the fact, that a wave propagating through vacuum is given by
\[ \Psi_v \coloneq \Psi_0 \cdot e^{i \mvec{k} \cdot \mvec{r}} \]
the phase-shift term simplifies to
\[ \Psi_P(\mvec{r}) = \Psi_v \cdot e^{-i\delta \mvec{k} \cdot \mvec{r}} \]
next similar transformations as with the X-ray attenuation based model can be done. And then the
phase-shift for a wave travelin through a homogeneous material with a single refraction index \(n\)
is given by
\[ \Phi = \delta \mvec{k} \cdot \mvec{r} \]
As with X-ray attenation, this can be extended to inhomogeneous media, by integrating the refractive
index decrement function \(\delta\)
\[ \Phi = \int \delta(x, y, z) k_y \mathrm{d}y \]
Then the refraction angle \(\alpha\) is given by
\[ \alpha(x,y) = \frac{\partial}{\partial x} \delta(x, y, z) \mathrm{d}y \]
This section is mostly based on the derivation given in~\cite{hahn_statistical_2014}.
It should be of note, that it is not possible to directly measure the phase-shift with current
detector technology, but it is sufficient to measure the refraction index. Albeit, it should be
notated, that the angles are very small.

\inlinetodo{Think about a figure showing the drop in average, shift and reduced amplitude, as in
	\cite{hahn_statistical_2014} Figure 2.3}

With that out of the way, we can see, that the forward model for differential phase-contrast is also
connected to the line integral. In this case the function integrated is not the attenuation
coefficient \(\mu\), but the refractive index decrement \(\delta\).

As a small excursion. As already eluded to a bit. The grating based setup can in addition to
attenuation and phase also measure scattering of the X-rays. Though, the scattering angles are
small, it is possible. Imaging modalities based on the scattering component are referred to as
\textit{dark-field}. The setup described above only measures scattering perpendicular to the
gratings. Hence, it is also possible to rotate the object around the central beam axis, i.e.\ in the
plane of the gratings. This opens the door for so call directional or \gls{AXDT}. The connection to
the previous modalities (apart from the similar setup), is also the connection of the line integral.
Thou more complicated, they still share this common aspect.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.60\textwidth}
				\includegraphics[width=\textwidth]{./figures/tooth/tooth_attenuation.png}
			\end{subfigure}%
			\begin{subfigure}{0.60\textwidth}
				\includegraphics[width=\textwidth]{./figures/tooth/tooth_phasecontrast.png}
			\end{subfigure}
		}}
	\caption{Example reconstruction of a medical tooth sample that was. On the left, the
		reconstruction of the attenuation part of the measured signal, on the right the
		reconstruction of the differential phase-contrast data. The absorption has been
		windowed to values in the range of \([0, 0.33]\), and for the phase-contrast image,
		an interval of \([-\frac{\pi}{8}, \frac{\pi}{8}]\) was used. Taken
		from~\cite{wieczorek_anisotropic_2017}. With permission from Tobias Lasser}
	\label{fig:medical_tooth_sample}
\end{figure}

As a final part of this chapter, \autoref{fig:medical_tooth_sample} presents the reconstruction of a
medical tooth sample, which was measured with a system as described above. The image of the left
shows the reconstruction of the attenuation based signal and on the right, the image based on the
differential phase-contrast is shown. This should mainly highlight, the difference in details gained
by the different methods.

\chapter{Radon Transform and its related transform}\label{chap:radon_transform_and_related}

In the previous chapter, the notion of the inverse problem was introduced. There, based on a given
measurement one tries to reconstruct the original quantity, based on a given model. This chapter is
mostly devoted to derive and analyze this model. Specifically, in the context of X-ray attenuation
CT, with a brief outlook into other areas needed for e.g.\ phase-contrast CT\@.

The physical model is the link between the unknown signal and it's measurements. Usually, the model
is referred to as forward model. Let us first state a couple of basic definitions, and then we will
look into the derivation of the forward model for X-ray attenuation CT\@.

\begin{definition}[Image]\label{def:image}
	Let \(f\colon \mathbb{R}^n \to \mathbb{R}\) be a \(n\)-dimensional continuous function,
	whose support is bounded. It is referred to it as a \(n\)-dimensional image. And often it will
	be referred to as image, without the special mention of \(n\)-dimensional.
\end{definition}

In the special case of \(n=2\), it is called an \textit{2-dimensional image} or just
\textit{2D image}. However, if from the context, the two-dimensional is obvious, it will still be
referred to as image. In case of \(n=3\), it is called a \textit{volume}.

\begin{definition}[Forward Model]\label{def:forward-model}
	To reconstruct an unknown image \(f\), a set of \(J\) scalar measurements is necessary.
	A single scalar valued measurement \(m_j\), with \(j \in \{1, \dots, J\}\) is defined in therms
	of the physical model:
	\[ m_j = \mathscr{M}_j(f)\]
	where
	\[ \mathscr{M}_j\colon (\Omega \to \mathbb{R}) \to \mathbb{R} \]
	and \(\Omega \subseteq \mathbb{R}^n\). The mapping is required to be linear, as this will play an
	important role later on.
\end{definition}

This is a very general definition. This is useful to mathematically model a wide variety of
different applications. In fact, all the applications in the previous chapter, can be modeled using
this general definition.

\section{Radon Transform}\label{sec:radon_transform}

Recall from \autoref{sec:xray_attenuation_ct}, the connection between the initial intensity and the
measured intensity was the line integral of the attenuation coefficients of the material. This
transformation of a function is known as the \textit{Radon Transform}, which is attributed to Johann
Radon and his work in \citeyear{radon_uber_1917}~\cite{radon_uber_1917,radon_determination_1986}. It
was later rediscovered by
\citeauthor{cormack_representation_1963}~\cite{cormack_representation_1963} in the context of the
invention of CT scanners.

Without any further ado, let us directly dive into the definition of the Radon Transform.

\begin{definition}[Radon Transform]
	Let \(\Omega \subset \mathbb{R}^n\) and \(f\colon \Omega \to \mathbb{R}\), which is assumed
	to sufficiently nice. Then the mapping \(\radon{R}f\colon (\mathbb{R}^n \to \mathbb{R})
	\to (\mathbb{R} \times \mathscr{S}^{n-1} \to \mathbb{R})\) of \(f\), which maps \(f\) into
	the set of its integrals over the affine hyperplanes of \(\mathbb{R}^{n-1}\), is called the
	\textit{Radon Transform} (c.f.~\cite{natterer_mathematics_1986,buzug_computed_2008}).

\end{definition}
Specifically, given the unit direction \(\theta \in \mathcal{S}^{n-1}\), one can define the
hyperplane \(\mathcal{H}^{n-1}(\theta)\) through the origin and perpendicular to \(\theta\).
The Radon Transform \(\radon\) of \(f\) is defined by the line integral over the
hyperplane perpendicular to the direction \(\theta\) with signed distance \(s \in
\mathbb{R}\) to the origin
\[ \radon f(\theta, s) = \int_{\mathcal{H}^{n-1}(\theta)} f(x + s\theta) \, \, \mathrm{d}x \]

Note that for \(n=2\) the hyperplanes are lines, and hence match the forward model for X-ray
imaging. For the 3-dimensional case, this does not fit anymore. For this case, the so called X-ray
Transform \(\xray\) was developed~\cite{solmon_x-ray_1976}, which is very similar to the Radon
Transform, but integrates over lines for all dimensions, instead of hyperplanes.

In the two-dimensional case, \(\theta\) is often described by its polar angles \(\phi\) and an
orthogonal vector \(\theta^\perp\) such that
\( \theta = (\cos \phi, \sin \phi)\) and \(\theta^\perp = (-\sin\phi, \cos\phi)\)
then the Radon Transform is described as \( \radon f(\phi, s) = \radon_\phi f(s) = \radon f(\theta^\perp, s)\).
\todo{is this really important, extract important part out of it}

As already noted in \autoref{sec:xray_attenuation_ct}, the projections of X-ray attenuation CT, can
be seen as the shadow of the measured object.
\inlinetodo{Add figure with object and it's projection}

However, in the setting of tomographic reconstruction, one wishes to reconstruct the original image
\(f\) from a set of measurements \(g\). Already, \citeauthor*{radon_uber_1917} showed a theoretical
way of the adjoint operations of the Radon Transform. However, these results are very theoretical.

\begin{definition}[Fourier Slice Theorem]\label{def:fourier_slice_theorem}
	Let \(f\colon \mathbb{R}^2 \to \mathbb{R}\) be sufficiently nice and \(\mathscr{F}_n\) the
	\(n\)-dimensional Fourier transform. Then
	\[ (\mathscr{F}_2f)(s) = (\mathscr{F}_1(\radon f(\cdot, \phi)))(s) \]
	It is also often referred to as \textit{projection-slice theorem} or \textit{central slice theorem}
\end{definition}

This is a very powerful theorem. In a more natural language, the \(1\)-dimensional Fourier Transform
of the projected data measured at the angle \(\phi\), yields a line in the two-dimensional
representation of the image \(f\). Even more, the line is the line going through the origin with a
rotation angle \(theta\). Hence, with enough projections, the \(f\) can be described fully in the
Fourier domain and reconstructed using the inverse \(2\)d Fourier Transform.

\inlinetodo{Add figure for projection line in cartesion space and the same line in fourier space}

However, this method has a couple of drawback. \textit{Enough} projections is quite a vague
statement and a strong limitation. Especially considering the trend to reduce X-ray dosage and hence
reducing the number of projections acquired. Further, problems arise as the Fourier domain is
typically sampled in polar coordinates, but for this representation, we'd like to access them using
Cartesian. This requires some for of interpolation. See the dissertation of
\citeauthor{vogel_tomographic_2015}\cite[Chapter~4.1.2]{vogel_tomographic_2015} for a little more
detailed discussions and very nice illustrative figures. More means to compute the adjoint and
reconstruction \(f\) are presented in \autoref{chap:tomographic_reconstruction}.

Of further interest to us is the first derivative of the Radon transform. As a variety of image
methods build on top of the derivative.

\begin{definition}[Derivative of the Radon Transform]
	The \(n\)th derivative of the Radon Transform is denoted by (compare
	e.g.\ \cite{nilchian_differential_2012,nilchian_fast_2013})
	\[ \radon^{(n)} = \frac{\partial^n}{\partial s^n} \radon f(\theta, s)\]
\end{definition}

The derivatives are linear operators, which are scale invariant, pseudo-distributive with respect to
convolution and projected translational invariant. The adjoint of the first derivative of the Radon
Transform is shown in~\cite{nilchian_differential_2012}, and for the \(n\)th derivative
see~\cite{nilchian_fast_2013}.

\section{X-ray Transform}\label{sec:xray_transform}

The \(n\)-dimensional Radon Transform computed the integral over \(n-1\)-dimensional hyperplanes.
However, for the setting of attenuation X-ray CT, one is interested in the line integration over
lines in \(n\)-dimensional spaces.

\begin{definition}[X-ray Transform]
	Given \(\theta \in \mathscr{S}^{n-1}\) and \(x \in \mathbb{R}^n\), then
	\[ \xray f(\theta, x) = \int_{-\infty}^{+\infty} f(x + t \theta) \, \mathrm{d}t\]
	is the X-ray Transform. It is the integral over the straight line through \(x\) with
	direction \(\theta\) (c.f.~\cite{natterer_mathematics_1986,solmon_x-ray_1976}).
\end{definition}

In the two-dimensional case, the Radon Transform and X-ray Transform are equivalent.
Then, the relation between the Radon Transform and the X-ray Transform is
\[\xray f(\theta, s\theta^\perp) = \radon f(\theta^\perp, s)\]
For the case of attenuation X-ray CT, the X-ray Transform is the physical forward model used.

\inlinetodo{Maybe find the derivative operation as well}

Other important transformations, which are not considered in this thesis are the Cone-Beam Transform
(c.f.~\cite[Chapter~2]{carpio_inverse_2008}), or Abel transform~\cite[Chapter~4.16]{buzug_computed_2008}.

\chapter{Image Representation}\label{chap:image_representation}

Images as defined in \autoref{def:image}, are continuous functions. However, if one wishes to use
computers to solve the reconstruction tasks, there exists a need for discretization, as computers
are inherently discrete. Hence, one wishes to represent an image in a discrete fashion.

\begin{definition}[Permissible representation]
	\label{def:permissible_representation}
	Let \(f\colon \mathbb{R}^n \to \mathbb{R}\) be a \(n\)-dimensional continuous function,
	\(N \in \mathbb{N}\) be a positive integer and \(\varphi_n\) a set basis function for
	\(1 \leq n \leq N\). Then the signal \(f\) can be approximated as a linear combinations
	of these basis functions and the coefficients \(c_n\):
	\[ f \approx \near{f}(\mvec{x}) = \sum_{k=1}^{N} c_k \varphi_k(\mvec{x}) \]
\end{definition}

\inlinetodo{Have figure of grid above image to represent the discretization}

For our purposes, we assume the function lies on a regular spaced discrete grid. Then, let
\(\varphi\) be a zero centered symmetrical basis function, \(\mvec{k} \in \mathbb{Z}^n\) be the
\(n\)-dimensional index of a grid cell, and \(\vec{x}_{\mvec{k}} \in \mathbb{R}^n\) the center
coordinate of the \(\mvec{k}\)-th grid cell. Then, the previous equation can be reformulated:
\[ \near{f}(\mvec{x}) = \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}} \varphi(x - x_{\mvec{k}}) \]
This definition follows the notation given in~\cite{momey_new_2011}. This method to discretize an
image is called \textit{series expansion} and is described in detail in
e.g.\ \cite{herman_basis_2015}.

Now, if one applies the Radon transformation to the discretized image: \todo{generalize to all linear physical models}
\[ \radon\near{f}(\mvec{x}) = \radon\left( \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}} \varphi(\mvec{x} - \mvec{x}_{\mvec{k}}) \right) \]
Due to the linearity of the Radon Transform this is equivalent to
\[ \radon\hat{f}(x) = \sum_{\symbfit{k} \in \mathbb{Z}^n} c_{\symbfit{k}}\radon\left( \varphi(x - x_{\symbfit{k}}) \right) \]
i.e.\ the Radon transformation of the image, only act upon the basis function. Hence, it is
sufficient to study, how the Radon transformation acts upon the individual basis function.

Note that this holds for any linear physical model. Notably, this holds for the X-ray transform and
the first derivative of the Radon transform. But it is also true for the physical models behind the
applications discussed in the previous chapter.
\[ \mathscr{M}_j\near{f}(x) = \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}}\mathscr{M}_j\left( \varphi(\mvec{x} - \mvec{x}_{\mvec{k}}) \right) \]

The key takeaway, is that the forward models related to the imaging modalities discussed in
\autoref{chap:imaging_modalities} only act on the basis function. Hence, one needs to only study how
the basis function behave under the given transform.

\section{Voxel Basis}\label{sec:voxel_basis}

The most likely most well known basis function in imaging is the pixel or voxel basis functions. The
voxel basis function is a piecewise linear function. The voxel basis function is most likely the
most widely used basis function. Most literature assumes the voxel basis function implicitly.

The centered voxel basis function of step width \(h\), is given by:
\begin{equation}\label{eq:voxel_basis_fn}
	\varphi^{\text{pixel}}(\mvec{x}) =
	\begin{cases}
		1, \abs{\mvec{x}} < \frac{h}{2} \\
		0, \text{otherwise}
	\end{cases}
\end{equation}
Here, the absolute value is coefficient wise, as soon as the absolute value of any coefficient of
the vector \(\mvec{x} \in \mathbb{R}^n\) is larger half the step size, the function will return
\(0\).

\inlinetodo{Add figure showing the centered basis function, show how a continuous function can
	approximated by pixels}

An image approximated by the voxel basis function, in the series expansion method is equivalent to
the nearest neighbourhood interpolation.

As pointed out by \citeauthor*{lewitt_multidimensional_1990}
in~\cite{lewitt_multidimensional_1990,lewitt_alternatives_1992} the voxel-basis function isn't
necessarily a good choice for biomedical images. Further, it is discontinuous at the boundaries.

The analytical formulation of the Radon transform of the pixel basis function
(compare~\cite{toft_radon_1996}) is given by:
\begin{equation}\label{eq:radon_voxel_basis}
	\radon\varphi^{\text{pixel}}(\rho, \theta) =
	\begin{cases}
		0                                                  & x_1 > 0                         \\
		\sqrt{4 + (x_1 - x_{-1})^2} = \frac{2}{\cos\theta} & x_1 < 1\;\text{and}\;x_{-1} < 1 \\
		\sqrt{(1 - x_1)^2 + (1 - x_{-1})^2}                & x_1 < 1\;\text{and}\;x_{-1} > 1
	\end{cases}
\end{equation}

As the voxel basis function is discontinuous at the boundaries, there does not exist a way to
compute the derivative of the radon transform relying on the basis function. Steps such as numerical
derivation must be used.

\todo{understand this properly and explain this properly}

\section{Blob Basis}\label{sec:blob_basis}

First introduced by Lewitt in~\cite{lewitt_multidimensional_1990}, spherically symmetric volume
elements (often referred to as blobs) are an alternative to the pixel basis.
~\cite{lewitt_alternatives_1992} describes how blobs can be used in iterative reconstruction
algorithms as a basis instead of pixels.

Blob basis functions have been adopted in multiple different fields. Among others electron
microscopy~\cite{marabini_3d_1998, garduno_optimization_2001}, positron emission tomography
(PET)~\cite{jacobs_comparative_1999, chlewicki_noise_2004}, single-photon emission tomography
(SPECT)~\cite{wang_3d_2004, yendiki_comparison_2004}, attenuation X-ray
CT~\cite{jacobs_iterative_1999, carvalho_helical_2003, isola_motion-compensated_2008},
phase-contrast CT~\cite{kohler_iterative_2011, xu_investigation_2012}, reconstruction of coronary
trees~\cite{zhou_blob-based_2008}, breast tomosynthesis~\cite{wu_breast_2010}, reduction of metal
artifacts~\cite{levakhina_two-step_2010} or computed laminography~\cite{trampert_spherically_2017}.

\inlinetodo{Read papers and assert what blobs brings to the table}

Generally, many fields report increased accuracy with a comparable performance. In other fields,
such as phase-contrast CT, blobs enable the usage of iterative reconstructions without an extra step
of numerical differentiation.

The generalized Kaiser-Bessel basis function as proposed by Lewitt, is defined as:
\begin{equation}\label{eq:blob_basis_fn}
	\varphi^{\text{blob}}_{m, \alpha, a}(r) =
	\begin{cases}
		\frac{I_m\left( \alpha \sqrt{1 - \left(\frac{r}{a}\right)^2} \right)} {I_m\left( \alpha \right)} \left( \sqrt{1 - \left(\frac{r}{a}\right)^2}\right)^m & 0 \le r \le a      \\
		0                                                                                                                                                      & \textit{otherwise}
	\end{cases}
\end{equation}
where \(I_m\) is the modified Kaiser-Bessel function of the first kind of order \(m\), \(r\) the
distance to the blob center, \(a\) the blob radius given in units of the grid, and \(\alpha\)
controlling the shape of the blob. \(m\) controls the continuity of the blob function.
\inlinetodo{Figures showing 2d blob and different parameters of blob}

The Radon Transform \todo{Or the X-ray transform?} of the blob basis function simplifies to the Abel
Transform~\cite{buzug_computed_2008}. This is possible as the blob basis function is rotationally
symmetric. Therefore, the Radon Transform of a blob basis function is by
(c.f.~\cite{lewitt_multidimensional_1990,lewitt_alternatives_1992})
\begin{align}\label{eq:radon_blob_basis}
	p(s) & = \int_{-\infty}^{+\infty} \varphi^{\text{blob}}_{m, \alpha, a}\left(t\right) \, \mathrm{d} t                                                                                                       \\
	     & = 2 \int_0^{\sqrt{(a^2-s^2)}} \varphi^{\text{blob}}_{m, \alpha, a}\left(\sqrt{s^2 - r^2}\right) \, \mathrm{d} r                                                                                     \\
	     & = \frac{a}{I_m(\alpha)} \left( \frac{2\pi}{\alpha}\right)^{1/2} \left( \sqrt{1 - \left(\frac{s}{a}\right)^2} \right)^{m + 1/2} I_{m+1/2}\left( \alpha \sqrt{1 - \left(\frac{s}{a}\right)^2} \right)
\end{align}
\(s\) is the distance from the X-ray to the blob center, and \(\sqrt{a^2 - s^2}\) is one half of the
intersection length between the blob and the ray. The projected value only depends on the distance
from the X-ray to the blob center. This is a very nice property. This makes implementations quite
efficient.

\inlinetodo{figure for parameters for projected basis, figure for parameters for basis,
	\cite{benkarroum_blob_2015}}
\inlinetodo{Derivative of Blob basis function}

From an implementation standpoint, the half integer order of the modified Kaiser-Bessel function
of the first kind, can be quite nasty. Implementations do exist as it can be seen
in~\cite{temme_numerical_1975}. However, the floating point implementations are non-trivial. Plus,
for the case of C++, since C++17 the standard library provides mathematical special functions
~\cite{noauthor_c_nodate, noauthor_stdcyl_bessel_i_nodate}. But sadly, it is not yet entirely
cross-platform, as it is only supported by libstdc++~\cite{noauthor_libstdc_nodate-1}, and not
libc++. However, for our cases it is sufficient to assume \(m \in \mathbb{N}\). Then the above
equation can be further simplified.

The recurrence formulation for the modified Kaiser-Bessel function of the first kind is
(c.f.~\cite[Chapter~9]{abramowitz_handbook_1972}):
\begin{equation}\label{eq:kaiser_bessel_recurrence}
	I_{m+1}(x) = I_{m-1}(x) - \frac{2 m}{x}I_m(x)
\end{equation}
Further, the Kaiser-Bessel functions have representations with elementary functions. For the
modified Kaiser-Bessel function of the first kind, there are defined as (c.f.~\cite[Chapter~10]{abramowitz_handbook_1972}):
\begin{align}\label{eq:kaiser_bessel_half_integer}
	I_{0.5}(x) & = \sqrt{\frac{2}{\pi x}} \sinh(x)                                                                               \\
	I_{1.5}(x) & = \sqrt{\frac{2}{\pi x}} \left( \cosh(x) \frac{\sinh(x)}{x} \right)                                             \\
	I_{2.5}(x) & = \sqrt{\frac{2}{\pi x}} \left(\left(\frac{3}{x^2} + \frac{1}{x}\right)\sinh(x) - \frac{3}{x^2} \cosh(x)\right)
\end{align}
Then \autoref{eq:radon_blob_basis} can be simplified to not include any non-integer evaluations of
the modified Kaiser-Bessel function of the first kind. For example assuming, \(m = 0\), and to keep
everything a little more concise, let \(w = \sqrt{1 - \left(\frac{r}{a}\right)^2}\):
\begin{align}\label{eq:radon_blob_basis_order_0_simplified}
	p(s) & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi}{\alpha}\right)^{1/2} \left( w \right)^{1/2} I_{1/2}\left( \alpha w \right)                     \\
	     & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi w}{\alpha}\right)^{1/2} I_{1/2}\left( \alpha w \right)                                          \\
	     & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi w}{\alpha}\right)^{1/2} \left( \frac{2}{\pi \alpha w}\right)^{1/2} \sinh \left(\alpha w \right) \\
	     & = \frac{2 a}{\alpha I_0(\alpha)} \sinh \left(\alpha w \right)
\end{align}
In the last step, \(\pi\) and \(w\) cancel out, and both the \(2^2\) and \(\alpha^2\) are moved out
of the square root, leaving it empty. Similar operations can be done for \(m = 1\) and \(m = 2\).

\section{B-Spline Basis}\label{sec:bspline_basis}

Splines are common in image and signal processing~\cite{unser_splines_1999}. Applications include
image interpolation, image transformations, image compressions or the calculation of the first and
second derivative. A common approach is the approximation of the function or image using Splines and
then working efficiently on the continuous representation of the splines. For B-Splines
specifically,~\citeauthor{unser_fast_1991}~\cite{unser_fast_1991} show the continuous image
representation using B-Splines.

This approach was adopted to tomographic reconstruction.~\cite{la_riviere_spline-based_1998}
proposed the calculation of the inverse 2D and 3D Radon transform based on B-Spline.
Similarly,~\cite{horbelt_discretization_2002} develops a B-Spline based filtered back projection.
Apart from attenuation CT, other medical applications of B-Splines include electron
tomography~\cite{tran_robust_2013, tran_inverse_2014}, positron emission tomography
(PET)~\cite{nichols_spatiotemporal_2002, li_fast_2007, verhaeghe_investigation_2007} and
single-photon emission tomography (SPECT)~\cite{guedon_b-spline_1991, reutter_fully_2007}.

Using B-Splines as a basis function was first presented by~\cite{momey_new_2011,
	momey_b-spline_2012, momey_spline_2015}. And a similar image representation was adapted for
phase-contrast CT in~\cite{nilchian_fast_2013, nilchian_differential_2012, nilchian_spline_2015}.
They differ in the approximation of the evaluation of the X-ray transform. The former use a
footprint of the B-Splines, where the later rely on the first derivative of the B-Spline basis
function.

\begin{definition}[B-Spline]
	The most basic definition of a B-Spline of degree \(0\) and unit width is the step function:
	\begin{equation}
		\beta^0(x) = \mu(x) =
		\begin{cases}
			1, & \text{if } x \in \mathopen[\minus \frac{1}{2}, \frac{1}{2}\mathclose] \\
			0, & \text{otherwise}
		\end{cases}
	\end{equation}
	Then the univariate B-Spline of degree \(d\) can be constructed by \(d + 1\) convolution of \(\beta^0\)
	(compare~\cite{momey_new_2011}):
	\begin{equation}
		\beta^d(x) = \beta^0 * \beta^{d-1}(x) =
		\underbrace{\beta^0 * \dots * \beta^0(x)}_{d+1 \text{convolution terms}}
	\end{equation}
\end{definition}
\inlinetodo{Add figure for B-Splines of different degree, add function approximation}
Note that B-Splines of degree \(0\) is just the voxel-basis function.

Another way to compute the B-Spline basis of order \(d\) is given in~\cite{unser_fast_1991}:
\begin{equation}
	\beta^d(x) = \sum_{i=0}^{d+1} \frac{(-1)^i}{n!} \binom{d+1}{i}(x - i)^d\mu(x - i)
\end{equation}
where \(\binom{d+1}{i}\) is the binomial coefficient.

The derivatives are again B-Spline of degree \(d-1\) (compare~\cite{unser_splines_1999}):
\begin{equation}
	\frac{\partial \beta^d(x)}{\partial x} = \beta^{d-1}\left(x + \frac{1}{2}\right) -
	\beta^{d-1}\left(x - \frac{1}{2}\right)
\end{equation}
B-Splines are continuously differentiable up to order \(d-1\).

B-Splines are separable. Hence, \(n\)-dimensional B-Splines, often referred to as tensor product
B-Splines, can be constructed the following way:
\begin{equation}
	\beta^d(x) = \prod^n_{i=1} \beta^d(x_i)
\end{equation}
where \(x \in \mathbb{R}^n\)

B-Splines have a couple of really attractive properties. B-Splines are the shortest and smoothest
scaling functions for a given order of approximation~\cite{momey_b-spline_2012}. They are close to a
Gaussian function, with a sufficiently large $d$~\cite{momey_b-spline_2012}, all while preserving
compactness. Hence, they tend to spherically symmetric functions, while preserving local support.
Due to these properties, \citeauthor*{momey_new_2011}\cite{momey_new_2011} argue for B-Splines over
blobs. Further, they note the need to tune the parameters for of blobs for optimal results, which
adds complexity.

Importantly, blobs fail to satisfy the partition of unity~\cite{nilchian_fast_2013}. A basis
functions that satisfies the partition of unity, can approximate any input function arbitrarily
close.~\cite{nilchian_fast_2013} show the importance of the property for tomographic reconstruction.

In~\cite{horbelt_discretization_2002}, it was shown that the Radon transform of B-Splines are spline
bikernel. \citeauthor*{entezari_box_2012} show in~\cite{entezari_box_2012} explicitly how (tensor
product) B-Splines act under the X-ray and Radon transform.~\cite{nilchian_differential_2012} shows
how B-Splines act under the first derivative of the Radon transform.

The Radon Transform of a two-dimensional B-Spline was shown by
\citeauthor*{horbelt_discretization_2002}\cite{horbelt_discretization_2002}. Given the projection
angle \(\theta\), then it is:
\begin{equation}
	\radon\beta^d(s) = \beta^d_{\sin\theta} * \beta^d_{\cos\theta}(d)
\end{equation}
Hence it is the convolution of two splines of different width (denoted by the subscript). These are
referred to as spline bikernels. \citeauthor*{horbelt_discretization_2002} presents an explicit
formulation to compute it.

To extend this to the \(3\)-dimensional setting, one can look into \textit{box splines}. Box splines
can be seen as a generalization of B-Splines.

\begin{definition}[Box Spline]
	Box splines are the shadow of a hypercube in \(\mathbb{R}^n\), when projected down to a
	lower dimension \(\mathbb{R}^d\). Similarly to B-Splines, box splines can be defined via
	convolution:
	\begin{equation}
		M_\Xi(x) = M_{\xi_1} * \dots * M_{\xi_n}(x)
	\end{equation}
	where \(\Xi \coloneq \mathopen[ \xi_1 \xi_2 \dots \xi_n \mathclose] \in \mathbb{R}^{s \times n}\)
	is the matrix of directions. Each \(\xi\) defines a direction of the hypercube.
	\(\Xi\) completely defines the box spline (compare~\cite{de_boor_box_1993})
\end{definition}

\citeauthor{entezari_box_2012}~\cite{entezari_box_2012} proof that the X-ray transform of a
\(d\)-variate box spline is a \(d - 1\) variate box spline. Further, it is the box spline defined
the by projection of the direction matrix \(\Xi\). This means, going back to B-Splines, that for any
dimension, the X-ray transform of B-Splines are again B-Splines of lower dimension.

\chapter{Tomographic Reconstruction}\label{chap:tomographic_reconstruction}

Till this point, the physical models involved in tomographic reconstruction have been presented and
discretization has been discussed. The last missing piece is the solution to the inverse problem.
As tomographic reconstruction problems are inverse problems, many methods depend on common solutions
to this space.

Generally, one needs to find solution to the system \(A(f) = m\). There \(A\) is the forward model,
\(f\) is the \(n\)-dimensional image one seeks to reconstruct, and \(m\) is the measured data, i.e.\
the projected data. In the specific case of X-ray attenuation CT, the forward model \(A\) is the
Radon Transform \(\radon\) or the X-ray Transform \(\xray\), the image \(f\) is the function of
attenuation coefficients of the scanned object \(\mu\), and \(m\) is the data measured at the
detector (including noise).

\section{Analytical Reconstruction}\label{sec:analytical_reconstruction}

As already alluded to in the section about the Radon Transform \ref{sec:radon_transform}. There do
exist closed form analytical inversion methods for the Radon Transform. In the aforementioned
section, the Fourier Slice Theorem was introduced. Methods exist that use this approach as a means
to reconstruct the desired image. However, they are not often used in practice in tomographic
reconstruction.

\begin{definition}[Back-Projection]\label{def:back_projection}
	Let \(f\colon \Omega \to \mathbb{R}\), where \(\Omega \in \mathbb{R}^2\) sufficiently nice.
	Further, let \(g_\phi \coloneq \radon f\) be the Radon Transform of \(f\) with the
	projection angle \(\phi\). Then
	\[ (R^\ast g)(x, y) \coloneq \int_0^\pi g_\phi(x\cos \phi + y \sin\phi) \mathrm{d}\phi \]
	is the unfiltered back-projection of \(g\) (c.f.~\cite{buzug_computed_2008}).
	\(\radon^\ast\) denotes the adjoint of Radon Transform.
\end{definition}

\inlinetodo{Add example images for 1, 2, 4, and so on projection angles}

The result of back-projecting the measured projections is a blurry version of the original function.
\citeauthor{buzug_computed_2008} describes post-processing as a possible solution. However, there
exists another option. If the projections are filtered in the Fourier domain and then the filtered
values are back-projected just as before, a sharper image can be obtained. This is referred to as
the filtered back-projection (FBP)~\cite{ramachandran_three-dimensional_1971}.

\begin{definition}[Filtered Back-Projection]\label{def:filtered_back_projection}
	Still, let \(f\colon \Omega \to \mathbb{R}\), where \(\Omega \in \mathbb{R}^2\) sufficiently
	nice, and \(g \coloneq \radon f\) be the Radon Transform of \(f\). Then
	\[ g^\delta(t, \phi) \coloneq (f \ast g(\cdot, \phi))(t) \]
	is the filtered projection. \(\delta(x) \approx \abs{x}\) is a filter, which is convoled
	with the projection data. Using \(\radon^\ast\) is the adjoint of the Radon Transform
	as in \autoref{def:back_projection}, then \(\radon^\ast g^\delta\) is the
	\textit{filtered back-projection}.
\end{definition}

The quality of the reconstruction depends on the filter and data acquisition. Further the FBP as
presented here, is limited to parallel beam geometry setups. There do exist other methods for fan
beam settings that require rebinning (i.e.\ sorting the projections, such that all rays are
parallel). However, overall the FBP leads to sharp images and it is widely used in medical CT
scanners~\cite{pan_why_2009}.

\inlinetodo{Use something like to show packprojection and filtered back projection
	\href{https://scikit-image.org/docs/dev/auto_examples/transform/plot_radon_transform.html} to create
	some nice graps and include code to reproduce results. Show how FBP fails}

\section{Towards the Matrix form}\label{sec:matrix_formulation}

The goal of this section is a short run through the steps that are necessary to go from the
continuous definition of the inverse problem as given in \autoref{def:inverse_problem} to a discrete
version, with which we can work on computers. In the previous section, the FBP still assumes a
continuous function to work with, which can create problems during reconstruction. For this reason,
it is desirable to find a suitable discretization and work with different algorithms.

In \autoref{def:forward-model}, the definition of forward model is given. This forward model
takes the place of the bounded linear operator \(A\) from \autoref{def:inverse_problem}. However,
this is all still in the continuous space. Using \autoref{def:permissible_representation}, \(f\) can
decompose into the sum of coefficients and basis functions:
\[ f \approx \near{f}(x) = \sum_{k=1}^{N} c_k \varphi_k(\mvec{x}) \]
as shown for the Radon Transform, the forward model can be applied and rearranging a little using
the linearity of the operator:
\[ m_j \approx \mathscr{M}_j(\hat{f}) = \sum_{k=1}^{N} c_k \mathscr{M}_j(\varphi_k) \]
\(a_{ji} \coloneq \mathscr{M}_j(\varphi_k)\) is the contribution of a single \(k\)th basis function
to the \(j\)th measurement.

\inlinetodo{Have an image like Vogel Beyond tomographic Figure 4.7}

Now, the measurements can be stacked to a vector \(m = (m_j) \in \mathbb{R}^J\), the same for
the coefficients \(c = (c_i) \in \mathbb{R}^I\), and the contributions \(a_{j} = (a_{ji}) \in
\mathbb{R}^I\). Then a single measurement can be written as a scalar product of the coefficient
vector and the contribution vector. But also importantly, the linear system can be defined:
\begin{equation}\label{eq:system_lin_equation}
	m \approx
	\begin{bmatrix}
		\rule[.5ex]{2em}{0.4pt} & a_1^T & \rule[.5ex]{2em}{0.4pt} \\
		\rule[.5ex]{2em}{0.4pt} & a_2^T & \rule[.5ex]{2em}{0.4pt} \\
		\vdots                                                    \\
		\rule[.5ex]{2em}{0.4pt} & a_J^T & \rule[.5ex]{2em}{0.4pt}
	\end{bmatrix} c \eqcolon A c
\end{equation}

This is a regular system of linear equation, it partitions the problem in the measurements, the
\textit{system matrix} \(A \in \mathbb{R}^{J \times I}\) and the coefficient vector \(c\). Also
note, that the choice of basis function is integrated into the system matrix. In
\autoref{fig:matrix_row}, the intuition for the system matrix is illustrated. There, for a single
measurement \(m_1\), the matrix row \(a_{1} = \begin{bmatrix}a_{1, 1}, a_{1, 2} \cdots
	a_{1,36}\end{bmatrix}\) is visualized. Each element of the row corresponds to an element of the
coefficient vector \(\mvec{c}\). One can also guess from this visualization the sparsity of the
rows, as already in this simple illustration, roughly half the entries of the row are \(0\).

\begin{figure}
	\centering
	\input{figures/matrix_row/matrix_row.pgf}
	\caption{Visualization of weights of a single row of the system matrix. \inlinetodo{Find
			better explanation, this should be standalone}}\label{fig:matrix_row}
\end{figure}

\section{Iterative Reconstruction}\label{sec:iterative_reconstruction}

As explained in \autoref{chap:image_representation}, the problems considered in this thesis are
ill-posed. Hence, care has to be taken when solving the linear system of equations in
\autoref{eq:system_lin_equation}. A common approach is to considered least squares problem instead.

\begin{definition}[Least Squared Problem]\label{def:least_squares_problem}
	The least squares problem is defined as
	\[ \argmin_c \frac{1}{2} \norm{Ac - m}^2_2 \]
	The solution to the least squares problem is given by the normal equation
	\[ A^T A c = A^T m \]
\end{definition}

Note here, that \(Ac\) is considered the forward projection and \(A^T m\) is the backward
projection.

However, the system matrix is usually too large to store in system memory. Therefore, algorithms are
necessary, which do not require the knowledge of the complete system matrix. The software computing
the system matrix on the fly, is often referred to as projectors. A deep dive into the
implementation will be conduced in \autoref{chap:projector}.

\subsection{Landweber Iteration}\label{subsec:landweber_iteration}

A well studied class of iterative algorithms is the \textit{landweber
	iteration}~\cite{landweber_iteration_1951}. It has been discovered in many different ways in
the past. The algorithm was introduced in the tomographic space by
\citeauthor{gilbert_iterative_1972}~\cite{gilbert_iterative_1972} under the name of
\gls{SIRT}.

\begin{definition}[Landweber Iteration]\label{def:landweber_iteration}
	Given a linear system of equations as defined in \autoref{def:inverse_problem}, the
	\textit{Landweber iteration} finds a solution to the corresponding least squares problem. The update
	step for \(k = 0, 1, \dots\) is given by
	\[
		c^{(k+1)} = c^{(k)} + \lambda^{(k)} A^T(m - Ac^{(k)})
	\]
	\(\lambda^{(k)} \in \mathbb{R}\) is a sequence of relaxation parameter that must satisfy
	\(0 < \lambda^{(k)} < 2 \norm{A^T A}_2^{-1}\quad \forall k \in \mathbb{N}\).
\end{definition}

Generally, Landweber iterations (in the basic case) only rely on the forward \(Ac^{(k)}\) and backward
\(A^T m\) projections. The innermost part of the update function, is a forward projection of the
current guess. Next, the residual to the measurement is taken and finally the error is back
projected and used as an update to the current guess.

The basic Landweber iteration is a special case of gradient descent. If \(f(c) = \frac{1}{2}
\norm{Ac - m}_2^2\), the update can be written in terms of the gradient
\[
	c^{(k+1)} = c^{(k)} - \lambda^{(k)} \nabla f(c^{(k)})
\]
A generalisation of the Landweber iteration can be given by
\[
	c^{(k+1)} = c^{(k)} + \lambda^{(k)} DA^TM(m - Ac^{(k)})
\]
The expat algorithm and it's convergence behavior, depend on the exact choice of the matrices \(D\)
and \(M\). The basic Landweber iteration as presented above has \(D = M = I\). If \(D = \frac{1}{J}
\text{diag}(\norm{a_j}^2_2)^{-1}\), with \(\norm{a_j}^2_2\) being the squared \(L_2\) norm of the
\(j\)th row of the system matrix~\cite[Chapter~6.2]{hansen_discrete_2010}.

\subsection{Algebraic Reconstruction Technique}\label{subsec:algebraic_reconstruction_technique}

The \gls{ART} was proposed by \citeauthor{gordon_algebraic_1970}\cite{gordon_algebraic_1970}.
However, outside of tomography the method is often knows as Kaczmarz
method~\cite{kaczmarz_approximate_1993}. Though, \gls{ART} is a slight modification of the original
Kaczmarz method.

The basic idea of the algorithm, is to view each row of the system matrix as a hyperplane and update
the solution by iteratively project it onto the hyperplane. If the system matrix is square \(I = J\)
and of full rank, all hyperplanes intersect at one point and \gls{ART} will converge to it. However, if
the system is overdetermined (\(J > I\)) and noisy, which it usually is, the hyperplanes will not
intersect at a single point, but rather at in close proximity to each other.

\begin{definition}[Algebraic Reconstruction Technique]\label{def:art}
	Given the system of linear equations \(Ac = m\), and an initial solution guess \(c^{(0)} \in
	\mathbb{R}^I\) (often the zero vector). Then the solution can be iteratively updated for
	\(k = 0, 1, \dots\)
	\[
		c^{(k+1)} = c^{(k)} + \lambda^{j(k)} \frac{m_{j(k)} - \langle a_{j(k)}, c^{j(k)} \rangle}{\norm{a_{j(k)}}}a_{j(k)}
	\]
	where \(\lambda^{(k)} \in \left(0, 1\right]\) is a sequence of relaxation parameters, and
	\(j(k)\) is a mapping to select an appropriate row for each iteration. In the simple case
	\(j(k) = (k \mod J) + 1\), but it can also be randomized~\cite{strohmer_randomized_2007}.
\end{definition}

The original Kaczmarz method had \(\lambda(k) = 1\, \forall k \in \mathbb{N}\), lowering the
relaxation parameter can improve the reconstruction in noisy settings. Further, the method can be
written as a Landweber-type method~\cite{hansen_discrete_2010}, but it's rather uncommon.

Compared to the Landweber iterations given in the previous section, the Kaczmarz methods accesses
the rows of the system matrix \(A\) sequentially (but maybe not in ascending order). On the other
hand Landweber type methods access all rows of the system matrix simultaneously. Hence, the
`simultaneous' as part of \gls{SIRT}\@.

\inlinetodo{add figure for this}

% \subsection{CG}\label{subsec:conjuage_gradient}
%
% CG and such
%
% \subsection{First-order methods}\label{subsec:first_order_methods}
%
% First other methods such as Gradient Descent and it's derivatives

\section{Regularization}\label{sec:regularization}

So far all solvers presented here have only looked at the least squares problem. I.e.\ they only
concern themselves with the forward model and do not incorporate any further constrains. However,
usually we have some information about the images we wish to reconstruct. For example, one would
expect them to be smooth. One hopes that regularization stabilizes the solution. In the sense that
small perturbations by noise in the measurements, still yields solutions close to the exact
solutions.

\begin{definition}[Regularized Problem]\label{def:regularized_problem}
	Let \(R(c)\) be a \textit{penalty function} or \textit{regularizer}, then the least square
	problem can be expanded to
	\[
		\argmin_c \frac{1}{2} \norm{A c - m}_2^2 + \lambda R(c)
	\]
	this is referred to as \textit{regularized problem}. \(lambda\) is a regularization
	parameter. It denotes the weight of the penalty term.
\end{definition}

This can also be generalized to other problems. Let \(T(c)\) be a data fidelity term (e.g.\
the least squares one, or the negative log-likelihood). Then the regularized problem can be
described as
\[ \argmin_c T(c) + \lambda R(c) \]
Usually, \(R\) is chosen to be non-linear and often is expected to be continuously differentiable.
This equation has three parts. The first \(T(c)\) is the data term. It measures how well a
prediction models the noisy data. However, we do not want to fit the noise in the data. This is the
second, the regularization term. \(\lambda\) controls the importance or the balance of each the
previous terms.

\subsection{Tikhonov Regularization}\label{subsec:tikhonov_regularization}

A well studied and often used regularization is named after Andrey Nikolayevich
Tikhonov~\cite{tihonov_solution_1963}. The penalty restricts the solution based on the Euclidean
norm.

\begin{definition}[Tikhonov Regularization]\label{def:tikhonov_regularization}
	The penalty term for Tikhonov regularization is given by
	\[
		R(c)_{\text{Tikhonov}} = \norm{\Gamma c}_2^2
	\]
\end{definition}
A common case is a simple scaling function i.e.\ \(\Gamma = \alpha I\), thus the Tikhonov
regularizer penalizes \(c\) with large \(L_2\) norm. Therefore, it is also referred to as
\(L_2\)-regularization. But also the first and second derivative operator is commonly
used~\cite{golub_tikhonov_1999} The hope is, that Tikhonov regularization suppresses high-frequency
noise.

On a further note, the Tikhonov regularization can be reformulated to a least squares problem again
\[
	\argmin_c \frac{1}{2}
	\left\lVert
	\begin{pmatrix}
		A \\
		\lambda \Gamma
	\end{pmatrix}
	c -
	\begin{pmatrix}
		m \\
		0
	\end{pmatrix}
	\right\rVert_2^2
\]
Here \(\begin{pmatrix}
	A \\
	\lambda \Gamma
\end{pmatrix}\) is a stacked matrix, with the system matrix on top, and the Tikhonov matrix in the
bottom. A different commonly used notation is
\[
	(A^T A + \lambda \Gamma^T \Gamma)x = A^T m
\]
The problem remains linear and thus can be solved using the previously discussed iterative
reconstruction algorithms. However, in general, for non Tikhonov regularization this does not hold
true. Thus, the problem is rendered non-linear and different optimization techniques have to be
used.

\subsection{\(L_1\)-Regularization}\label{subsec:l1_regularization}

Another common regularization method is based on the \(L_1\) norm, i.e.\ the sum of absolute
values.
\begin{definition}[\(L_1\)-Regularization]\label{def:l1_regularization}
	The penalty term for Tikhonov regularization is given by
	\[
		R(c)_{L_1} = \norm{c}_1
	\]
	See~\cite{tibshirani_regression_1996,tibshirani_lasso_2013,beck_fast_2009}
\end{definition}
Compared to the \(L_2\) regularization, the \(L_1\) regularization enforces sparsity. I.e.\ the
assumption is that the representation is in some way sparse, and should be enforced. Also, it is
more robust to outliers~\cite{beck_fast_2009}. For information on how these problems can be solved
see \citeauthor{beck_fast_2009}~\cite{beck_fast_2009}. As it will be used in the experimental
sections, specifically \gls{ISTA} and  \gls{FISTA}.

\begin{definition}[ISTA]\label{def:ista}
	The update step for \gls{ISTA} is given by
	\[
		c^{(k+1)} = \mathscr{T_\alpha} (c^{(k)} - 2 \lambda A^T (A c^{(k)} - m))
	\]
	where \(t\) is an appropriate step size and \(\mathscr{T_\alpha}\) is the shrinkage operator
	defined by
	\[
		\mathscr{T_\alpha}(c)_j = \max(\abs{c_i} - \alpha, 0) \sign(c_j)
	\]
\end{definition}
Similar to Landweber like methods, the residual of the forward projection current prediction and the
measurement vector is back projected. Next, the projected error is subtracted from the current
estimate and then the shrinkage operator is applied.

However, the convergence of \gls{ISTA} is rather slow (compare~\cite{beck_fast_2009} and its
references). \gls{FISTA} improves on the convergence of \gls{ISTA}, but it is out of scope for this
thesis. Please refer to \citeauthor{beck_fast_2009}~\cite{beck_fast_2009} for further reading.

% \subsection{TV Regularization}\label{subsec:tv_regularization}
%
% \begin{listing}
% 	\begin{minted}{cpp}
% int main() {
%     fmt::print("hello, world\n");
%     return 0;
% }
%     \end{minted}
% 	\caption{"Some sampe C code"}
% \end{listing}
% \begin{listing}
% 	\begin{minted}{python}
% import numpy as np
%
% np.linspace(0, 1)
%     \end{minted}
% 	\caption{"Some sampe python code"}
% \end{listing}
