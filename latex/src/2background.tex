\chapter{Notation and Terminology}\label{chap:notation}

This chapter shortly introduces most of the common notation used throughout this thesis. It can be
freely skipped and jumped back to when in doubt about a specific notation. However, I hope that the
notation is self-explanatory or clear from the context given at all places.

Generally, standard notation regarding symbols such as the natural numbers \(\mathbb{N}\), integers
\(\mathbb{Z}\), \(\mathbb{R}\) are used. Scalar values of these spaces are denoted by lowercase
non-bold letters, such as \(n \in \mathbb{N}\) or \(x \in \mathbb{R}\). A special notation is
introduced for scalar measurements. They have a integer subscript \(m_j\), but are not necessarily
connected to a vector. Vectors are always assumed to be column vectors and are denoted with bold
characters such as \(\mvec{x} \in \mathbb{R}^n\). Elements of \(n\)-dimensional vectors are
subscribed \(\mvec{x}_j\). Row vectors are specifically denoted with brackets such as \([\mvec{x}_1,
		\mvec{x}_2, \mvec{x}_3, \dots ]\).

Given \(\mvec{x} \in \mathbb{R}\) and \(\mvec{y} \in \mathbb{R}\), then \(\abs{\mvec{x}}\) is the
componentwise absolute value, \(\norm{\mvec{x}}\) is a no further specified norm,
\(\norm{\mvec{x}}_2\) the \(l_2\) or Euclidean norm, \(\norm{\mvec{x}}^2_2\) the squared \(l_2\)
norm, and \(\langle \mvec{x}, \mvec{y} \rangle\) the scalar product. \(\mathscr{S}^n\) is the unit
\(n\)-sphere defined as \(\mathscr{S}^n = \{\mvec{x} \in \mathbb{R}^n \colon \norm{\mvec{x}} = 1 \}\).
\(\mvec{x}^\perp\) denotes a vector perpendicular to \(\mvec{x}\). Though at one place, the scalar
product is also denoted by \(\mvec{x} \cdot \mvec{y}\). \(\mvec{x}^{(k)}\) is the \(k\)th vector of
a sequence of vectors. Given the matrix \(A \in \mathbb{R}^{n \times m}\). Then \(A^T\) is the
transpose and \(A^{-1}\) the inverse of the matrix.

\(\mathcal{H}\) and \(\mathcal{K}\) denote Hilbert spaces, and \(\mathscr{L}(\mathcal{H},
\mathcal{K})\) the set of linear bounded operators from \(\mathcal{H}\) to \(\mathcal{K}\). Let \(A
\in \mathscr{L}(\mathcal{H}, \mathcal{K})\) be linear bounded operator, then \(A^\ast\) denotes the
adjoint of the operator.

Other important symbols include \(\mu\), the attenuation coefficient, \(\Phi\), the phase-shift of a
wave front, \(\delta\) the refractive index decrement. Important transformation used throughout
the thesis are the Radon Transform \(\radon\), the X-ray Transform \(\xray\), and the Fourier
Transformation \(\mathscr{F}\). Specifically, in the notation of the Fourier Transform, a subscript
denotes the dimensionality of the transform, i.e.\ \(\mathscr{F}_1\) is the one-dimensional Fourier
Transform, and \(\mathscr{F}_2\) the two-dimensional one and so on. For the Radon and X-ray
Transform the angle of projection is often denoted by a subscript, e.g.\ \(\radon_\theta\).
\(\mathscr{M}_j\) denotes the physical model that is used to acquire \(m_j\).

Throughout the thesis, the function \(f\) is the function that one seeks to reconstruction, and
\(g \coloneq \radon f\) is the Radon Transform of \(f\). Given two functions \(g\) and \(h\),
\(g \ast h\) is the convolution of the two functions. \(\nabla f\) is the gradient of the
function \(f\).

\chapter{Imaging Modalities}\label{chap:imaging_modalities}

Numerous fields boil down to a very similar problem statement: based on a given measurement, how can
one retrieve the original measured object, assuming the measurement process is known. This is also
often referred to as reconstruction form projections~\cite{herman_basis_2015}. This is precisely,
the definition of reconstruction used throughout this thesis.

These fields include, but are not limited to, variational methods in imaging (e.g.\ image denoising,
inpainting, super resolution and more~\cite{scherzer_variational_2009}), X-ray attenuation CT,
differential phase-contrast CT, X-ray dark-field contrast CT, light-field tomography, seismic
imaging and nondestructive material testing~\cite{carpio_inverse_2008}. All of these problems are
part of the class of so-called \textit{inverse problems}.

A little detour to emphasize, how ubiquitously inverse problems are: the Hubble Space Telescope was
launched into space in 1990. However, it initially had an issue with the spherical aberration in its
optics. A hardware fix was deployed in 1993. But due to the cost of the operation in general, the
images of the telescope were still used and lots of processing went into the images. Numerous
different techniques were used to recover as much information as possible. This includes techniques
involving the solution of inverse problem similar as discussed in this thesis. The details are out
of scope, but the interested reader can look into~\cite{white_restoration_1992,adorf_hubble_1995}.

\begin{definition}[Inverse Problem]\label{def:inverse_problem}
	Loosely speaking, the solution to inverse problems is the cause of an effect. Turning this
	into the mathematical setting, let \(\mathcal{H}\) and \(\mathcal{K}\) be Hilbert spaces
	(i.e.\ a vector space, which has a scalar product and is complete), then let \(m \in
	\mathcal{K}\) the measurements and \(f \in \mathcal{H}\) the original cause. The system
	which causes the effect can be modeled by a linear bounded operator \(A \in \mathscr{L}(H,
	K)\). Then the problem is formulated as
	\[ A f = m \]
	The inverse problem is to retrieve \(f\) (the cause) given \(m\) (the measurements) and \(A\)
	(the physical model).
\end{definition}

Hilbert spaces are complete vector spaces, where a scalar product \(\langle\cdot,\cdot\rangle\) is
defined. Hence, they make sufficiently nice spaces to work in. For the purposes of this thesis,
usually one can assume \(\mathcal{H}\) and \(\mathcal{K}\) to be subspaces of \(\mathbb{R}^n\), so
no further studies on Hilber Spaces is conducted at this point.

I want to point out a minor, but important detail. Different imaging modalities, which vary
drastically in scope of physical properties, can be mathematically reduces to a common concept. This
enables reasoning on common ground. Improvements in one field, can benefit other fields. Further, a
common language can be used. This, I personally find very much fascinating and is one of my
motivations to keep learning.

Back to the inverse problems. Broadly speaking, problems in math can be categorized in two
categories. Problems are either \textit{well-posed} or they are \textit{ill-posed}. Following the
definition of Hadamard~\cite{hadamard_sur_1902} a problem is well posed if all the following
properties are fulfilled:

\begin{itemize}
	\item \textbf{Existence}: There exists a solution.
	\item \textbf{Uniqueness}: It is the only solution.
	\item \textbf{Stability}: The solution depends continuously on the data.
\end{itemize}

If any of these conditions do not hold, it is ill-posed. An example for well-posed problems is the
heat equation with specified initial conditions. Inverse problems are basically all
ill-posed~\cite{hansen_discrete_2010}, at least the ones considered in this thesis.

For an ill-posed inverse problem, either the inverse \(A^{-1}\) does not exist, the solution does
not lie in \(K\), or is not continuous (c.f.~\cite[Chapter~4]{natterer_mathematics_1986}). From a
practical standpoint the first two properties can be solved quite easily. If no solution exists, one
can substitute it by a different problem, e.g.\ the looking for the solution to the least squares
problem. If multiple or infinitely many solutions exists, one can choose the one with minimal norm.
However, if the third property is violated, the solutions to a system with two close measurements
\(g\) and \(g^\epsilon\) need not be close.

From a practical point this is quite important. Imagine two blurred images of the same scene, that
only differ slightly from one another. If the stability criterion is violated, the solution to the
inverse problem trying to deblur the images, need not be close to each other. Hence, proper care
needs to be taken in the development of algorithms, that search for solutions for the inverse
problem. See \citeauthor{hansen_discrete_2010}~\cite{hansen_discrete_2010} for some nice
illustrative examples for each property.

In the specific field of tomographic reconstruction, the challenge is to reconstruction an image
from a finite set of projections. Specifically, the applications considered here are projections
from X-ray sources. However, other imaging modalities such as light field microscopy exist.

An essential aspect of tomographic reconstruction is the so-called \textit{forward model}. It is the
mathematical abstraction of the physical measuring process (\(A\) in \autoref{def:inverse_problem}).
Throughout this thesis, X-rays are treated as infinitely thin rays, and therefore, mathematically a
single X-ray going through the object can be model using a line. Along its path through the object
interacts with the matter and once it passed through it will hit some kind of detector. This can
either measure the attenuation of the X-ray, the refraction or the scattering, but the mathematical
abstraction is very similar.

This idea was already studied by \citeauthor{radon_uber_1917} in \citeyear{radon_uber_1917}. Hence,
the resulting transformation modeling the projection of an object to its projection is often
referred to as the \textit{Radon Transform}. For two-dimensional reconstructions this holds true,
but for higher dimensions, this is not necessarily true anymore. Other transformations, such as the
\textit{X-ray Transform}~\cite{solmon_x-ray_1976}, have been presented. An overview of both the
Radon Transformation and the X-ray Transformation and generally a more mathematically focused
discussion is given in \autoref{chap:radon_transform_and_related}.

Again, note how the mathematical description closes the gap between different concepts of
measuring X-ray attenuation, refraction and scattering.

The remainder of this chapter will mainly introduce X-ray attenuation CT\@. This mostly involves the
derivation of the forward model, but it also includes the basic physical aspect necessary to
understand the derivation. Further, differential X-ray phase-contrast CT is introduced and the
common aspects of the forward model both modalities share are highlighted. This should also help to
gain a visual intuition for the mathematical introduction and definitions in the following chapters.

Out of scope are physical details. Rather, they will be striped down and simplified to what is
necessary and useful for the scope of this thesis and the concepts presented. However, as much as
possible, resources for the interested reader are given in the corresponding sections.

\section{X-ray Attenuation CT}\label{sec:xray_attenuation_ct}

The discovery of X-rays by Wilhelm Conrad RÃ¶ntgen~\cite{rontgen_uber_1895} and its impact in medical
diagnostics have been tremendous. For the first time it was possible to `look inside' an object
without opening it. As touched on in the introduction of \autoref{chap:introduction}, this was used,
among others, to find and plan the removal of metal objects in bodies.

\citeauthor*{cormack_representation_1963}~\cite{cormack_representation_1963} laid the mathematical
foundations for X-ray attenuation CT\@. Thereby, reinventing what \citeauthor*{radon_uber_1917}
already discovered. However, X-ray attenuation CT did not take off till the publication series of
\citeauthor*{hounsfield_computerized_1973}~\cite{hounsfield_computerized_1973},
\citeauthor*{ambrose_computerized_1973}~\cite{ambrose_computerized_1973} and
\citeauthor*{perry_computerized_1973}~\cite{perry_computerized_1973} and their corresponding
prototypes of CT scanners.

X-ray attenuation CT is an easy principle. The projections of the CT scanner are acquired using a
simple setup. The object one wants to scan is between the X-ray source and the detector. Then for
each projection a `photo' is taken, the object is rotated in relation to the source and detector,
and then the next acquisitions is performed and so on. It is common to described a projection with
an angle in two dimensions and two angles in three dimensions. This fully qualifies a single
projection pose. A a further notice, it is of no importance for the reconstruction, if the object of
interested is rotated or the source and detector are rotated. X-ray sources for common CT scanners
are vacuum tubes, which convert electrical power to radiation. The detector consists of an array of
pixels, which reacts sensitive to X-rays. For a detailed overview see
\citeauthor{buzug_computed_2008}~\cite[Chapter~2]{buzug_computed_2008}.

The objective of tomographic reconstruction for X-ray attenuation CT, is the retrieval of the
attenuation coefficient for the complete object of interest. To achieve this, numerous projections
are necessary. Each projection is the X-ray shadow of the measured object.
\autoref{fig:sinogram_example_abdomen} shows three different projections for such an object. In this
specific case, the object of interest was rotated relative to the X-ray source and detector. The
graph on the right of each sub-image, shows the measured projections values. The higher this value
is, the larger the attenuation (i.e.\ the darker the X-ray shadow) of the line hitting the
projection plane at this position.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_0.png}
				\label{fig:sinogram_example_0_degree}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_45.png}
				\label{fig:sinogram_example_45_degree}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram_90.png}
				\label{fig:sinogram_example_90_degree}
			\end{subfigure}%
		}}%
	\caption{Three different projections of an object. In this case the X-ray source would be on
		the far left and generating parallel X-rays. From left to right: A projection from
		\(0^\circ\), \(45^\circ\) and \(90^\circ\). A single projection is the X-ray shadow
		of the desired object. It is also the sum of the attenuation coefficient of the
		integral along the infinite set of lines perpendicular to the projection plane (the
		line showing the attenuation values on the right)}\label{fig:sinogram_example_abdomen}
\end{figure}

For a simple study of the physical process in X-ray attenuation CT, one can start with the analysis
of a single X-ray going through an object with a homogeneous (i.e.\ constant) attenuation
coefficient (see \autoref{fig:x-ray_homogeneous_attenuation}). The object one desires to
investigate, is between an X-ray source and a detector. The X-ray source generates X-rays with a
certain intensity \(I_0\). After the X-ray traverses the object, the detector measures a reduced
intensity denoted as \(I_1\). The connection between \(I_0\) and \(I_1\) is determined by the
attenuation coefficient \(\mu\) and the distance traveled through the matter \(s\). It is given by
\[ I_1 = I_0 e^{-\mu s} \]

\begin{figure}
	\centering
	\def\svgwidth{0.75\textwidth}
	\import{./figures/homogeneous_attenuation}{homogeneous_attenuation.pdf_tex}
	\caption{Simplified model of a single X-ray (red line) going through a material with
		homogeneous attenuation coefficient \(\mu\) (gray rectangle). \(I_0\) is the initial
		intensity of the X-ray, \(I_1\) is the measured intensity, given by attenuation
		coefficient \(\mu\) and the distance \(s\) the ray travels through the
		object.}\label{fig:x-ray_homogeneous_attenuation}
\end{figure}

Extending this model to accommodate changing or varying attenuation coefficients, one needs to
replace the constant coefficient \(\mu\), by a function \(\mu: \mathbb{R}^2 \mapsto \mathbb{R}\)
(for now, this is kept in the two-dimensios). Then the measured intensity is given by the
integral along the line the ray travels along \(L\) of the function \(\mu\), see
\autoref{fig:x-ray_nonhomogeneous_attenuation} for an illustration.

\begin{figure}
	\centering
	\def\svgwidth{0.75\textwidth}
	\import{./figures/nonhomogeneous_attenuation}{nonhomogeneous_attenuation.pdf_tex}
	\caption{Model of a single X-ray (red line) going through a material with
		homogeneous attenuation coefficient \(\mu(x)\) (abdominal section). Again \(I_0\) is
		the initial intensity of the X-ray, \(I_1\) is the measured intensity, given by the
		integral along the line \(L\) (i.e.\ the ray given in red) of the attenuation
		coefficient function \(\mu(\mvec{x})\), where \(\mvec{x}\) is each point along the
		line \(L\).}\label{fig:x-ray_nonhomogeneous_attenuation}
\end{figure}

% Some help from https://www.fips.fi/slides/Bubba_SummerSchoolVFIP2019_1.pdf
Then the connection between the initial intensity, and measured intensity is connected by the
\textit{Beer-Lambert law}~\cite{buzug_computed_2008}:
\begin{equation}\label{eq:beer-Lambert-law}
	- \ln \frac{I}{I_0} = \int_L \mu (\mvec{x}) \, \mathrm{d}\mvec{x}
\end{equation}
The right-hand side of \autoref{eq:beer-Lambert-law} is the line integral of the attenuation
coefficient function \(\mu\) along the line \(L\), \(\mvec{x} in \mathbb{R}\) are the points that
lie on \(L\). The line integrals for all lines which are parallel to each other, are precisely the
above mentioned projections for a given projection angle \(\theta\). This is what is exemplarily
shown in \autoref{fig:sinogram_example_abdomen} for 3 different projection angles \(0^\circ\),
\(45^\circ\) and \(90^\circ\).

To successfully reconstruct an object from its projection, one needs many projections from different
angles. The resulting measurements can be stacked together to an image. This is referred to as
\textit{sinogram}. The name originates from the sinusoidal pattern a point draws in such an image,
see \autoref{fig:sinogram_simple_complete} for an example. There the sinogram for a single point in
the phantom is shown (together with the simple phantom) on the left. Further, the sinogram for the
abdomen used throughout this chapter can be seen in \autoref{fig:sinogram_abdomen_complete}. The
vertical lines mark the projections taken in \autoref{fig:sinogram_example_abdomen}.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/simple_phatom.png}
				\caption{}\label{fig:sinogram_simple_phantom}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/simple_sinogram.png}
				\caption{}\label{fig:sinogram_simple_complete}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_512.png}
				\caption{}\label{fig:sinogram_abdomen_phantom}
			\end{subfigure}
			\begin{subfigure}{0.325\textwidth}
				\includegraphics[width=\textwidth]{./figures/sinogram_example/abdomen_sinogram.png}
				\caption{}\label{fig:sinogram_abdomen_complete}
			\end{subfigure}
		}}
	\caption{Examples of sinograms. The name originates from the pattern a single points draw in
		the sinogram. This can be seen in
		\subref{fig:sinogram_simple_phantom}--\subref{fig:sinogram_simple_complete}. The
		sinogram for the abdomen \subref{fig:sinogram_abdomen_phantom} used throughout the
		chapter can be seen in \subref{fig:sinogram_abdomen_complete}. The vertical lines
		mark the projections depicted in \autoref{fig:sinogram_example_abdomen}.
	}\label{fig:sinogram_complete}
\end{figure}

The first to proof that a function (in this case the \(\mu\)) can be described fully via its line
integral, was first shown by \textit{Radon Transform}~\cite{radon_uber_1917}
(see~\cite{radon_determination_1986} for the English translation). Further details on the Radon
Transform can be found in \autoref{chap:radon_transform_and_related}. Here it should just be
highlighted, that the line integral of a function is the basis of many imaging modalities.

Stepping back, to again a more practical approach. CT scanners evolved over time. Hence, there do
exists many so-called \textit{generations} of CT scanners. The first generation of CT scanners, have
a paralllel beam geometry (see \autoref{fig:parallel_beam_geometry}). Today they are mostly
interesting because much of the theory is build around their principles. There all rays are
generated in parallel to each other and hit the detector. This is achieved by having an X-ray source
and the detector shift perpendicular to the projection direction.

Another, common setting is the fan-bean geometry as shown in \autoref{fig:fan_beam_geometry}. It is
a two-dimensional setting, where the X-rays are emitted from a point-source and are not parallel to
each other, but rather (as the name suggest) have a fan like pattern. Further, the detector is often
curved. Other common geometry setups include inherently three-dimensional setup using a cone-like
beam shape and a two-dimensional detector. Newer CT scanners, also rely on multiple sources. A
detailed discussion is given in e.g.\ \cite{buzug_computed_2008}. Most of the geometric setups are
introduced to either reduce the acquisition time or increase the spatial resolution of the
reconstruction.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.6\textwidth}
				\incfigmaybe{./figures/parallel_beam_setup}
				\caption{Parallel Beam Setup}\label{fig:parallel_beam_geometry}
			\end{subfigure}%
			\begin{subfigure}{0.6\textwidth}
				\incfigmaybe{./figures/fan_beam_setup}
				\caption{Fan Beam Setup}\label{fig:fan_beam_geometry}
			\end{subfigure}%
		}}%
	\caption{Examples of geometric setups of CT scanners. \subref{fig:parallel_beam_geometry}
		show a simplified version of the geometry of first generation of CT scanner, in
		which the X-rays travel parallel to each other. \subref{fig:fan_beam_geometry} shows
		a fan beam setup. In which the X-rays emit from a points source through the object
		and hit a (in this case) curved detector.}\label{fig:ct_geometry_setup}
\end{figure}

\section{Phase-Contrast CT}\label{sec:phasecontrast_ct}

In the X-ray attenuation CT setup, X-rays are only considered exhibiting attenuation. However, as
visible light, X-rays are also refracted and scattered. Methods based on refraction can measure the
phase-shift of the X-ray. These phase-contrast imaging modalities in general provide an advantage in
soft-tissue contrast, as the difference in refraction index is higher for soft-tissues than for the
attenuation coefficient. This chapter aims to introduce basic concepts on the retrieval of
phase-contrast based imaging modules and derive the forward model used in such imaging modalities.
Specifically, emphasize is put on the similarities in the forward model regarding X-ray attenuation
CT\@.

There are different ways to measure the refraction and thus the phase-contrast. A setup, which
gained a lot of traction lately is the setup proposed by \citeauthor*{pfeiffer_phase_2006} in
~\cite{pfeiffer_phase_2006,pfeiffer_hard-x-ray_2008}. The setup is based on Talbot-Lau
interferometry. It allows both the retrieval of the X-ray refraction and scattering information
(which can be used for dark-field imaging). The setup described in~\cite{pfeiffer_hard-x-ray_2008}
enables the usage of conventional X-ray sources, which was previously not possible. Hence, the basic
setup is similar to the one conventional X-ray attenuation CT, i.e.\ a X-ray source and detector and
the object, one wishes to scan in between. Additionally, 3 gratings are placed in the setup: the
\textit{source grating} G0, the \textit{phase-grating} G1 and the \textit{analyzer grating} G2. G0
is placed between the X-ray source and the object, the other two are placed between the object and
the detector. The source grating creates sufficiently high coherence, which allows for a periodic
interference behind the phase grating. Using the analyzer grating allows for conventional X-ray
detectors to be used. For a detailed discussion about the exact placement of the gratings,
see~\cite{donath_inverse_2009}.

A key advantage of this grating-based setup over other approaches for phase-contrast, is the
possibility of using conventional X-ray sources. This makes this setup suitable for (bio-) medical
applications. Hence, it was possible to incorporated in a medical grate CT
scanner~\cite{viermetz_dark-field_2022}.

The important observation in the grating-based setup is, that an object placed in the X-ray beam
causes a refraction of the beam by an angle \(\alpha\) (following~\cite{donath_inverse_2009}) in the
\(x\)-direction. The refraction angle is connected to the differential phase-shift \(\frac{\partial
	\Phi}{\partial x}\) by:
\begin{equation}
	\alpha = \frac{\lambda}{2 \pi} \frac{\partial \Phi}{\partial x}
\end{equation}
\(\lambda\) is the X-ray wavelength, and the beam propagates along the \(z\)-axis.
Simplified, placing an object in the beam, causes a refraction, which results in a displacement of
the interference pattern created by the gratings. And by the above formula is connected to the
phase-shift introduced by the object. However, the interference patterns can not be spatially
resolved by the detector. This can be solved by performing multiple measurements with a later
shifted analyzer grating. This creates an intensity modulation of the detector read-out. This is
referred to as \textit{phase stepping}. Apart from the additional stepping necessary, the process of
acquiring measurements is the same to the one in conventional X-ray attenuation CT\@. I.e.\ the
rotational trajectory around the object. The different possible values measured using phase-stepping
are illustrated in \autoref{fig:grating_setup_what_happens}. All measured values are in relation to
a reference stepping curve, acquired without any object in the X-ray beam. In this setup,
attenuation is reflected by a drop of the average intensity. Compared to that, phase-shifts leads to
a lateral displacement of the interferometer pattern. And scattering reduces the amplitude of the
oscillation.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_attenuation.png}
			\end{subfigure}%
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_phase.png}
			\end{subfigure}
			\begin{subfigure}{0.42\textwidth}
				\includegraphics[width=\textwidth]{./figures/phase_contrast/plot_scattered.png}
			\end{subfigure}
		}}
	\caption{Visualization of the measured intensity changing measured at the detector, when
		performing phase-stepping. Attenuation is measured by a drop of the average
		intensity value compared to the reference signal (left most plot). Phase-shift leads
		to a lateral shift of the intensity signal (center plot). And scattering drops in
		amplitude (left plot). The reference signal is plotted in black for each plot.}%
	\label{fig:grating_setup_what_happens}
\end{figure}

Now that the setup is described, the next step is the derivation of the forward model. The intensity
signal \(I(x, y)\) measured in each pixel \((x, y)\) oscillates as a function of the stepping
direction. The phases \(\varphi(x, y)\) of the intensity oscillations in each pixel are connected to
the refraction angle \(\alpha(x, y)\), the distance \(d\) between G1 and G2 and the period \(p_2\)
of the analyzer grating G2 by~\cite{weitkamp_x-ray_2005}
\begin{equation}
	\varphi = 2 \pi \alpha \frac{d}{p_2} = \frac{\lambda d}{p_2} \frac{\partial \Phi}{\partial x}
\end{equation}
Using the phenomenological notion of a complex index of refraction, a combined description of
refraction and attenuation can be given. It is defined as
\begin{equation}
	n = 1 - \delta + i \beta
\end{equation}
The real part describes scattering and refraction, and the imaginary part describes attenuation. A
wave propagating with a wave vector \(\mvec{k}\) through a medium with refractive index \(n\), can
be described as
\begin{equation}\label{eq:wave_propagation}
	\Psi(\mvec{r}) = \Psi_0 \cdot e^{i n \mvec{k} \cdot \mvec{r}} = \Psi_0 \cdot e^{i(1-\delta)\mvec{k} \cdot \mvec{r}} \cdot e^{-\beta \mvec{k} \cdot \mvec{r}}
\end{equation}
Here the first exponential on the right-hand side represents a phase factor and the second an
attenuation of the wave's amplitude. This model can be used to derive the Beer-Lambert law as it was
shown in \autoref{eq:beer-Lambert-law} (compare~\cite[Chapter~2.1]{hahn_statistical_2014}). If one
looks only at the phase related term, it can be reformulated to
\begin{equation}\label{eq:wave_propagation_phase}
	\Psi_P(\mvec{r}) \coloneq \Psi_0 \cdot e^{i \mvec{k} \cdot \mvec{r}} \cdot e^{-i\delta \mvec{k} \cdot \mvec{r}}
\end{equation}
Using the fact, that a wave propagating through vacuum is given by
\begin{equation}
	\Psi_v \coloneq \Psi_0 \cdot e^{i \mvec{k} \cdot \mvec{r}}
\end{equation}
the phase-shift term of \autoref{eq:wave_propagation} given in \autoref{eq:wave_propagation_phase}
simplifies to
\begin{equation}
	\Psi_P(\mvec{r}) = \Psi_v \cdot e^{-i\delta \mvec{k} \cdot \mvec{r}}
\end{equation}
Next, a similar transformation as with the X-ray attenuation based model can be done. And then the
phase-shift for a wave traveling through a homogeneous material with a single refraction index \(n\)
is given by
\begin{equation}
	\Phi = \delta \mvec{k} \cdot \mvec{r}
\end{equation}
As with X-ray attenuation, this can be extended to inhomogeneous media, by integrating the refractive
index decrement function \(\delta\)
\begin{equation}
	\Phi = \int \delta(x, y, z) k_y \mathrm{d}y
\end{equation}
Then the refraction angle \(\alpha\) is given by
\begin{equation}
	\alpha(x,y) = \frac{\partial}{\partial x} \delta(x, y, z) \mathrm{d}y
\end{equation}
This section is mostly based on the derivation given in~\cite{hahn_statistical_2014}.
It should be of note, that it is not possible to directly measure the phase-shift with current
detector technology, but it is sufficient to measure the refraction index. Albeit, it should be
notated, that the angles are very small.

With that out of the way, we can see, that the forward model for differential phase-contrast is also
connected to the line integral. In this case the function integrated is not the attenuation
coefficient \(\mu\), but the refractive index decrement \(\delta\).

As a small excursion. As already alluded to a bit, the grating based setup can in addition to
attenuation and phase also measure scattering of the X-rays. Though, the scattering angles are
small, it is possible. Imaging modalities based on the scattering component are referred to as
\textit{dark-field}. The setup described above only measures scattering perpendicular to the
gratings. Hence, it is also possible to rotate the object around the central beam axis, i.e.\ in the
plane of the gratings. This opens the door for so-called directional or \gls{AXDT}. The connection
to the previous modalities (apart from the similar setup), is also the connection of the line
integral. Thou more complicated, they still share this common aspect.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}{0.55\textwidth}
				\includegraphics[width=\textwidth]{./figures/tooth/tooth_attenuation.png}
			\end{subfigure}%
			\begin{subfigure}{0.55\textwidth}
				\includegraphics[width=\textwidth]{./figures/tooth/tooth_phasecontrast.png}
			\end{subfigure}
		}}
	\caption{Example reconstruction of a medical tooth sample that was. On the left, the
		reconstruction of the attenuation part of the measured signal, on the right the
		reconstruction of the differential phase-contrast data. The absorption has been
		windowed to values in the range of \([0, 0.33]\), and for the phase-contrast image,
		an interval of \([-\frac{\pi}{8}, \frac{\pi}{8}]\) was used. Taken
		from~\cite{wieczorek_anisotropic_2017}. With permission from Tobias Lasser}
	\label{fig:medical_tooth_sample}
\end{figure}

As a final part of this chapter, \autoref{fig:medical_tooth_sample} presents the reconstruction of a
medical tooth sample, which was measured with a system as described above. The image of the left
shows the reconstruction of the attenuation based signal and on the right, the image based on the
differential phase-contrast is shown. This should mainly highlight, the difference in details gained
by the different methods.

\chapter{Mathematical Forward Models in Tomography}\label{chap:radon_transform_and_related}

In the previous chapter, the notion of the inverse problem is introduced. Further a forward model
for both X-ray attenuation and phase-contrast CT is derived. There the derivation was mostly driven
by the physical properties of the X-rays. This chapter dives deeper in the mathematical formulations
of forward models. And specifically important transformations in the field of tomographic
reconstruction.

The physical model is the link between the unknown signal and its measurements. Usually, the model
is referred to as \text{forward model}. First a couple of basic definitions are given, followed by a
deeper dive in to the mathematical formulation of the forward model for X-ray attenuation CT\@.

\begin{definition}[Signal]\label{def:signal}
	Let \(f\colon \mathbb{R}^n \to \mathbb{R}\) be a \(n\)-dimensional continuous function,
	whose support is bounded. It is referred to it as a \(n\)-dimensional signal. And often it
	will be referred to as signal, without the special mention of \(n\)-dimensional.
\end{definition}

Other names for signal are common, such as \textit{image} as in~\cite{herman_basis_2015}. However,
image is an overloaded term and can be misunderstood. Hence, it does not suit itself in a general
setting. In specific cases, such as the reconstruction of a two-dimensional functions, it works well
and thus, I will often refer to two-dimensional signals as images. Though, the usage is limited to
the solution domain of the inverse problem, as e.g.\ sinograms are not images in the colloquial
meaning of images. Hence, sinogram are not referred to as images. A similar distinction is made for
the three-dimensional case. There the three-dimensional signal is referred to as \textit{volume}.

Recall the definition of inverse problem given in \autoref{def:inverse_problem}. Just to reiterate,
there, the definition is given in terms of Hilbert spaces. But for the discussion here, one can
assume \(\mathcal{H} = \mathbb{R}^I\), \(\mathcal{K} = \mathbb{R}^J\) and \(A \in
\mathbb{R}^{I\times J}\) with \(I \in \mathbb{N}\) and \(J \in \mathbb{N}\). Now, the forward model
can be defined.

\begin{definition}[Forward Model]\label{def:forward-model}
	To reconstruct an unknown \(I\)-dimensional signal \(f: \mathbb{R}^I \to \mathbb{R}\), a set
	of \(J\) scalar measurements is necessary. A single scalar valued measurement \(m_j \in
	\mathbb{R}\), with \(j \in \{1, \dots, J\}\) is defined in therms of the physical model:
	\[ m_j = \mathscr{M}_j(f)\]
	where
	\[ \mathscr{M}_j\colon (\Omega \to \mathbb{R}) \to \mathbb{R} \]
	and \(\Omega \subseteq \mathbb{R}^I\). The mapping is required to be linear.
\end{definition}

This is a very general definition. This is useful to mathematically model a wide variety of
different applications. Usually, some restrictions are put upon the function \(f\), such that is has
compact support, i.e.\ is \(0\) outside a certain region, and that it is sufficiently nice. All the
applications in the previous chapter, can be modeled using this general definition.

The next sections are devoted to mathematical examples of such forward models. As the maybe most
important or at least most famous model, the \textit{Radon Transform} is discusses in detail.
However, for X-ray imaging modalities, the Radon Transform is only a good model for the
two-dimensional case. Therefore, the special \textit{X-ray Transform} is also presented.

\section{Radon Transform}\label{sec:radon_transform}

Recall from \autoref{sec:xray_attenuation_ct}, the connection between the initial intensity and the
measured intensity was the line integral of the attenuation coefficients of the matter. The
transformation mapping a function into its all line integrals known as the Radon Transform, which is
attributed to Johann Radon and his work in
\citeyear{radon_uber_1917}~\cite{radon_uber_1917,radon_determination_1986}. It was later
rediscovered by \citeauthor{cormack_representation_1963}~\cite{cormack_representation_1963} in the
context of the invention of CT scanners. Without any further ado, let us directly dive into the
definition of the Radon Transform.

\begin{definition}[Radon Transform]\label{def:radon_transform}
	Let \(\Omega \subset \mathbb{R}^I\) and \(f\colon \Omega \to \mathbb{R}\), which is assumed
	to sufficiently nice. Then the mapping \(\radon f\colon (\mathbb{R}^I \to \mathbb{R})
	\to (\mathbb{R} \times \mathscr{S}^{I-1} \to \mathbb{R})\) of \(f\), which maps \(f\) into
	the set of its integrals over the affine hyperplanes of \(\mathbb{R}^{I-1}\), is called the
	\textit{Radon Transform} (c.f.~\cite{natterer_mathematics_1986,buzug_computed_2008,carpio_inverse_2008}).
\end{definition}

Specifically, given the unit direction \(\mvec{\theta} \in \mathcal{S}^{I-1}\) and a scalar \(s \in
\mathbb{R}\), one can define the hyperplane \(\mathcal{H}^{I-1}(\mvec{\theta}, s) = \lbrace \mvec{x}
\in \mathbb{R}^I \, \colon \langle \mvec{x}, \mvec{\theta} \rangle = s  \rbrace\) with distance
\(s\) to the origin and perpendicular to \(\mvec{\theta}\). The Radon Transform \(\radon\) of \(f\)
is defined by the line integral over the hyperplane \(\mathcal{H}^{I-1}(\mvec{\theta}, s)\):
\begin{equation}\label{eq:radon_transform}
	\radon f(\mvec{\theta}, s) = \int_{\langle \mvec{x}, \mvec{\theta} \rangle = s} f(\mvec{x}) \, \, \mathrm{d}\mvec{x}
\end{equation}
Note that for \(n=2\) the hyperplanes are lines, and hence match the forward model for X-ray
imaging. For the 3-dimensional case, this does not fit anymore. For this case, the so-called X-ray
Transform \(\xray\) was developed by \citeauthor*{solmon_x-ray_1976}~\cite{solmon_x-ray_1976}, which
is very similar to the Radon Transform, but integrates over lines for all dimensions, instead of
hyperplanes. See \autoref{sec:xray_transform} for more on the X-ray Transform.

Also note that there many notations are common. Specifically in two dimensions, it is common to
define it via the polar coordinates. Others define a subspace perpendicular to the projection
direction \(\theta^\perp\). But the basic principle is the same. A notation used throughout the
thesis, is the subscript of the projection angle \(\theta\) as in \(\radon_\theta\). This is only
relevant for two-dimensional Radon Transform.

The Radon Transform is related to the Fourier Transformation. Also, it is a special case of the
Hankel Transform. Another special case of the Radon Transform is the \textit{Abel Transform}. If the
function \(f\) is a spherically-symmetric function the Radon Transform coincides with the Abel
Transform~\cite{buzug_computed_2008}. This is particularly interesting in the case of
spherically-symmetric basis functions, as is covered in \autoref{sec:blob_basis}.

\begin{definition}[Back-Projection]\label{def:back_projection}
	If the Radon Transform is defined as a linear bounded operator. One can define its adjoint
	\(\radon^\ast\) as
	\[ \radon^\ast g (\mvec{x}) = \int_{\mathcal{S}^{I-1}} g(\mvec{\theta}, \langle \mvec{x}, \mvec{\theta} \rangle) \, \, \mathrm{d} \mvec{\theta} \]
	Often one defines \(g = \radon f\). The adjoint is often referred to as the
	\textit{back-projection}. Compared to the \textit{forward projection} which is \(\radon f\).
\end{definition}

The backprojection is basically a smearing of the projection angles along the projection direction.
This is illustrated in \autoref{fig:backprojection_shepp_logan} on the left-hand side. For more and
more back-projections, the image gets closer to the original signal. However, it stays a blurry. A
sharper reconstruction can be achieved through different means. This is discussed in
\autoref{chap:tomographic_reconstruction}.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/backprojection/backprojection_shepp_logan_001.png}
				\phantomsubcaption{}\label{fig:backprojection_shepp_logan_1}
			\end{subfigure}%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/backprojection/backprojection_shepp_logan_002.png}
				\phantomsubcaption{}\label{fig:backprojection_shepp_logan_2}
			\end{subfigure}%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/backprojection/backprojection_shepp_logan_032.png}
				\phantomsubcaption{}\label{fig:backprojection_shepp_logan_16}
			\end{subfigure}%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/backprojection/backprojection_shepp_logan_256.png}
				\phantomsubcaption{}\label{fig:backprojection_shepp_logan_256}
			\end{subfigure}%
		}}%
	\caption{Back-projection of the Shepp-Logan phantom of \(1\), \(2\), \(32\) and \(256\)
		different projection angles.}\label{fig:backprojection_shepp_logan}
\end{figure}

In the setting of tomographic reconstruction, one wishes to reconstruct the original signal \(f\)
from a set of measurements \(m\). Already, \citeauthor*{radon_uber_1917} showed a theoretical way of
the adjoint operations of the Radon Transform. However, these results are very theoretical. A more
practical approach uses the connection of the Radon Transform to the Fourier Transform.

\begin{definition}[Fourier Slice Theorem]\label{def:fourier_slice_theorem}
	Let \(f\colon \mathbb{R}^2 \to \mathbb{R}\) be sufficiently nice and \(\mathscr{F}_n\) the
	\(n\)-dimensional Fourier transform. Then by the \textit{Fourier Slice Theorem}:
	\[ (\mathscr{F}_2f)(\theta, s) = (\mathscr{F}_1(\radon_\theta f(\cdot)))(s) \]
	It is also often referred to as \textit{projection-slice theorem} or \textit{central slice theorem}
\end{definition}

This is a very powerful theorem. In a more natural language, the \(1\)-dimensional Fourier Transform
of the projected data measured at the angle \(\theta\), is the same as a line through going the
origin of the \(2\)-dimensional Fourier Transform of the complete signal. The line is the line going
through the origin with a rotation angle \(\theta\). Hence, with enough projections, the \(f\) can be
described fully in the Fourier domain and reconstructed using the inverse \(2\)d Fourier Transform.

However, this method has a couple of drawback. \textit{Enough} projections is quite a vague
statement and a strong limitation. Especially considering the trend to reduce X-ray dosage and hence
reducing the number of projections acquired. Further, problems arise as the Fourier domain is
typically sampled in polar coordinates, but for this representation, one would like to access them
using Cartesian coordinates. This requires some for of interpolation. See the dissertation of
\citeauthor{vogel_tomographic_2015}~\cite[Chapter~4.1.2]{vogel_tomographic_2015} for a detailed
discussions and nice illustrative figures. More methods to compute the adjoint and reconstruction of
\(f\) are presented in \autoref{chap:tomographic_reconstruction}.

Of further interest to us is the first derivative of the Radon transform. As a variety of imaging
methods build on top of the derivative.

\begin{definition}[Derivative of the Radon Transform]
	The \(n\)th derivative of the Radon Transform is denoted by (compare
	e.g.\ \cite{nilchian_differential_2012,nilchian_fast_2013})
	\[ \radon^{(n)} = \frac{\partial^n}{\partial s^n} \radon f(\theta, s)\]
\end{definition}

The derivatives are linear operators, which are scale invariant, pseudo-distributive with respect to
convolution and projected translational invariant. The adjoint of the first derivative of the Radon
Transform is shown in~\cite{nilchian_differential_2012}, and for the \(n\)th derivative
see~\cite{nilchian_fast_2013}.

\section{X-ray Transform}\label{sec:xray_transform}

The \(n\)-dimensional Radon Transform computes the integral over \(n-1\)-dimensional hyperplanes.
However, for the setting of attenuation X-ray CT, one is interested in the line integration over
lines in \(n\)-dimensional spaces. Hence, a variation of the Radon Transform is introduced.

\begin{definition}[X-ray Transform]\label{def:x-ray_transform}
	Given the projection direction \(\mvec{\theta} \in \mathscr{S}^{n-1}\) and \(\mvec{x} \in
	\mathbb{R}^n\), then
	\[ \xray f(\mvec{\theta}, \mvec{x}) = \int_{-\infty}^{+\infty} f(\mvec{x} + t \mvec{\theta}) \, \mathrm{d} t \]
	is the \textit{X-ray Transform}. It is the integral over the straight line through
	\(\mvec{x}\) with direction \(\mvec{\theta}\)
	(c.f.~\cite{natterer_mathematics_1986,solmon_x-ray_1976}).
\end{definition}

In the two-dimensional case, the Radon Transform and X-ray Transform are equivalent.
Then, the relation between the Radon Transform and the X-ray Transform is
\begin{equation}
	\xray f(\mvec{\theta}, s\mvec{\theta}^\perp) = \radon f(\mvec{\theta}^\perp, s)
\end{equation}
For the case of attenuation X-ray CT, the X-ray Transform is the physical forward model used. The
Fourier Slice Theorem~\ref{def:fourier_slice_theorem} also holds true for the X-ray Transform.

Another transformations, which is not considered in this thesis, is the Cone-Beam Transform
(c.f.~\cite[Chapter~2]{carpio_inverse_2008}). Also, other important topics such as the Riesz
potential are left out.

\chapter{Signal Representation}\label{chap:signal_representation}

Recall from the beginning, three main steps need to be performed, to reconstruct a problem in the
tomographic setting. In the previous chapters, the first of the three steps --- defining the forward
model --- is covered. This chapter is completely devoted to the second step: The discretization of
the problem space.

Signals as defined in \autoref{def:signal}, are continuous functions. However, if one wishes to use
computers to solve the reconstruction tasks, there exists a need for discretization, as computers
are inherently discrete. Hence, one wishes to represent a signal in a discrete fashion.

\begin{definition}[Permissible representation]\label{def:permissible_representation}
	Let \(f\colon \mathbb{R}^n \to \mathbb{R}\) be a \(n\)-dimensional continuous function,
	\(N \in \mathbb{N}\) be a positive integer and \(\varphi_n\) a set basis function for
	\(1 \leq n \leq N\). Then the signal \(f\) can be approximated as a linear combination
	of these basis functions and the coefficients \(c_n\) (c.f.\ \cite{herman_basis_2015}):
	\[ f \approx \near{f}(\mvec{x}) = \sum_{k=1}^{N} c_k \varphi_k(\mvec{x}) \]
\end{definition}

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.55\textwidth}
				\resizebox{\textwidth}{!}{%
					\input{figures/image_representation/grid_representation.pgf}
				}%
				\caption{Permissible representation of a signal with regularly spaced coefficients.}\label{fig:permissible_representation_idx}
			\end{subfigure}
			\begin{subfigure}[t]{0.55\textwidth}
				\resizebox{\textwidth}{!}{%
					\input{figures/image_representation/grid_pixel_representation.pgf}
				}%
				\caption{Permissible representation of a signal using pixel basis function}\label{fig:permissible_representation_pixel}
			\end{subfigure}
		}}
	\caption{Visualization of the permissible representation. In this case the
		coefficients are spaces equally along the signal.
		\subref{fig:permissible_representation_idx} shows the coefficients of the
		permissible representation. \subref{fig:permissible_representation_pixel} shows the
		same but additionally overlays the pixel basis function
	}\label{fig:permissible_representation}
\end{figure}

For our purposes, we assume the function lies on a regular spaced discrete grid (see
\autoref{fig:permissible_representation}). However, this notation is a little too general for our
needs. It is sufficient to express everything in terms of a single zero center symmetrical basis
function. Hence, let \(\varphi\) be such a zero centered symmetrical basis function, \(\mvec{k} \in
\mathbb{Z}^n\) be the \(n\)-dimensional index of a grid cell, and \(\mvec{x}_{\mvec{k}} \in
\mathbb{R}^n\) the center coordinate of the \(\mvec{k}\)-th grid cell. Then, the previous equation
can be reformulated:
\begin{equation}
	\near{f}(\mvec{x}) = \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}} \varphi(\mvec{x} - \mvec{x}_{\mvec{k}})
\end{equation}
This definition follows the notation given in~\cite{momey_new_2011}. This method to discretize a
signal is called \textit{series expansion} and is described in detail in
e.g.\ \cite{herman_basis_2015}.

With that, only a finite number of points are necessary to represent a signal, at least under the
assumption that functions have compact support. Hence, a discrete representation is found. But the
quality and accuracy of the representation depends heavily on the chosen basis function. However,
before more details are given regarding the choice of basis function, it is interesting to
investigate how the permissible representation behaves under certain transformations.

As it is an important transformation, a closer look is taken at Radon Transformation. Applying the
Radon Transform yields the following:
\[ \radon\near{f}(\mvec{x}) = \radon\left( \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}} \varphi(\mvec{x} - \mvec{x}_{\mvec{k}}) \right) \]
Due to the linearity of the Radon Transform this is equivalent to
\[ \radon\hat{f}(\mvec{x}) = \sum_{\mvec{k} \in \mathbb{Z}^n} c_{\mvec{k}}\radon\left( \varphi(\mvec{x} - \mvec{x}_{\mvec{k}}) \right) \]
Put into natural language, the Radon transformation applied to the permissible representation, only
act upon the basis function. Hence, it is sufficient to study, how the Radon transformation acts
upon the individual basis function.

Note that this holds for any linear physical model. Notably, this holds for the X-ray transform and
the first derivative of the Radon transform. But it is also true for the physical models behind the
applications discussed in the previous chapter.

The key takeaway, is that the linear operators, such as the forward models related to the imaging
modalities discussed in \autoref{chap:imaging_modalities}, or the derivative operator only act on
the basis function. Therefore, part of the next sections is exactly this discussion. Further, the
aforementioned accuracy discussion is also following in the respective sections. The basis functions
introduced are: the pixel or voxel basis function; the family of spherically-symmetric basis
functions introduced by \citeauthor*{lewitt_multidimensional_1990}; and an interesting
generalization of the voxel basis functions, called B-Splines basis functions.

Before diving deeper into each of the basis functions, a high level contextual introduction may be
helpful. The pixel or voxel basis function is ubiquitous. It is everywhere. But that does not
necessarily make it the best choice or even a good choice. In the field of tomographic
reconstruction the family of spherically-symmetric basis functions have received a lot of attention.
Specifically, it is often used in the approximation of the Radon and X-ray Transform. There it is
typically used as a direct replacement of the pixel or voxel basis function in the series expansion
method. Hence, many techniques can be carried over. This is in contrast to the B-Spline basis
function. The most research in the tomographic field regarding B-Spline is the continuous
approximation of the signal. I.e.\ a continuous representation of the measurements is constructed,
such that certain properties of analytical solutions hols (c.f.~\cite{horbelt_discretization_2002}).
To the best of my knowledge, only~\cite{nilchian_fast_2013}
and~\cite{momey_new_2011,momey_b-spline_2012,momey_spline_2015} take the comparable approach of the
series expansion method with B-Splines. With this in mind, let us discuss the details of each basis
function.

\section{Voxel Basis}\label{sec:voxel_basis}

Likely, the most well known basis function in imaging, is the pixel or voxel basis functions.
Usually, it is referred to as pixel basis function for two-dimensions, and voxel basis for the
three-dimensional case. However, to be agnostic, from here on it will be referred to as voxel basis
for any dimension, expect if explicitly the two-dimensional case is referred to.

The voxel basis function is a piecewise linear function. The voxel basis function is most likely the
most widely used basis function. Most literature assumes the voxel basis function implicitly. A
illustration of the permissible representation of a signal using the voxel basis function can be
seen in \autoref{fig:permissible_representation_pixel}.

The centered voxel basis function of unit step width, is given by:
\begin{equation}\label{eq:voxel_basis_fn}
	\varphi^{\text{pixel}}(\mvec{x}) = \Pi(\mvec{x})
	\begin{cases}
		1, \abs{\mvec{x}} < \frac{1}{2}           \\
		\frac{1}{2}, \abs{\mvec{x}} = \frac{1}{2} \\
		0, \text{otherwise}
	\end{cases}
\end{equation}
\(\Pi\) is the rectangular pulse of unit step length. Also, the absolute value is coefficient wise,
as soon as the absolute value of any coefficient of the vector \(\mvec{x} \in \mathbb{R}^n\) is
larger half the step size, the function will return \(0\).

The voxel basis function for the one-dimensional case is just the step function centered around the
origin. It can be seen in \autoref{fig:pixel_basis_function_1d}. Approximating a signal using the
voxel basis function is equivalent to averaging the values of a certain region. Or, phrased
differently, is equivalent to the nearest neighbor interpolation. This is shown in
\autoref{fig:pixel_basis_approx_fn}. For a two-dimensional signal, an example is given in
\autoref{fig:permissible_representation_idx}.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.55\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/pixel_basis/pixel_basis.png}
				\caption{One-dimensional voxel basis function}\label{fig:pixel_basis_function_1d}
			\end{subfigure}
			\begin{subfigure}[t]{0.55\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/pixel_basis/pixel_transformation.png}
				\caption{Approximation of a signal using the voxel basis function.}\label{fig:pixel_basis_approx_fn}
			\end{subfigure}
		}}
	\caption{Visualization of the voxel basis function. \subref{fig:pixel_basis_function_1d}
		shows the one-dimensional centered voxel basis function.
		\subref{fig:pixel_basis_approx_fn} shows an approximation of a \(\sin\) curve using
		the voxel basis function. The staircase approximation is clearly visible.
	}\label{fig:pixel_basis_function}
\end{figure}

As pointed out by \citeauthor*{lewitt_multidimensional_1990}
in~\cite{lewitt_multidimensional_1990,lewitt_alternatives_1992} the voxel basis function isn't
necessarily a good choice for biomedical imaging. Not specifically for biomedical images, but this
can be seen in \autoref{fig:pixel_basis_approx_fn}. The smooth function of a \(\sin\) is crudely
approximated by a staircase version of the \(\sin\). As usually biomedical images are assumed to be
smooth, this can result in artefacts. Though, it is possible to increase the resolution of the
sampling rate and increase accuracy that way. But this approach is rather suboptimal, as at some
point physical limits are reached in terms of resolution during the measurement process.

Further, the voxel basis function is discontinuous at the boundaries. And as it can be seen in the
above figure, the permissible representation is not continuously differentiable. This makes it
unsuited for certain applications such differential phase-contrast CT\@. As the derivative is a key
component forward model, the voxel basis function needs certain special treatment for such models.
Frequently, some for of analytical differentiation is performed, such as
in~\cite{xu_investigation_2012}.

There exists an analytical formulation of the Radon Transform. It is given
in~\cite{toft_radon_1996}. However, usually approximates are used. Some of these are discussed in
\autoref{chap:projector}.

\section{Blob Basis}\label{sec:blob_basis}

First introduced by~\citeauthor*{lewitt_multidimensional_1990}
in~\cite{lewitt_multidimensional_1990}, spherically-symmetric volume elements (often referred to as
blobs) are an alternative to the pixel basis.~\cite{lewitt_alternatives_1992} describes how blobs
can be used in iterative reconstruction algorithms as a basis instead of pixels.

Blob basis functions have been adopted in multiple different fields. Among others electron
microscopy~\cite{marabini_3d_1998, garduno_optimization_2001}, positron emission tomography
(PET)~\cite{jacobs_comparative_1999, chlewicki_noise_2004}, single-photon emission tomography
(SPECT)~\cite{wang_3d_2004, yendiki_comparison_2004}, attenuation X-ray
CT~\cite{jacobs_iterative_1999, carvalho_helical_2003, isola_motion-compensated_2008},
phase-contrast CT~\cite{kohler_iterative_2011, xu_investigation_2012}, reconstruction of coronary
trees~\cite{zhou_blob-based_2008}, breast tomosynthesis~\cite{wu_breast_2010}, reduction of metal
artifacts~\cite{levakhina_two-step_2010} or computed laminography~\cite{trampert_spherically_2017}.

Generally, many fields report increased accuracy or improved handling of artifacts. In other fields,
such as phase-contrast CT, blobs enable the usage of iterative reconstructions without an extra step
of numerical differentiation.

\begin{figure}
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.45\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/blob_basis/blob_2d.png}
			\end{subfigure}
		}}%
	\caption{A visualization of a \(2\)D blob basis function}\label{fig:blob_basis}
\end{figure}

Now that the applications and some advantages for the blob basis functions were highlighted. Let us
dive into the definition.

\begin{definition}[Blob basis function]\label{def:blob_basis_fn}
	The generalized Kaiser-Bessel basis function as proposed by
	\citeauthor{lewitt_multidimensional_1990}~\cite{lewitt_multidimensional_1990,
		lewitt_alternatives_1992} is defined as:
	\[
		\varphi^{\text{blob}}_{m, \alpha, a}(r) =
		\begin{cases}
			\frac{I_m\left( \alpha \sqrt{1 - \left(\frac{r}{a}\right)^2} \right)} {I_m\left( \alpha \right)} \left( \sqrt{1 - \left(\frac{r}{a}\right)^2}\right)^m & 0 \le r \le a      \\
			0                                                                                                                                                      & \textit{otherwise}
		\end{cases}
	\]
	where \(I_m\) is the modified Kaiser-Bessel function of the first kind of order \(m\), \(r\) the
	distance to the blob center, \(a\) the blob radius given in units of the grid, \(\alpha\)
	controlling the shape of the blob, and \(m\) controls the continuity of the blob function. A
	visualization of a blob basis function in two dimensions is given in \autoref{fig:blob_basis}.
\end{definition}

The influence of the parameters \(\alpha\) and \(m\) is shown in
\autoref{fig:blob_basis_alphas_order_0}--\autoref{fig:blob_basis_alphas_order_2}. From that it
should be clear how important the exact choice of parameters is.

Regarding the parameter \(m\), the blob is not continuously differentiable if \(m = 0\). For \(m >
1\) blob is continuous with \(m - 1\) continuous derivatives, compare~\cite{matej_practical_1996}.
They also advise using \(m > 2\) such that the first derivative is also continuous.

Regarding, the other parameters, \(a\) and \(\alpha\),~\cite{matej_practical_1996} already conducted
investigations regarding good choices of \(\alpha\) and \(a\) for Cartesian grids including an
optimization method. A key take-away is that the exact choice depends highly on the concrete
problem. However, they propose a \textit{standard blob} with parameters with \(a = 2\) and \(\alpha
= 10.4\). The exact choice of \(\alpha\) is this case is motivated by the aim to find a band-limited
signal representation. The rationale for this is laid out in~\cite{lewitt_multidimensional_1990}
and also discussed in~\cite{benkarroum_blob_2015}. E.g.~\cite{xu_investigation_2012} follows this
specific value. But some others use slightly different values for
\(\alpha\).~\cite{kohler_iterative_2011} uses \(\alpha = 10.826\) and
~\cite{levakhina_three-dimensional_2014} \(\alpha = 10.83\). It should be noted
that~\cite{benkarroum_blob_2015} recommends the use of \(\alpha = 13.738507\) and \(a = 2.453144\).
However, these are not used throughout this thesis, as the computational burden keeps growing with a
larger value of \(a\). Hence, the experiments conduced in \autoref{chap:experiments} follow the
values used in~\cite{levakhina_three-dimensional_2014}, which are similar to the standard blob.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.425\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/blob_basis/blob_alphas_order_0.png}
				\caption{}\label{fig:blob_basis_alphas_order_0}
			\end{subfigure}%
			\begin{subfigure}[t]{0.425\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/blob_basis/blob_alphas_order_1.png}
				\caption{}\label{fig:blob_basis_alphas_order_1}
			\end{subfigure}%
			\begin{subfigure}[t]{0.425\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/blob_basis/blob_alphas_order_2.png}
				\caption{}\label{fig:blob_basis_alphas_order_2}
			\end{subfigure}%
		}}%
	\caption{Influence of blob parameters \(\alpha\) and \(m\) on the shape of blob basis
		functions. From left to right, \(m = 0\), \(m = 1\) and \(m = 2\). For each \(m\),
		\(\alpha \in \lbrace 0, 4, 8, 10.83 \rbrace\) is plotted. Only the positive part of
		the symmetric basis function is shown.
	}\label{fig:blob_parameter_overview}
\end{figure}

Apart from its increased accuracy, blobs have another nice property. There exists a close form of
the Radon and X-ray Transform. The blob basis function as discussed here, are rotationally
symmetric. Therefore, the X-ray Transform simplifies to the Abel
Transform~\cite{buzug_computed_2008}. Effectively, this means, that the X-ray Transform is
independent on the projection angle, but only dependent on the distance from the origin. The Radon
Transform of the blob basis function is defined as
(c.f.~\cite{lewitt_multidimensional_1990,lewitt_alternatives_1992}):
\begin{align}\label{eq:radon_blob_basis}
	g(s) & = \int_{-\infty}^{+\infty} \varphi^{\text{blob}}_{m, \alpha, a}\left(t\right) \, \mathrm{d} t                                                                                                       \\
	     & = 2 \int_0^{\sqrt{(a^2-s^2)}} \varphi^{\text{blob}}_{m, \alpha, a}\left(\sqrt{s^2 - r^2}\right) \, \mathrm{d} r                                                                                     \\
	     & = \frac{a}{I_m(\alpha)} \left( \frac{2\pi}{\alpha}\right)^{1/2} \left( \sqrt{1 - \left(\frac{s}{a}\right)^2} \right)^{m + 1/2} I_{m+1/2}\left( \alpha \sqrt{1 - \left(\frac{s}{a}\right)^2} \right)
\end{align}
\(s\) is the distance from the X-ray to the blob center, and \(\sqrt{a^2 - s^2}\) is one half of the
intersection length between the blob and the ray. The projected value only depends on the distance
from the X-ray to the blob center. This is a very nice property.~\cite{xu_investigation_2012}
provides an explicit formula for the derivative of the X-ray transform of the blob basis functions,
as it is required by applications such as differential phase-contrast CT\@.

From an implementation standpoint, the half integer order of the modified Kaiser-Bessel function of
the first kind, can be quite nasty. Implementations do exist as it can be seen
in~\cite{temme_numerical_1975}. However, the floating point implementations are non-trivial. For the
case of C++, since C++17 the standard library provides mathematical special functions
~\cite{noauthor_c_nodate, noauthor_stdcyl_bessel_i_nodate}. But sadly, it is not yet entirely
portable across systems, as only two out of three major implementations of the standard library.
Explicitly, is it not implemented in libc++. However, for our cases it is sufficient to assume \(m
\in \mathbb{N}\). Then the above equation can be further simplified.

The recurrence formulation for the modified Kaiser-Bessel function of the first kind is
(c.f.~\cite[Chapter~9]{abramowitz_handbook_1972}):
\begin{equation}\label{eq:kaiser_bessel_recurrence}
	I_{m+1}(x) = I_{m-1}(x) - \frac{2 m}{x}I_m(x)
\end{equation}
Further, the Kaiser-Bessel functions have representations with elementary functions. For the
modified Kaiser-Bessel function of the first kind, there are defined as (c.f.~\cite[Chapter~10]{abramowitz_handbook_1972}):
\begin{align}\label{eq:kaiser_bessel_half_integer}
	I_{0.5}(x) & = \sqrt{\frac{2}{\pi x}} \sinh(x)                                                                               \\
	I_{1.5}(x) & = \sqrt{\frac{2}{\pi x}} \left( \cosh(x) \frac{\sinh(x)}{x} \right)                                             \\
	I_{2.5}(x) & = \sqrt{\frac{2}{\pi x}} \left(\left(\frac{3}{x^2} + \frac{1}{x}\right)\sinh(x) - \frac{3}{x^2} \cosh(x)\right)
\end{align}
Then \autoref{eq:radon_blob_basis} can be simplified to not include any non-integer evaluations of
the modified Kaiser-Bessel function of the first kind. For example assuming, \(m = 0\), and to keep
everything a little more concise, let \(w = \sqrt{1 - \left(\frac{r}{a}\right)^2}\):
\begin{align}\label{eq:radon_blob_basis_order_0_simplified}
	g(s) & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi}{\alpha}\right)^{1/2} \left( w \right)^{1/2} I_{1/2}\left( \alpha w \right)                     \\
	     & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi w}{\alpha}\right)^{1/2} I_{1/2}\left( \alpha w \right)                                          \\
	     & = \frac{a}{I_0(\alpha)} \left(\frac{2\pi w}{\alpha}\right)^{1/2} \left( \frac{2}{\pi \alpha w}\right)^{1/2} \sinh \left(\alpha w \right) \\
	     & = \frac{2 a}{\alpha I_0(\alpha)} \sinh \left(\alpha w \right)
\end{align}
In the last step, \(\pi\) and \(w\) cancel out, and both the \(2^2\) and \(\alpha^2\) are moved out
of the square root, leaving it empty. Similar operations can be done for \(m = 1\) and \(m = 2\).

\section{B-Spline Basis}\label{sec:bspline_basis}

Splines are common in image and signal processing~\cite{unser_splines_1999}. Applications include
image interpolation, image transformations, image compressions or the calculation of the first and
second derivative. A common approach is the approximation of the function or image using Splines and
then working efficiently on the continuous representation of the splines. For B-Splines
specifically,~\citeauthor*{unser_fast_1991}~\cite{unser_fast_1991} show the continuous image
representation using B-Splines.

This approach was adopted to tomographic reconstruction.~\cite{la_riviere_spline-based_1998}
proposed the calculation of the inverse 2D and 3D Radon transform based on B-Spline.
Similarly,~\cite{horbelt_discretization_2002} develops a B-Spline based filtered back projection.
Apart from attenuation CT, other medical applications of B-Splines include electron
tomography~\cite{tran_robust_2013, tran_inverse_2014}, positron emission tomography
(PET)~\cite{nichols_spatiotemporal_2002, li_fast_2007, verhaeghe_investigation_2007} and
single-photon emission tomography (SPECT)~\cite{guedon_b-spline_1991, reutter_fully_2007}.

Using B-Splines as a basis function was first presented by~\cite{momey_new_2011,
	momey_b-spline_2012, momey_spline_2015}. And a similar signal representation was adapted for
phase-contrast CT in~\cite{nilchian_fast_2013, nilchian_differential_2012, nilchian_spline_2015}.
They differ in the approximation of the evaluation of the X-ray transform. The former use a
footprint of the B-Splines, where the later rely on the first derivative of the B-Spline basis
function.

Now, first couple of definitions and properties are given.
\begin{definition}[B-Spline]
	The most basic definition of a B-Spline of order \(0\) and unit width is the step function:
	\[
		\beta^0(x) = \Pi(x) =
		\begin{cases}
			1,           & \text{if } \abs{x} < \frac{1}{2} \\
			\frac{1}{2}, & \text{if } \abs{x} = \frac{1}{2} \\
			0,           & \text{otherwise}
		\end{cases}
	\]
	Note that B-Splines of order \(0\) is just the voxel basis function. This makes the
	B-Splines a nice generalization of the voxel basis function. Then the univariate B-Spline of
	order \(d\) can be constructed by \(d + 1\) convolution of
	\(\beta^0\) (compare~\cite{momey_new_2011}):
	\[
		\beta^d(x) = \beta^0 * \beta^{d-1}(x) = \underbrace{\beta^0 * \dots * \beta^0(x)}_{d+1 \text{convolution terms}}
	\]
	See \autoref{fig:bspline_basis_1d} for illustrations of the B-Spline basis functions of
	different order.
\end{definition}

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/bsplines_basis/bspline_basis_1d_order0.png}
				\phantomsubcaption{}\label{fig:bspline_basis_order_0}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/bsplines_basis/bspline_basis_1d_order1.png}
				\phantomsubcaption{}\label{fig:bspline_basis_order_1}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/bsplines_basis/bspline_basis_1d_order2.png}
				\phantomsubcaption{}\label{fig:bspline_basis_order_2}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/bsplines_basis/bspline_basis_1d_order3.png}
				\phantomsubcaption{}\label{fig:bspline_basis_order_3}
			\end{subfigure}
		}}%
	\caption{Examples of the \(1\)d univariate B-Spline basis functions of different order. From
		left to right, B-Spline basis of order \(0\), \(1\), \(2\) and \(3\).
	}\label{fig:bspline_basis_1d}
\end{figure}

Another way to compute the B-Spline basis of order \(d\) is given in~\cite{unser_fast_1991}:
\begin{equation}
	\beta^d(x) = \sum_{i=0}^{d+1} \frac{(-1)^i}{n!} \binom{d+1}{i}(x - i)^d\Pi(x - i)
\end{equation}
where \(\binom{d+1}{i}\) is the binomial coefficient.

The derivative is again B-Spline of order \(d-1\) (compare~\cite{unser_splines_1999}):
\begin{equation}
	\frac{\partial \beta^d(x)}{\partial x} = \beta^{d-1}\left(x + \frac{1}{2}\right) -
	\beta^{d-1}\left(x - \frac{1}{2}\right)
\end{equation}
B-Splines are continuously differentiable up to order \(d-1\).

B-Splines are separable. Hence, \(n\)-dimensional B-Splines, often referred to as tensor product
B-Splines. They can be constructed the following way:
\begin{equation}
	\beta^d(\mvec{x}) = \prod^n_{i=1} \beta^d(\mvec{x}_i)
\end{equation}
where \(\mvec{x} \in \mathbb{R}^n\).

B-Splines have a couple of really attractive properties. B-Splines are the shortest and smoothest
scaling functions for a given order of approximation~\cite{momey_b-spline_2012}. They are close to a
Gaussian function, with a sufficiently large \(d\)~\cite{momey_b-spline_2012}, all while preserving
compactness. Hence, they tend to spherically-symmetric functions, while preserving local support.
Due to these properties, \citeauthor*{momey_new_2011}\cite{momey_new_2011} argue for B-Splines over
blobs. Further, they note the need to tune the parameters for of blobs for optimal results, which
adds complexity. This is an important point. During reconstruction, there are many, so-called
hyperparameters, such as the blob basis parameters. With more parameters, the complexity and the
possible combination of parameter choices grows quickly. Hence, finding the optimal or at least good
hyperparameters for a reconstruction gets harder. Also finding default values can be harder, which
also increases complexity.

Importantly, blobs fail to satisfy the partition of unity~\cite{nilchian_fast_2013}. A basis
functions that satisfies the partition of unity, can approximate any input function arbitrarily
close.~\citeauthor*{nilchian_fast_2013}~\cite{nilchian_fast_2013} show the impact of the property
for tomographic reconstruction. They outperform blob in a similar setting in terms of reconstruction
quality.

According to~\cite{momey_spline_2015}, quadric (order \(2\)) B-Splines are around as accurate as the
blob basis function. Though as mentioned above, with growing order, the B-Splines tent to
spherically-symmetric functions, many such
as~\cite{momey_new_2011,momey_b-spline_2012,momey_spline_2015, nilchian_fast_2013} restrict
themselves to B-Splines of order \(3\). This seems to be an optimum for accuracy and computation
cost, as larger orders have an increased footprint and therefore increase the necessary amount of
computation.

In~\cite{horbelt_discretization_2002}, it was shown that the Radon transform of B-Splines are spline
bikernel. \citeauthor*{entezari_box_2012} show in~\cite{entezari_box_2012} explicitly how (tensor
product) B-Splines act under the X-ray and Radon transform.~\cite{nilchian_differential_2012} shows
how B-Splines act under the first derivative of the Radon transform.

The Radon Transform of a two-dimensional B-Spline was shown by
\citeauthor*{horbelt_discretization_2002}\cite{horbelt_discretization_2002}. Given the projection
angle \(\theta\), then it is:
\begin{equation}
	\radon_\theta\beta^d(s) = \beta^d_{\sin\theta} * \beta^d_{\cos\theta}(s)
\end{equation}
Hence it is the convolution of two splines of different width (denoted by the subscript). These are
referred to as spline bikernels. \citeauthor*{horbelt_discretization_2002} presents an explicit
formulation to compute it.

To extend this to the \(3\)-dimensional setting, one can look into \textit{box splines}. (Tensor
product) B-Splines are a special case of box splines.
\begin{definition}[Box Spline]\label{def:box_splines}
	Box splines are the shadow of a hypercube in \(\mathbb{R}^n\), when projected down to a
	lower dimension \(\mathbb{R}^d\). Similarly to B-Splines, box splines can be defined via
	convolution:
	\begin{equation}
		M_\Xi(\mvec{x}) = M_{\xi_1} * \dots * M_{\xi_n}(\mvec{x})
	\end{equation}
	where \(\Xi \coloneq \mathopen[ \xi_1 \xi_2 \dots \xi_n \mathclose] \in \mathbb{R}^{s \times
		n}\) is the matrix of directions. Each \(\xi\) defines a direction of the hypercube. \(\Xi\)
	completely defines the box spline (compare~\cite{de_boor_box_1993}). If \(\Xi\) is the
	identity matrix, the box spline is the same as the tensor-product B-Spline.
\end{definition}

\citeauthor*{entezari_box_2012}~\cite{entezari_box_2012} proof that the X-ray transform of a
\(d\)-variate box spline is a \(d - 1\) variate box spline. Further, it is the box spline defined
the by projection of the direction matrix \(\Xi\). This means, going back to B-Splines, that for any
dimension, the X-ray transform of B-Splines are again B-Splines of lower dimension.

\chapter{Tomographic Reconstruction}\label{chap:tomographic_reconstruction}

Till this point, the physical models involved in tomographic reconstruction have been presented, and
discretization methods have been discussed. The last missing piece is the solution to the inverse
problem.

Generally, one needs to find solution to the system \(Af = m\). There \(A\) is the forward model,
\(f\) is the \(n\)-dimensional signal one seeks to reconstruct, and \(m\) is the measured data, i.e.\
the projected data. In the specific case of X-ray attenuation CT, the forward model \(A\) is the
Radon Transform \(\radon\) or the X-ray Transform \(\xray\), the signal \(f\) is the function of
attenuation coefficients of the scanned object \(\mu\), and \(m\) is the data measured at the
detector (including noise).

\section{Analytical Reconstruction}\label{sec:analytical_reconstruction}

As already alluded to in the section about the Radon Transform in \autoref{sec:radon_transform}.
There do exist closed form analytical inversion methods for the Radon Transform. In the
aforementioned section, the Fourier Slice Theorem was introduced. Methods exist that use this
approach as a means to reconstruct the desired signal. However, they are not often used in practice
in tomographic reconstruction.

Recall from the back-projection from \autoref{def:back_projection}. This can be seen as a first kind
of solution to inverse problem. The result of back-projecting the measured projections is a blurry
version of the original function. \citeauthor{buzug_computed_2008}~\cite{buzug_computed_2008}
describes post-processing as a possible solution. However, there exists another option. If the
projections are filtered in the Fourier domain and then the filtered values are back-projected just
as before, a sharper image can be obtained. This is referred to as the filtered back-projection
(FBP)~\cite{ramachandran_three-dimensional_1971}.

\begin{definition}[Filtered Back-Projection]\label{def:filtered_back_projection}
	Let \(f\colon \Omega \to \mathbb{R}\), where \(\Omega \in \mathbb{R}^2\) sufficiently nice,
	and \(g \coloneq \radon f\) be the Radon Transform of \(f\). Then
	\[ g^\delta(t, \phi) \coloneq (\delta \ast g(\cdot, \phi))(t) \]
	is the filtered projection. \(\delta(x) \approx \abs{x}\) is a filter, which is convolved
	with the projection data. With the adjoint of the Radon Transform \(\radon^\ast\) as in
	\autoref{def:back_projection}, then \(\radon^\ast g^\delta\) is the \textit{\gls{FBP}}.
\end{definition}

The \gls{FBP} for a different number of projection angles can be seen in
\autoref{fig:filtered_backprojection_shepp_logan}. It is clearly visible, that a large amount of
projection angles are necessary to reconstruct a pleasing image. The filtered Radon Transform of a
measurement can be seen on the bottom row on the left of
\autoref{fig:filtered_backprojection_shepp_logan}. In this case the filter is a so called
\textit{ramp} filter (depicted on the bottom right of
\autoref{fig:filtered_backprojection_shepp_logan}). Other common filters include the
Ram-Lak~\cite{ramachandran_three-dimensional_1971} or the Shepp-Logan filter
\cite{shepp_fourier_1974}. The later is also depicted on the plot together with the ramp filter. The
Shepp-Logan filter includes a smoothing filter to deal better with noise.

\begin{figure}
	\centering
	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_shepp_logan_032.png}
				\phantomsubcaption{}\label{fig:fbp_32_projections}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_shepp_logan_064.png}
				\phantomsubcaption{}\label{fig:fbp_64_projections}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_shepp_logan_128.png}
				\phantomsubcaption{}\label{fig:fbp_128_projections}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_shepp_logan_512.png}
				\phantomsubcaption{}\label{fig:fbp_512_projections}
			\end{subfigure}
		}}%

	\makebox[\textwidth]{ \makebox[1.3\textwidth]{%
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_shepp_logan_ramp.png}
				\phantomsubcaption{}\label{fig:fbp_filtered_sinogram}
			\end{subfigure}
			\begin{subfigure}[t]{0.3125\textwidth}
				\includegraphicsmaybe[width=\textwidth]{figures/filtered_backprojection/fbp_filters.png}
				\phantomsubcaption{}\label{fig:fbp_filters}
			\end{subfigure}
		}}%
	\caption{Top row: reconstruction using \gls{FBP} with a different number of projection
		angles. From left to right: \(32\), \(64\), \(128\) and \(512\) projection angles.
		Bottom row: one the right filtered projection measurement, filtered with the ramp
		filter and and the left, plot of the ramp and Shepp-Logan filter.
	}\label{fig:filtered_backprojection_shepp_logan}
\end{figure}

The quality of the reconstruction depends on the filter and data acquisition. Further the FBP as
presented here, is limited to parallel beam geometry setups. There do exist other methods for fan
beam settings that require rebinning (i.e.\ sorting the projections, such that all rays are
parallel). However, overall the FBP leads to sharp images, and it is widely used in medical CT
scanners~\cite{pan_why_2009}.

\section{Towards the Matrix form}\label{sec:matrix_formulation}

As it can be seen in the previous section, the \gls{FBP} leads to overall sharp results. But
iterative reconstruction algorithm generally outperform it. Importantly, with iterative
reconstruction algorithms, the X-ray dose can be reduced~\cite{willemink_evolution_2019}. This is
desired as exposure to X-rays involves health risks.

Before, however, iterative reconstruction algorithms are presented, one needs the correct problem
statement. So far the forward model \(A\) is still assumed to be continuous. However, this is not
the desired form for those group of algorithms. Hence, this section is a short run through the steps
that are necessary to go from the continuous definition of the inverse problem as given in
\autoref{def:inverse_problem} to a discrete version.

As already shown inÂ¸\autoref{def:permissible_representation}, the signal \(f\) can be described as
\begin{equation}
	f \approx \near{f} = \sum_{k=1}^{N} c_k \varphi(\cdot - \mvec{x}_k) = \sum_{k=1}^{N} c_k \varphi_k
\end{equation}
choosing any zero centered symmetric basis function for \(\varphi\) (e.g.\ voxel basis, blobs, or
B-Splines). \(\varphi_k\) is only a shorted notation. Note, here a linearized index is used not a
index vector \(\mvec{k}\) as it is shown \autoref{def:permissible_representation}. They are
equivalent, however, this notation will come on handy here.

Using the notation given in \autoref{def:forward-model}, i.e. \(J\) is a set of scalar measurements,
and a single scalar measurements \(m_j \in \mathbb{R}\) with \(j \in \lbrace 1, \dots, J \rbrace\),
the scalar measurements can be approximated using the permissible representation of \(f\) using the
physical model \(\mathscr{M}_j\):
\begin{equation}
	m_j \approx \mathscr{M}_j\hat{f} = \sum_{k=1}^{I} c_k \mathscr{M}_j\varphi_k
\end{equation}
This is possible due to the linearity of the forward model. \(a_{ji} \coloneq
\mathscr{M}_j(\varphi_k)\) is the contribution of a basis function to the \(j\)th measurement.

\begin{figure}
	\centering
	\resizebox{0.7\textwidth}{!}{%
		\input{figures/matrix_row/matrix_row.pgf}
	}%
	\caption{Visualization of the idea behind the matrix form of the problem regarding
		tomographic reconstruction. The problem and measurement domain is discretized and
		then linearized to a vector. Here the vector for a single measurement is given as
		\(a_{1,i}\). Weights closer to the ray can be expected have a higher
		contribution.}\label{fig:matrix_row}
\end{figure}

For a single measurements \(m_j\), the contributions can be gathered in a single vector \(\mvec{a}_j
= (a_{j,i}) \in \mathbb{R}^I\). Here, the choice of linearized index comes in handy. Note that the
dimensionality of the problem space does not matter. The intuition behind this idea is given in
\autoref{fig:matrix_row}. There, the measurement \(m_1\), the contribution vector \(\mvec{a}_{1} =
\begin{bmatrix}a_{1, 1}, a_{1, 2} \cdots a_{1,36}\end{bmatrix}^T\) is visualized for a typical
\(2\)d X-ray setup. As this is two-dimensional setting, the linearized index is rearranged, to fit a
two-dimensional image. This works for any dimension. From the illustration it should be obvious,
that contribution further away from the ray, are closer or equal to \(0\). One can guess from this
visualization the sparsity of the contribution vectors, as already in this simple illustration,
roughly half the entries of the row are \(0\).

Now, both the measurements and the coefficients can be stacked to a vector, i.e.\ \(\mvec{m} = (m_j)
\in \mathbb{R}^J\) and \(\mvec{c} = (c_i) \in \mathbb{R}^I\) respectively. Now, a single measurement
can be written as a scalar product of the coefficient vector and the contribution vector. But taking
it a step further. A linear system can be defined:
\begin{equation}\label{eq:system_lin_equation}
	\mvec{m} \approx
	\begin{bmatrix}
		\rule[.5ex]{2em}{0.4pt} & \mvec{a}_1^T & \rule[.5ex]{2em}{0.4pt} \\
		\rule[.5ex]{2em}{0.4pt} & \mvec{a}_2^T & \rule[.5ex]{2em}{0.4pt} \\
		\vdots                                                           \\
		\rule[.5ex]{2em}{0.4pt} & \mvec{a}_J^T & \rule[.5ex]{2em}{0.4pt}
	\end{bmatrix} \mvec{c} \eqcolon A \mvec{c}
\end{equation}

This is a regular system of linear equation, it partitions the problem in the measurements, the
\textit{system matrix} \(A \in \mathbb{R}^{J \times I}\) and the coefficient vector \(\mvec{c}\).
It should be noted that it is equivalent to solve for \(mvec{x}\) and solve for \(f\).

As the system matrix is the model of the system of linear equations is it tremendously important.
The system matrix represents not only the physical process and its approximation. But also the
imaging geometry and discretization scheme. Of special importance for the scope of this thesis, it
further integrates the choice of basis function.

\section{Iterative Reconstruction}\label{sec:iterative_reconstruction}

In the previous chapter the linear system of equation is defined. With this iterative reconstruction
algorithms can be applied. This has several advantages. As explained in
\autoref{chap:signal_representation}, the problems considered in this thesis are ill-posed. Hence,
care has to be taken when solving the linear system of equations. Another significant aspect is
mentioned in the previous section. Iterative reconstruction algorithms handle noisy and challenging
setups better. Such settings include low number of available projections. As described above, it is
desirable to reduce the number of projections, to lower the X-ray exposure.

A common approach to handle ill-posed problems is to considered least squares problem instead.
\begin{definition}[Least Squared Problem]\label{def:least_squares_problem}
	The least squares problem is defined as
	\[ \argmin_{\mvec{c}} \frac{1}{2} \norm{A\mvec{c} - \mvec{m}}^2_2 \]
	The solution to the least squares problem is given by the normal equation
	\[ A^T A \mvec{c} = A^T \mvec{m} \]
\end{definition}
Note here, that \(A\mvec{c}\) is considered the forward projection and \(A^T \mvec{m}\) is the
backward projection.

The system matrix is usually too large to store in system memory. Therefore, algorithms are
necessary, which do not require the knowledge of the complete system matrix. The software computing
the system matrix on the fly, is often referred to as projectors. A deep dive into the algorithms
for such projectors is conduced in \autoref{chap:projector}.

In the following sections a portion of common and known algorithms in the space of tomographic
reconstruction are presented. These sections should provide an overview, of what methods exist and
a brief introduction on how they work. Out of scope is a detailed discussion about convergence of
the algorithms. Two important classes of iterative reconstruction algorithm is presented, namely
\textit{Landweber Iteration} and \textit{\gls{ART}}. Further, a common addition is the use of regularization.
Hence, the problem formulation regarding regularization is given and two different regularization
strategies are presented: \textit{Tikhonov} (i.e.\ \(l_2\)) and \(l_1\) regularization. For both
regularization methods, a short dive into their solutions is given as well.

\subsection{Landweber Iteration}\label{subsec:landweber_iteration}

A well studied class of iterative algorithms is the \textit{Landweber
	Iteration}~\cite{landweber_iteration_1951}. It has been discovered in many ways in the past.
The algorithm was introduced in the tomographic space by
\citeauthor{gilbert_iterative_1972}~\cite{gilbert_iterative_1972} under the name of
\gls{SIRT}.

\begin{definition}[Landweber Iteration]\label{def:landweber_iteration}
	Given a linear system of equations as defined in \autoref{def:inverse_problem}, the
	\textit{Landweber iteration} finds a solution to the corresponding least squares problem. The update
	step for \(k = 0, 1, \dots\) is given by
	\[
		\mvec{c}^{(k+1)} = \mvec{c}^{(k)} + \lambda^{(k)} A^T(\mvec{m} - A\mvec{c}^{(k)})
	\]
	\(\lambda^{(k)} \in \mathbb{R}\) is a sequence of relaxation parameter that must satisfy
	\(0 < \lambda^{(k)} < 2 \norm{A^T A}_2^{-1}\quad \forall k \in \mathbb{N}\).
\end{definition}

Generally, Landweber iterations (in the basic case) only rely on the forward \(A\mvec{c}^{(k)}\) and backward
\(A^T \mvec{m}\) projections. The innermost part of the update function, is a forward projection of the
current guess. Next, the residual to the measurement is taken and finally the error is back
projected and used as an update to the current guess.

The basic Landweber iteration is a special case of gradient descent. If \(f(\mvec{c}) = \frac{1}{2}
\norm{A\mvec{c} - \mvec{m}}_2^2\), the update can be written in terms of the gradient
\begin{equation}
	\mvec{c}^{(k+1)} = \mvec{c}^{(k)} - \lambda^{(k)} \nabla f(\mvec{c}^{(k)})
\end{equation}
A generalisation of the Landweber iteration can be given by
\begin{equation}
	\mvec{c}^{(k+1)} = \mvec{c}^{(k)} + \lambda^{(k)} DA^TM(\mvec{m} - A\mvec{c}^{(k)})
\end{equation}
The exact algorithm and it's convergence behavior, depend on the precise choice of the matrices
\(D\) and \(M\). The basic Landweber iteration as presented above has \(D = M = I\). If \(D =
\frac{1}{J} \text{diag}(\norm{\mvec{a}_j}^2_2)^{-1}\), with \(\norm{\mvec{a}_j}^2_2\) being the
squared \(l_2\) norm of the \(j\)th row of the system matrix, the method is known as
Cimmino's~\cite[Chapter~6.1]{hansen_discrete_2010}.

Both the vanilla Landweber Iterations and Cimmino's method are known to exhibit semiconvergence.
Semiconvergence is a term coined by Natter~\cite{natterer_mathematics_1986}, however, I find the
explanation given by \citeauthor*{hansen_discrete_2010} in~\cite[Chapter~6]{hansen_discrete_2010}
to be very good.

\begin{definition}[Semiconvergence]\label{def:semiconvergence}
	Iterative Reconstruction algorithms produce a sequence of approximate solutions
	\(\mvec{c}^{(1)} \mvec{c}^{(2)}\mvec{c}^{(3)}\mvec{c}^{(4)}, \cdots\). An algorithm is said
	to exhibit semiconvergence, if the first many \(\mvec{c}^{(k)}\) for \(k = 1, 2, \cdots\),
	resembles the regularized exact solution, but starts to diverge again for later iterations.
\end{definition}

The semiconvergence of the Landweber Itations is quite slow.

\subsection{Algebraic Reconstruction Technique}\label{subsec:algebraic_reconstruction_technique}

The \glsfirst{ART} was proposed by \citeauthor{gordon_algebraic_1970}\cite{gordon_algebraic_1970}.
However, outside of tomography the method is often knows as Kaczmarz
method~\cite{kaczmarz_approximate_1993}. Though, \gls{ART} is a slight modification of the original
Kaczmarz method.

The basic idea of the algorithm, is to view each row of the system matrix as a hyperplane and update
the solution by iteratively project it onto the hyperplane. If the system matrix is square \(I = J\)
and of full rank, all hyperplanes intersect at one point and \gls{ART} will converge to it. However, if
the system is overdetermined (\(J > I\)) and noisy, which it usually is, the hyperplanes will not
intersect at a single point, but rather at in close proximity to each other.

\begin{definition}[Algebraic Reconstruction Technique]\label{def:art}
	Given the system of linear equations \(A\mvec{c} = \mvec{m}\), and an initial solution guess
	\(\mvec{c}^{(0)} \in \mathbb{R}^I\) (i.e.\ the zero vector). Then the solution can be
	iteratively updated for
	\(k = 0, 1, \dots\)
	\[
		\mvec{c}^{(k+1)} = \mvec{c}^{(k)} + \lambda^{j(k)} \frac{\mvec{m}_{j(k)} - \langle \mvec{a}_{j(k)}, \mvec{c}^{j(k)} \rangle}{\norm{\mvec{a}_{j(k)}}}\mvec{a}_{j(k)}
	\]
	where \(\lambda^{(k)} \in \left(0, 1\right]\) is a sequence of relaxation parameters, and
	\(j(k)\) is a mapping to select an appropriate row for each iteration. In the simple case
	\(j(k) = (k \mod J) + 1\), but it can also be randomized~\cite{strohmer_randomized_2007}.
\end{definition}

The original Kaczmarz method had \(\lambda(k) = 1\, \forall k \in \mathbb{N}\), lowering the
relaxation parameter can improve the reconstruction in noisy settings. Further, the method can be
written as a Landweber-type method~\cite{hansen_discrete_2010}, but it's rather uncommon.

The convergence of \gls{ART} is quite fast for the first couple of iterations, but tapers off after
that and becomes quite slow~\cite{hansen_discrete_2010}. However, there do exist problems if the
hyperplanes do not intersect at a single points. \gls{ART} also exhibits semiconvergence.

Compared to the Landweber iterations given in the previous section, the Kaczmarz methods accesses
the rows of the system matrix \(A\) sequentially (but maybe not in ascending order). On the other
hand Landweber type methods access all rows of the system matrix simultaneously. Hence, the
`simultaneous' as part of \gls{SIRT}\@.

\section{Regularization}\label{sec:regularization}

So far all solvers presented here have only looked at the least squares problem. I.e.\ they only
concern themselves with the forward model and do not incorporate any further constrains. However,
usually we have some information about the images we wish to reconstruct. For example, one would
expect them to be smooth. One hopes that regularization stabilizes the solution. In the sense that
small perturbations by noise in the measurements, still yields solutions close to the exact
solutions.

\begin{definition}[Regularized Problem]\label{def:regularized_problem}
	Let \(R(\mvec{c})\) be a \textit{penalty function} or \textit{regularizer}, then the least
	square problem can be expanded to
	\[
		\argmin_{\mvec{c}} \frac{1}{2} \norm{A \mvec{c} - \mvec{m}}_2^2 + \lambda R(\mvec{c})
	\]
	this is referred to as \textit{regularized problem}. \(\lambda\) is a regularization
	parameter. It denotes the weight of the penalty term.
\end{definition}

This can also be generalized to other problems. Let \(T(\mvec{c})\) be a data fidelity term (e.g.\
the least squares one, or the negative log-likelihood). Then the regularized problem can be
described as
\begin{equation}\label{eq:optimization_problem}
	\argmin_{\mvec{c}} T(\mvec{c}) + \lambda R(\mvec{c})
\end{equation}
Usually, \(R\) is chosen to be non-linear and often is expected to be continuously differentiable.
This equation has three parts. The first \(T(\mvec{c})\) is the data term. It measures how well a
prediction models the noisy data. However, we do not want to fit the noise in the data. This is the
second, the regularization term. \(\lambda\) controls the importance or the balance of each the
previous terms.

\subsection{Tikhonov Regularization}\label{subsec:tikhonov_regularization}

A well studied and often used regularization is named after Andrey Nikolayevich
Tikhonov~\cite{tihonov_solution_1963}. The penalty restricts the solution based on the Euclidean
norm.

\begin{definition}[Tikhonov Regularization]\label{def:tikhonov_regularization}
	The penalty term for Tikhonov regularization is given by
	\[
		R(\mvec{c})_{\text{Tikhonov}} = \norm{\Gamma \mvec{c}}_2^2
	\]
\end{definition}
A common case is a simple scaling function i.e.\ \(\Gamma = \alpha I\), thus the Tikhonov
regularizer penalizes \(\mvec{c}\) with large \(l_2\) norm. Therefore, it is also referred to as
\(l_2\)-regularization. But also the first and second derivative operator is commonly
used~\cite{golub_tikhonov_1999} The hope is, that Tikhonov regularization suppresses high-frequency
noise.

On a further note, the Tikhonov regularization can be reformulated to a least squares problem again
\begin{equation}
	\argmin_{\mvec{c}} \frac{1}{2}
	\left\lVert
	\begin{pmatrix}
		A \\
		\lambda \Gamma
	\end{pmatrix}
	\mvec{c} -
	\begin{pmatrix}
		\mvec{m} \\
		0
	\end{pmatrix}
	\right\rVert_2^2
\end{equation}
Here \(\begin{pmatrix}
	A \\
	\lambda \Gamma
\end{pmatrix}\) is a stacked matrix, with the system matrix on top, and the Tikhonov matrix in the
bottom. A different commonly used notation is
\begin{equation}
	(A^T A + \lambda \Gamma^T \Gamma)\mvec{c} = A^T \mvec{m}
\end{equation}
The problem remains linear and thus can be solved using the previously discussed iterative
reconstruction algorithms. However, in general, for non Tikhonov regularization this does not hold
true. Thus, the problem is rendered non-linear and different optimization techniques have to be
used.

\subsection{\(l_1\)-Regularization}\label{subsec:l1_regularization}

Another common regularization method is based on the \(l_1\) norm, i.e.\ the sum of absolute
values.
\begin{definition}[\(l_1\)-Regularization]\label{def:l1_regularization}
	The penalty term for Tikhonov regularization is given by
	(compare~\cite{tibshirani_regression_1996,tibshirani_lasso_2013,beck_fast_2009})
	\[
		R(\mvec{c})_{l_1} = \norm{\mvec{c}}_1
	\]
\end{definition}
Compared to the \(l_2\) regularization, the \(l_1\) regularization enforces sparsity. I.e.\ the
assumption is that the representation is in some way sparse, and should be enforced. Also, it is
more robust to outliers~\cite{beck_fast_2009}. For information on how these problems can be solved
see \citeauthor{beck_fast_2009}~\cite{beck_fast_2009}. As it will be used in the experimental
sections, specifically \gls{ISTA} and  \gls{FISTA}.

\begin{definition}[ISTA]\label{def:ista}
	The update step for \gls{ISTA} is given by
	\[
		\mvec{c}^{(k+1)} = \mathscr{T_\alpha} (\mvec{c}^{(k)} - 2 \lambda A^T (A \mvec{c}^{(k)} - \mvec{m}))
	\]
	where \(t\) is an appropriate step size and \(\mathscr{T_\alpha}\) is the shrinkage operator
	defined by
	\[
		\mathscr{T_\alpha}(\mvec{c})_j = \max(\abs{\mvec{c}_i} - \alpha, 0) \sign(\mvec{c}_j)
	\]
\end{definition}
Similar to Landweber like methods, the residual of the forward projection current prediction and the
measurement vector is back projected. Next, the projected error is subtracted from the current
estimate and then the shrinkage operator is applied.

However, the convergence of \gls{ISTA} is rather slow (compare~\cite{beck_fast_2009} and its
references). \gls{FISTA} improves on the convergence of \gls{ISTA}, but it is out of scope for this
thesis. Please refer to \citeauthor{beck_fast_2009}~\cite{beck_fast_2009} for further reading.
