
@article{entezari_box_2012,
	title = {A {Box} {Spline} {Calculus} for the {Discretization} of {Computed} {Tomography} {Reconstruction} {Problems}},
	volume = {31},
	issn = {0278-0062, 1558-254X},
	url = {http://ieeexplore.ieee.org/document/6172241/},
	doi = {10.1109/TMI.2012.2191417},
	abstract = {B-splines are attractive basis functions for the continuous-domain representation of biomedical images and volumes. In this paper, we prove that the extended family of box splines are closed under the Radon transform and derive explicit formulae for their transforms. Our results are general; they cover all known brands of compactly-supported box splines (tensorproduct B-splines, separable or not) in any number of dimensions. The proposed box spline approach extends to non-Cartesian lattices used for discretizing the image space. In particular, we prove that the 2-D Radon transform of an N -direction box spline is generally a (non-uniform) polynomial spline of degree N − 1. The proposed framework allows for a proper discretization of a variety of tomographic reconstruction problems in a box spline basis. It is of relevance for imaging modalities such as X-ray computed tomography and cryo-electron microscopy.},
	language = {en},
	number = {8},
	urldate = {2021-02-17},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Entezari, A. and Nilchian, M. and Unser, M.},
	month = aug,
	year = {2012},
	pages = {1532--1541},
	file = {Entezari et al. - 2012 - A Box Spline Calculus for the Discretization of Co.pdf:/home/david/Zotero/storage/7W67K34M/Entezari et al. - 2012 - A Box Spline Calculus for the Discretization of Co.pdf:application/pdf},
}

@phdthesis{wieczorek_anisotropic_2017,
	title = {Anisotropic {X}-ray {Dark}-field {Tomography}},
	abstract = {Modern X-ray based imaging enables recording of phase-contrast (refraction) and dark-field
(Small Angle X-ray Scattering) information using Talbot-Lau interferometry. These X-ray
imaging modalities provide improved contrast where standard absorption based imaging
only provides poor to none. The task of Computed Tomography (CT) amounts to recon-
struction of the physical quantities within the imaged object which caused a specific obser-
vation/measurement. A major prerequisite for tomographic reconstruction is first a model
of the physical properties, e.g. using scalars, vectors or tensors. Second, a forward model is
required which enables simulation of measurements from a given 3D representation of the
physical properties. For X-ray based absorption CT, this describes the task of computing the
accumulative effect on the X-ray beam traversing through the object. The combination of a
forward model and corresponding measurements form an inverse problem. Mathematically,
the task of CT corresponds to the inversion of the forward model which can be computed
using according numerical methods.
While tomographic reconstruction for modalities different than X-ray CT often employs very
similar mathematical concepts, software frameworks are often strictly focused on a specific
modality. The first contribution presented in this thesis is the development of an abstract
software framework for tomographic reconstruction. Within this framework the numerical
methods are implemented independently from the specific forward model which enables
adaptation and application of methods for multiple modalities. Additionally, the framework
supports the composition of various common approaches such as regularization methods which
allows for intensive comparison and evaluation of specific methods for multiple modalities.
Within the scope of this work, this framework will be applied to tomographic reconstruction
of the dark-field signal.
Reconstruction of the dark-field signal poses a particularly challenging problem, as the
scattering within an object depends on the X-ray beam’s direction as well as the grating
orientation in contrast to absorption and phase-contrast imaging. Thus, the physical quantity
at each position cannot be modeled by a scalar entity, but requires a more complex model
instead. A first method has been presented previously in form of X-ray Tensor Tomography
(XTT) where a rank-2 tensor is used to describe the scattering happening in each location of
the measured object. This tensor combines information on the scattering strength as well as
its directional distribution which provides an insight into orientation of microstructures within
the object.
A major limitation of the XTT approach is that a tensor is restricted to a single microstructure
direction. In order to cope with this problem within this thesis a general closed-form, continu-
ous forward model of the Anisotropic X-ray Dark-field Tomography will be presented. This
vii
model contains the XTT model under specific assumptions and in addition enables the tomo-
graphic reconstruction of a spherical function representing the whole scattering profile in each
location of the object. This novel approach provides strongly improved reconstructions using
spherical harmonics. All this is achieved at a computational complexity comparable to that
required by XTT. Additionally, an approach to extract the orientation of the microstructures
causing the scattering will be presented. Experiments show that the method of AXDT is capa-
ble of reconstructing multiple scattering orientations and the corresponding microstructure
orientations.
Finally, a first biomedical experiment on a sample of a human cerebellum indicates that AXDT
could provide a complementary imaging modality for imaging nerve fibers within the Central
Nervous System (CNS).},
	language = {en},
	school = {Technische Universität München},
	author = {Wieczorek, Matthias},
	month = oct,
	year = {2017},
	file = {Wieczorek - 2017 - Anisotropic X-ray Dark-field Tomography.pdf:/home/david/Zotero/storage/VINZ2W2A/Wieczorek - 2017 - Anisotropic X-ray Dark-field Tomography.pdf:application/pdf},
}

@article{nilchian_fast_2013,
	title = {Fast iterative reconstruction of differential phase contrast {X}-ray tomograms},
	volume = {21},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-21-5-5511},
	doi = {10.1364/OE.21.005511},
	abstract = {Differential phase-contrast is a recent technique in the context of X-ray imaging. In order to reduce the specimen’s exposure time, we propose a new iterative algorithm that can achieve the same quality as FBP-type methods, while using substantially fewer angular views. Our approach is based on 1) a novel spline-based discretization of the forward model and 2) an iterative reconstruction algorithm using the alternating direction method of multipliers. Our experimental results on real data suggest that the method allows to reduce the number of required views by at least a factor of four.},
	language = {en},
	number = {5},
	urldate = {2021-02-17},
	journal = {Optics Express},
	author = {Nilchian, Masih and Vonesch, Cédric and Modregger, Peter and Stampanoni, Marco and Unser, Michael},
	month = mar,
	year = {2013},
	pages = {5511},
	file = {Nilchian et al. - 2013 - Fast iterative reconstruction of differential phas.pdf:/home/david/Zotero/storage/YPH6XGY2/Nilchian et al. - 2013 - Fast iterative reconstruction of differential phas.pdf:application/pdf},
}

@book{de_boor_box_1993,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Box {Splines}},
	volume = {98},
	isbn = {978-1-4419-2834-4 978-1-4757-2244-4},
	url = {http://link.springer.com/10.1007/978-1-4757-2244-4},
	language = {en},
	urldate = {2021-02-17},
	publisher = {Springer New York},
	author = {de Boor, Carl and Höllig, Klaus and Riemenschneider, Sherman},
	editor = {John, F. and Marsden, J. E. and Sirovich, L.},
	year = {1993},
	doi = {10.1007/978-1-4757-2244-4},
	file = {de Boor et al. - 1993 - Box Splines.pdf:/home/david/Zotero/storage/XZACJRNH/de Boor et al. - 1993 - Box Splines.pdf:application/pdf},
}

@phdthesis{von_teuffenbach_statistical_nodate,
	title = {Statistical signal processing and reconstruction algorithms for grating-based {X}-ray imaging and computed tomography},
	abstract = {Grating-based X-ray interferometry is a novel imaging technique that offers great potential for
the visualization of materials and tissues that are not easily depicted using conventional X-ray
imaging methods. Tomographic reconstruction based on interferometric data provides not only
access to the distribution of an object’s attenuation but also to its refraction and ultra-small-
angle scattering power. These images provide valuable additional information that could well
expand the diagnostic capabilities of a clinical computer tomography (CT) scanner.
One of the main reasons why this technique has not yet been implemented in a modern CT
scanner is that the improved functionality comes at the cost of longer measurement times. Ex-
isting projection-based processing algorithms require not a single measurement per projection
angle but several measurements with precise grating movements in between. A further reason
is that these signal estimation algorithms are also very sensitive to changes in the system align-
ment due to mechanical vibrations or thermal drifts, which are abound in a clinical high-power
CT using a continuously rotating gantry.
Several solutions for these problems have been proposed but all suffer from major drawbacks.
In this thesis first two simple improvements to existing signal estimation methods are pre-
sented and then a novel direct reconstruction method is introduced. A fast algorithm for
reconstructions using this method is developed, the technique is tested at scans using just a
single measurement per angular position and further enhancements that make the reconstruc-
tions robust to vibrations and drifts are implemented and tested.
The results in this thesis demonstrate that it is possible to successfully reconstruct the attenu-
ation, refraction, and ultra-small-angle scattering of an object using only a single measurement
per projection angle on a system influenced by significant vibrations and drifts.
This is a milestone for the future implementation of a grating interferometer onto a continuously
rotating clinical CT scanner.},
	language = {English},
	school = {Technische Universität München},
	author = {von Teuffenbach, Maximilian},
	file = {von Teuffenbach - Statistical signal processing and reconstruction a.pdf:/home/david/Zotero/storage/XDQRZTVK/von Teuffenbach - Statistical signal processing and reconstruction a.pdf:application/pdf},
}

@article{kohler_iterative_2011,
	title = {Iterative reconstruction for differential phase contrast imaging using spherically symmetric basis functions: {Iterative} reconstruction for differential phase constrast imaging},
	volume = {38},
	issn = {00942405},
	shorttitle = {Iterative reconstruction for differential phase contrast imaging using spherically symmetric basis functions},
	url = {http://doi.wiley.com/10.1118/1.3608906},
	doi = {10.1118/1.3608906},
	abstract = {Purpose: The purpose of this work is to combine two areas of active research in tomographic x-ray imaging. The ﬁrst one is the use of iterative reconstruction (IR) techniques. The second one is differential phase contrast imaging (DPCI).
Methods: The authors derive a maximum likelihood (ML) reconstruction algorithm with regularization for DPCI. Forward and back-projection are implemented using spherically symmetric basis functions (blobs) and differential footprints, thus completely avoiding the need for numerical differentiation throughout the reconstruction process. The method is applied to the problem of reconstruction of an object from sparsely sampled projections.
Results: The results show that the proposed method can handle the sparsely sampled data efﬁciently. In particular no streak artifacts are visible which are present in images obtained by ﬁltered back-projection (FBP).
Conclusions: IR algorithms have a wide spectrum of proven advantages in the area of conventional computed tomography. The present work describes for the ﬁrst time, how a matched forward and back-projection can be implemented for DPCI, which is furthermore free of any heuristics. The newly developed ML reconstruction algorithm for DPCI shows that for the case of sparsely sampled projection data, an improvement in image quality is obtained that is qualitatively comparable to a corresponding situation in conventional x-ray imaging. Based on the proposed operators for forward and back-projection, a large variety of IR algorithms is thus made available for DPCI.},
	language = {en},
	number = {8},
	urldate = {2021-02-24},
	journal = {Medical Physics},
	author = {Köhler, Thomas and Brendel, Bernhard and Roessl, Ewald},
	month = jul,
	year = {2011},
	note = {Number: 8},
	pages = {4542--4545},
	file = {Köhler et al. - 2011 - Iterative reconstruction for differential phase co.pdf:/home/david/Zotero/storage/JC48J3TV/Köhler et al. - 2011 - Iterative reconstruction for differential phase co.pdf:application/pdf;Köhler et al. - 2011 - Iterative reconstruction for differential phase co.pdf:/home/david/Zotero/storage/DSPA27N2/Köhler et al. - 2011 - Iterative reconstruction for differential phase co.pdf:application/pdf},
}

@book{bebis_advances_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Advances in {Visual} {Computing}: 10th {International} {Symposium}, {ISVC} 2014, {Las} {Vegas}, {NV}, {USA}, {December} 8-10, 2014, {Proceedings}, {Part} {I}},
	volume = {8887},
	isbn = {978-3-319-14248-7 978-3-319-14249-4},
	shorttitle = {Advances in {Visual} {Computing}},
	url = {http://link.springer.com/10.1007/978-3-319-14249-4},
	language = {en},
	urldate = {2021-02-24},
	publisher = {Springer International Publishing},
	editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and McMahan, Ryan and Jerald, Jason and Zhang, Hui and Drucker, Steven M. and Kambhamettu, Chandra and El Choubassi, Maha and Deng, Zhigang and Carlson, Mark},
	year = {2014},
	doi = {10.1007/978-3-319-14249-4},
	file = {Bebis et al. - 2014 - Advances in Visual Computing 10th International S.pdf:/home/david/Zotero/storage/BGRSUDL4/Bebis et al. - 2014 - Advances in Visual Computing 10th International S.pdf:application/pdf},
}

@inproceedings{mirzargar_spline_2013,
	address = {San Francisco, CA, USA},
	title = {A spline framework for sparse tomographic reconstruction},
	isbn = {978-1-4673-6455-3 978-1-4673-6456-0 978-1-4673-6454-6},
	url = {http://ieeexplore.ieee.org/document/6556763/},
	doi = {10.1109/ISBI.2013.6556763},
	abstract = {We present a spline-based sparse tomographic reconstruction framework. The proposed method utilizes the closed-form analytical Radon transform of B-splines and box splines of any order and integrates the (transform-domain) sparsity of the image into the reconstruction algorithm. Our experiments show that the synergy of sparse reconstruction together with higher order basis functions (e.g., cubic B-splines) improves the accuracy of the reconstruction. This gain can also be exploited for reducing the number of projection angles in the data acquisition.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {2013 {IEEE} 10th {International} {Symposium} on {Biomedical} {Imaging}},
	publisher = {IEEE},
	author = {Mirzargar, Mahsa and Sakhaee, Elham and Entezari, Alireza},
	month = apr,
	year = {2013},
	pages = {1272--1275},
	file = {Mirzargar et al. - 2013 - A spline framework for sparse tomographic reconstr.pdf:/home/david/Zotero/storage/GHZPRVVJ/Mirzargar et al. - 2013 - A spline framework for sparse tomographic reconstr.pdf:application/pdf},
}

@article{momey_spline_2015,
	title = {Spline {Driven}: {High} {Accuracy} {Projectors} for {Tomographic} {Reconstruction} {From} {Few} {Projections}},
	volume = {24},
	issn = {1057-7149, 1941-0042},
	shorttitle = {Spline {Driven}},
	url = {http://ieeexplore.ieee.org/document/7182340/},
	doi = {10.1109/TIP.2015.2466083},
	language = {en},
	number = {12},
	urldate = {2021-02-24},
	journal = {IEEE Transactions on Image Processing},
	author = {Momey, Fabien and Denis, Loic and Burnier, Catherine and Thiebaut, Eric and Becker, Jean-Marie and Desbat, Laurent},
	month = dec,
	year = {2015},
	note = {Number: 12},
	pages = {4715--4725},
	file = {Momey et al. - 2015 - Spline Driven High Accuracy Projectors for Tomogr.pdf:/home/david/Zotero/storage/BVR98LW9/Momey et al. - 2015 - Spline Driven High Accuracy Projectors for Tomogr.pdf:application/pdf},
}

@article{momey_b-spline_2012,
	title = {A {B}-spline based and computationally performant projector for iterative reconstruction in tomography},
	language = {en},
	author = {Momey, Fabien and Denis, Loıc and Mennessier, Catherine},
	year = {2012},
	pages = {5},
	file = {Momey et al. - 2012 - A B-spline based and computationally performant pr.pdf:/home/david/Zotero/storage/KKG94HAZ/Momey et al. - 2012 - A B-spline based and computationally performant pr.pdf:application/pdf},
}

@article{kobbelt_stable_1997,
	title = {Stable {Evaluation} of {Box} {Splines}},
	abstract = {The most elegant way to evaluate box-splines is by using their recursive de nition. However, a straightforward implementation reveals numerical di culties. A careful analysis of the algorithm allows a reformulation which overcomes these problems without losing e ciency. A concise vectorized MATLAB-implementation is given.},
	language = {en},
	author = {Kobbelt, Leif},
	month = may,
	year = {1997},
	pages = {4},
	file = {Kobbelt - 1997 - Stable Evaluation of Box Splines.pdf:/home/david/Zotero/storage/4A3VXJDQ/Kobbelt - 1997 - Stable Evaluation of Box Splines.pdf:application/pdf},
}

@article{richter_use_1998,
	title = {Use of box splines in computer tomography},
	volume = {61},
	issn = {0010-485X, 1436-5057},
	url = {http://link.springer.com/10.1007/BF02684410},
	doi = {10.1007/BF02684410},
	abstract = {Box splines are attractive for practical multivariate approximation, since they possess good approximation power and can he evaluated very efficiently.We want to give an idea of how their qualities can be made to come into play in the field of image reconstruction in computerized tomography (CT). To keep the exposition simple, we will concentrate on a special situation: our tomograph will be characterized by the bivariate standard scanning geometry and our reconstructions will alwayslie in scales of the linear space spanned by the integer translates of a fixed piecewise quadratic box spline. On the other hand we give details of an algorithm based on Fourier reconstruction, which produces approximationsof optimal order for the box splines used, whilst the amount of computational work required is of no higher order than for classical Fourier reconstruction. We present another reconstruction procedure based on quasi-interpolation, which compares to filtered backprojection in computational complexity.Along with our exposition,we give a generalization of a certain Theorem due to Nievergelt which may be of interest for practical applications.},
	language = {en},
	number = {2},
	urldate = {2021-02-24},
	journal = {Computing},
	author = {Richter, M.},
	month = jun,
	year = {1998},
	note = {Number: 2},
	pages = {133--150},
	file = {Richter - 1998 - Use of box splines in computer tomography.pdf:/home/david/Zotero/storage/HYN3R3C2/Richter - 1998 - Use of box splines in computer tomography.pdf:application/pdf},
}

@incollection{prautzsch_box_2002,
	title = {Box {Splines}},
	isbn = {0-444-51104-0},
	booktitle = {Handbook of {Computer} {Aided} {Geometric} {Design}},
	publisher = {North Holland; Illustrated Edition},
	author = {Prautzsch, Hartmut and Boehm, Wolfgang},
	month = mar,
	year = {2002},
	keywords = {Box Splines},
	file = {Prautzsch and Boehm - 2002 - Box Splines.pdf:/home/david/Zotero/storage/FJILGBCN/Prautzsch and Boehm - 2002 - Box Splines.pdf:application/pdf},
}

@article{ruijters_gpu_2012,
	title = {{GPU} {Prefilter} for {Accurate} {Cubic} {B}-spline {Interpolation}},
	volume = {55},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/bxq086},
	doi = {10.1093/comjnl/bxq086},
	language = {en},
	number = {1},
	urldate = {2021-02-24},
	journal = {The Computer Journal},
	author = {Ruijters, D. and Thevenaz, P.},
	month = jan,
	year = {2012},
	pages = {15--20},
	file = {Ruijters and Thevenaz - 2012 - GPU Prefilter for Accurate Cubic B-spline Interpol.pdf:/home/david/Zotero/storage/7V32IDUX/Ruijters and Thevenaz - 2012 - GPU Prefilter for Accurate Cubic B-spline Interpol.pdf:application/pdf},
}

@inproceedings{entezari_linear_2004,
	address = {Austin, TX, USA},
	title = {Linear and cubic box splines for the body centered cubic lattice},
	isbn = {978-0-7803-8788-1},
	url = {http://ieeexplore.ieee.org/document/1372174/},
	doi = {10.1109/VISUAL.2004.65},
	abstract = {In this paper we derive piecewise linear and piecewise cubic box spline reconstruction ﬁlters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction ﬁlters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these ﬁlters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar ﬁlters applied to data sampled on the Cartesian lattice.},
	language = {en},
	urldate = {2021-02-24},
	booktitle = {{IEEE} {Visualization} 2004},
	publisher = {IEEE Comput. Soc},
	author = {Entezari, A. and Dyer, R. and Moller, T.},
	year = {2004},
	pages = {11--18},
	file = {Entezari et al. - 2004 - Linear and cubic box splines for the body centered.pdf:/home/david/Zotero/storage/Q4MD9SQB/Entezari et al. - 2004 - Linear and cubic box splines for the body centered.pdf:application/pdf},
}

@article{horacsek_fast_2016,
	title = {Fast and exact evaluation of box splines via the {PP}-form},
	url = {http://arxiv.org/abs/1606.08910},
	abstract = {For the class of non-degenerate box splines, we prove that these box splines are piecewise polynomial. This is not a new result, it is in fact a well known and useful property of box splines. However, our proof is constructive, and the main result of this work is a corollary that follows from this proof, namely one that gives an explicit construction scheme for the polynomial pieces in the interior regions of any non-degenerate box spline.},
	language = {en},
	urldate = {2021-02-24},
	journal = {arXiv:1606.08910 [math]},
	author = {Horacsek, Joshua and Alim, Usman},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.08910},
	keywords = {Mathematics - Functional Analysis, Mathematics - Numerical Analysis},
	file = {Horacsek and Alim - 2016 - Fast and exact evaluation of box splines via the P.pdf:/home/david/Zotero/storage/FDPCAMML/Horacsek and Alim - 2016 - Fast and exact evaluation of box splines via the P.pdf:application/pdf},
}

@article{condat_three-directional_2006,
	title = {Three-directional box-splines: characterization and efficient evaluation},
	volume = {13},
	issn = {1070-9908},
	shorttitle = {Three-directional box-splines},
	url = {http://ieeexplore.ieee.org/document/1642713/},
	doi = {10.1109/LSP.2006.871852},
	abstract = {We propose a new characterization of three-directional box-splines, which are well adapted for interpolation and approximation on hexagonal lattices. Inspired by a construction already applied with success for exponential splines [1] and hex-splines [2], we characterize a box-spline as a convolution of a generating function, which is a Green function of the spline’s associated differential operator, and a discrete ﬁlter that plays the role of a localization operator. This process leads to an elegant analytical expression of three-directional box-splines. It also brings along a particularly efﬁcient implementation.},
	language = {en},
	number = {7},
	urldate = {2021-02-24},
	journal = {IEEE Signal Processing Letters},
	author = {Condat, L. and Van De Ville, D.},
	month = jul,
	year = {2006},
	pages = {417--420},
	file = {Condat and Van De Ville - 2006 - Three-directional box-splines characterization an.pdf:/home/david/Zotero/storage/JSMJQQMN/Condat and Van De Ville - 2006 - Three-directional box-splines characterization an.pdf:application/pdf},
}

@article{de_boor_evaluation_2000,
	title = {On the evaluation of box splines},
	language = {en},
	author = {de Boor, Carl},
	month = feb,
	year = {2000},
	pages = {19},
	file = {de Boor - 2000 - On the evaluation of box splines.pdf:/home/david/Zotero/storage/ZZ7I7GFD/de Boor - 2000 - On the evaluation of box splines.pdf:application/pdf},
}

@article{speleers_inner_2015,
	title = {Inner products of box splines and their derivatives},
	volume = {55},
	issn = {0006-3835, 1572-9125},
	url = {http://link.springer.com/10.1007/s10543-014-0513-1},
	doi = {10.1007/s10543-014-0513-1},
	abstract = {A simple and explicit expression is given for the inner product of (higher order) derivatives of multivariate box splines and their translates. We also show that the energy inner product related to a linear partial differential equation discretized with a set of shifted box splines can be interpreted as an evaluation of the differential operator applied to a higher order box spline.},
	language = {en},
	number = {2},
	urldate = {2021-02-24},
	journal = {BIT Numerical Mathematics},
	author = {Speleers, Hendrik},
	month = jun,
	year = {2015},
	pages = {559--567},
	file = {Speleers - 2015 - Inner products of box splines and their derivative.pdf:/home/david/Zotero/storage/KQNDLECX/Speleers - 2015 - Inner products of box splines and their derivative.pdf:application/pdf},
}

@book{hansen_discrete_2010,
	address = {Philadelphia},
	series = {Fundamentals of algorithms},
	title = {Discrete inverse problems: insight and algorithms},
	isbn = {978-0-89871-696-2},
	shorttitle = {Discrete inverse problems},
	language = {en},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Hansen, Per Christian},
	year = {2010},
	note = {OCLC: ocn469915410},
	keywords = {Inverse problems (Differential equations)},
	file = {Hansen - 2010 - Discrete inverse problems insight and algorithms.pdf:/home/david/Zotero/storage/6D4E4743/Hansen - 2010 - Discrete inverse problems insight and algorithms.pdf:application/pdf},
}

@book{rieder_keine_2003,
	address = {Wiesbaden},
	title = {Keine {Probleme} mit {Inversen} {Problemen}},
	isbn = {978-3-528-03198-5 978-3-322-80234-7},
	url = {http://link.springer.com/10.1007/978-3-322-80234-7},
	language = {de},
	urldate = {2021-03-04},
	publisher = {Vieweg+Teubner Verlag},
	author = {Rieder, Andreas},
	year = {2003},
	doi = {10.1007/978-3-322-80234-7},
	file = {Rieder - 2003 - Keine Probleme mit Inversen Problemen.pdf:/home/david/Zotero/storage/C2Y88G2D/Rieder - 2003 - Keine Probleme mit Inversen Problemen.pdf:text/html;Rieder - 2003 - Keine Probleme mit Inversen Problemen.pdf:/home/david/Zotero/storage/U4EAHJF9/Rieder - 2003 - Keine Probleme mit Inversen Problemen.pdf:application/pdf},
}

@article{entezari_practical_2008,
	title = {Practical {Box} {Splines} for {Reconstruction} on the {Body} {Centered} {Cubic} {Lattice}},
	volume = {14},
	issn = {1077-2626, 1941-0506, 2160-9306},
	url = {https://ieeexplore.ieee.org/document/4359498/},
	doi = {10.1109/TVCG.2007.70429},
	abstract = {We introduce a family of box splines for efficient, accurate, and smooth reconstruction of volumetric data sampled on the body-centered cubic (BCC) lattice, which is the favorable volumetric sampling pattern due to its optimal spectral sphere packing property. First, we construct a box spline based on the four principal directions of the BCC lattice that allows for a linear C0 reconstruction. Then, the design is extended for higher degrees of continuity. We derive the explicit piecewise polynomial representations of the C0 and C2 box splines that are useful for practical reconstruction applications. We further demonstrate that approximation in the shift-invariant space—generated by BCC-lattice shifts of these box splines—is twice as efficient as using the tensor-product B-spline solutions on the Cartesian lattice (with comparable smoothness and approximation order and with the same sampling density). Practical evidence is provided demonstrating that the BCC lattice not only is generally a more accurate sampling pattern, but also allows for extremely efficient reconstructions that outperform tensor-product Cartesian reconstructions.},
	language = {en},
	number = {2},
	urldate = {2021-03-05},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	author = {Entezari, Alireza and Van De Ville, Dimitri and Moller, Torsten},
	month = mar,
	year = {2008},
	pages = {313--328},
	file = {Entezari et al. - 2008 - Practical Box Splines for Reconstruction on the Bo.pdf:/home/david/Zotero/storage/FMXDXXTX/Entezari et al. - 2008 - Practical Box Splines for Reconstruction on the Bo.pdf:application/pdf},
}

@article{paleo_practical_2016,
	title = {A practical local tomography reconstruction algorithm based on known subregion},
	url = {http://arxiv.org/abs/1606.04940},
	abstract = {We propose a new method to reconstruct data acquired in a local tomography setup. This method uses an initial reconstruction and reﬁnes it by correcting the low frequency artifacts known as the cupping eﬀect. A basis of Gaussian functions is used to correct the initial reconstruction. The coeﬃcients of this basis are iteratively optimized under the constraint of a known subregion. Using a coarse basis reduces the degrees of freedom of the problem while actually correcting the cupping eﬀect. Simulations show that the known region constraint yields an unbiased reconstruction, in accordance to uniqueness theorems stated in local tomography.},
	language = {en},
	urldate = {2021-03-10},
	journal = {arXiv:1606.04940 [physics]},
	author = {Paleo, Pierre and Desvignes, Michel and Mirone, Alessandro},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.04940},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Physics - Medical Physics},
	file = {Paleo et al. - 2016 - A practical local tomography reconstruction algori.pdf:/home/david/Zotero/storage/X5MLXQN7/Paleo et al. - 2016 - A practical local tomography reconstruction algori.pdf:application/pdf},
}

@inproceedings{zhou_blob-based_2008,
	address = {San Diego, CA},
	title = {A blob-based tomographic reconstruction of {3D} coronary trees from rotational x-ray angiography},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.769478},
	doi = {10.1117/12.769478},
	abstract = {A method is proposed for a 3D reconstruction of coronary networks from rotational projections that departs from motion-compensated approaches. It deals with multiple views extracted from a time-stamped image sequence through ECG gating. This statistics-based vessel reconstruction method relies on a new imaging model by considering both the eﬀect of background tissues and the image representation using spherically-symmetric basis functions, also called ’blobs’ . These blobs have a closed analytical expression for the X-ray transform, which makes easier to compute a cone-beam projection than a voxel-based description. A Bayesian maximum a posteriori (MAP) estimation is used with a Poisson distributed projection data instead of the Gaussian approximation often used in tomography reconstruction. A heavy-tailed distribution is proposed as image prior to take into account the sparse nature of the object of interest. The optimization is performed by an expectationmaximization like (EM) block iterative algorithm which oﬀers a fast convergence and a sound introduction of the non-negativity constraint for vessel attenuation coeﬃcients. Simulations are performed using a model of coronary tree extracted from multidetector CT scanner and a performance study is conducted. They point out that, even with severe angular undersampling (6 projections over 110 degrees for instance) and without introducing a prior model of the object, signiﬁcant results can be achieved.},
	language = {en},
	urldate = {2021-03-10},
	author = {Zhou, Jian and Bousse, Alexandre and Yang, Guanyu and Bellanger, Jean-Jacques and Luo, Limin and Toumoulin, Christine and Coatrieux, Jean-Louis},
	editor = {Hsieh, Jiang and Samei, Ehsan},
	month = mar,
	year = {2008},
	pages = {69132N},
	file = {Zhou et al. - 2008 - A blob-based tomographic reconstruction of 3D coro.pdf:/home/david/Zotero/storage/C7TUBHKX/Zhou et al. - 2008 - A blob-based tomographic reconstruction of 3D coro.pdf:application/pdf},
}

@article{castrillo_blob-enhanced_2016,
	title = {Blob-enhanced reconstruction technique},
	volume = {27},
	issn = {0957-0233, 1361-6501},
	url = {https://iopscience.iop.org/article/10.1088/0957-0233/27/9/094011},
	doi = {10.1088/0957-0233/27/9/094011},
	abstract = {A method to enhance the quality of the tomographic reconstruction and, consequently, the 3D velocity measurement accuracy, is presented. The technique is based on integrating information on the objects to be reconstructed within the algebraic reconstruction process. A first guess intensity distribution is produced with a standard algebraic method, then the distribution is rebuilt as a sum of Gaussian blobs, based on location, intensity and size of agglomerates of light intensity surrounding local maxima. The blobs substitution regularizes the particle shape allowing a reduction of the particles discretization errors and of their elongation in the depth direction. The performances of the blob-enhanced reconstruction technique (BERT) are assessed with a 3D synthetic experiment. The results have been compared with those obtained by applying the standard camera simultaneous multiplicative reconstruction technique (CSMART) to the same volume. Several blob-enhanced reconstruction processes, both substituting the blobs at the end of the CSMART algorithm and during the iterations (i.e. using the blob-enhanced reconstruction as predictor for the following iterations), have been tested. The results confirm the enhancement in the velocity measurements accuracy, demonstrating a reduction of the bias error due to the ghost particles. The improvement is more remarkable at the largest tested seeding densities. Additionally, using the blobs distributions as a predictor enables further improvement of the convergence of the reconstruction algorithm, with the improvement being more considerable when substituting the blobs more than once during the process. The BERT process is also applied to multi resolution (MR) CSMART reconstructions, permitting simultaneously to achieve remarkable improvements in the flow field measurements and to benefit from the reduction in computational time due to the MR approach. Finally, BERT is also tested on experimental data, obtaining an increase of the signal-to-noise ratio in the reconstructed flow field and a higher value of the correlation factor in the velocity measurements with respect to the volume to which the particles are not replaced.},
	language = {en},
	number = {9},
	urldate = {2021-03-10},
	journal = {Measurement Science and Technology},
	author = {Castrillo, Giusy and Cafiero, Gioacchino and Discetti, Stefano and Astarita, Tommaso},
	month = sep,
	year = {2016},
	pages = {094011},
	file = {Castrillo et al. - 2016 - Blob-enhanced reconstruction technique.pdf:/home/david/Zotero/storage/ZC3AVLSH/Castrillo et al. - 2016 - Blob-enhanced reconstruction technique.pdf:application/pdf},
}

@article{herman_basis_2015,
	title = {Basis {Functions} in {Image} {Reconstruction} {From} {Projections}: {A} {Tutorial} {Introduction}},
	volume = {16},
	issn = {1557-2064, 1557-2072},
	shorttitle = {Basis {Functions} in {Image} {Reconstruction} {From} {Projections}},
	url = {http://link.springer.com/10.1007/s11220-015-0107-2},
	doi = {10.1007/s11220-015-0107-2},
	abstract = {The series expansion approaches to image reconstruction from projections assume that the object to be reconstructed can be represented as a linear combination of ﬁxed basis functions and the task of the reconstruction algorithm is to estimate the coefﬁcients in such a linear combination based on the measured projection data. It is demonstrated that using spherically symmetric basis functions (blobs), instead of ones based on the more traditional pixels, yields superior reconstructions of medically relevant objects. The demonstration uses simulated computerized tomography projection data of head cross-sections and the series expansion method ART for the reconstruction. In addition to showing the results of one anecdotal example, the relative efﬁcacy of using pixel and blob basis functions in image reconstruction from projections is also evaluated using a statistical hypothesis testing based task oriented comparison methodology. The superiority of the efﬁcacy of blob basis functions over that of pixel basis function is found to be statistically signiﬁcant.},
	language = {en},
	number = {1},
	urldate = {2021-03-10},
	journal = {Sensing and Imaging},
	author = {Herman, Gabor T.},
	month = dec,
	year = {2015},
	keywords = {blobs},
	pages = {6},
	file = {Herman - 2015 - Basis Functions in Image Reconstruction From Proje.pdf:/home/david/Zotero/storage/CRBR5QWI/Herman - 2015 - Basis Functions in Image Reconstruction From Proje.pdf:application/pdf},
}

@article{jacobs_iterative_nodate,
	title = {Iterative {Image} {Reconstruction} {From} {Projections} {Based} {On} {Generalised} {Kaiser}-{Bessel} {Window} {Functions}},
	abstract = {Tomographic images are calculated from data provided by a scanner. The reconstruction algorithms used for this purpose are either analytical or iterative in nature. The paper focuses on an iterative algorithm called the row-action maximum-likelihood algorithm, and on transmission tomography. Iterative algorithms approximate the image as a linear combination of a limited set of basis functions. The paper introduces a new set of basis functions, called blobs, into the field of process tomography. It also presents preliminary results of a study which evaluates the advantage of using blobs, instead of pixels, for different amounts of available data and different noise levels. The results clearly show that the use of blobs is also beneficial for process tomography.},
	language = {en},
	author = {Jacobs, Filip and Lemahieu, Ignace},
	pages = {7},
	file = {Jacobs and Lemahieu - Iterative Image Reconstruction From Projections Ba.pdf:/home/david/Zotero/storage/2P5QZHG3/Jacobs and Lemahieu - Iterative Image Reconstruction From Projections Ba.pdf:application/pdf},
}

@article{lewitt_alternatives_1992,
	title = {Alternatives to voxels for image representation in iterative reconstruction algorithms},
	volume = {37},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/0031-9155/37/3/015},
	doi = {10.1088/0031-9155/37/3/015},
	abstract = {Spherically symmetric volume elements are alternatives to the more conventional voxels far the Construction o f volume images in the computer. The image representation, and the calculation of projections of it, are essential components of iterative algorithms for image reconstmction from projenion data. A two-parameter family of spherical volume elements is described that allows control of the smoothness properties of the represented image, whereas conventional voxek are discontinuous. The rotational symmetry of the spherical elements leads to efficient calculation of projections of the represented image, as required in iterative reconstruction algorithms. Far volume elements whose shape is ellipsoidal (rather than spherical) it is shown that efficient calculation of the projections is also possible by means of an image space transformation.},
	language = {en},
	number = {3},
	urldate = {2021-03-10},
	journal = {Physics in Medicine and Biology},
	author = {Lewitt, R M},
	month = mar,
	year = {1992},
	pages = {705--716},
	file = {Lewitt - 1992 - Alternatives to voxels for image representation in.pdf:/home/david/Zotero/storage/YXG4DKA2/Lewitt - 1992 - Alternatives to voxels for image representation in.pdf:application/pdf},
}

@article{matej_efficient_1995,
	title = {Efficient {3D} grids for image reconstruction using spherically-symmetric volume elements},
	volume = {42},
	issn = {00189499},
	url = {http://ieeexplore.ieee.org/document/467854/},
	doi = {10.1109/23.467854},
	language = {en},
	number = {4},
	urldate = {2021-03-10},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Matej, S. and Lewitt, R.M.},
	month = aug,
	year = {1995},
	pages = {1361--1370},
	file = {Matej and Lewitt - 1995 - Efficient 3D grids for image reconstruction using .pdf:/home/david/Zotero/storage/YUQSMM4P/Matej and Lewitt - 1995 - Efficient 3D grids for image reconstruction using .pdf:application/pdf},
}

@article{matej_practical_1996,
	title = {Practical considerations for 3-{D} image reconstruction using spherically symmetric volume elements},
	volume = {15},
	issn = {02780062},
	url = {http://ieeexplore.ieee.org/document/481442/},
	doi = {10.1109/42.481442},
	abstract = {Spherically symmetric volume elements with smooth tapering of the values near their boundaries are alternatives to the more conventional voxels for the construction of volume images in the computer. Their use, instead of voxels, introduces additional parameters which enable the user to control the shape of the volume element (blob) and consequently to control the characteristics of the images produced by iterative methods for reconstruction from projection data. For images composed of blobs, efficient algorithms have been designed €or the projection and discrete back-projection operations, which are the crucial parts of iterative reconstruction methods. We have investigated the relationship between the values of the blob parameters and the properties of images represented by the blobs. Experiments show that using blobs in iterative reconstruction methods leads to substantial improvement in the reconstruction performance, based on visual quality and on quantitative measures, in comparison with the voxel case. The images reconstructed using appropriately chosen blobs are characterized by less image noise for both noiseless data and noisy data, without loss of image resolution.},
	language = {en},
	number = {1},
	urldate = {2021-03-10},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Matej, S. and Lewitt, R.M.},
	month = feb,
	year = {1996},
	pages = {68--78},
	file = {Matej and Lewitt - 1996 - Practical considerations for 3-D image reconstruct.pdf:/home/david/Zotero/storage/497ZYSHG/Matej and Lewitt - 1996 - Practical considerations for 3-D image reconstruct.pdf:application/pdf},
}

@article{bippus_projector_2011,
	title = {Projector and {Backprojector} for {Iterative} {CT} {Reconstruction} with {Blobs} using {CUDA}},
	abstract = {Using blobs allows modeling the CT system’s geometry more correctly within an iterative reconstruction framework. However their application comes with an increased computational demand. This led us to use blobs for image representation and a dedicated GPU hardware implementation to counteract their computational demand. Making extensive use of the texture interpolation capabilities of CUDA and implementing an asymmetric projector/backprojector pair we achieve reasonable processing times and good system modeling at the same time.},
	language = {en},
	author = {Bippus, Rolf-Dieter and Köhler, Thomas and Bergner, Frank and Brendel, Bernhard and Hansis, Eberhard and Proksa, Roland},
	year = {2011},
	pages = {4},
	file = {Bippus et al. - 2011 - Projector and Backprojector for Iterative CT Recon.pdf:/home/david/Zotero/storage/KEA2CVT8/Bippus et al. - 2011 - Projector and Backprojector for Iterative CT Recon.pdf:application/pdf},
}

@inproceedings{popescu_ray_2004,
	address = {Rome, Italy},
	title = {Ray tracing through a grid of blobs},
	volume = {6},
	isbn = {978-0-7803-8700-3},
	url = {http://ieeexplore.ieee.org/document/1466750/},
	doi = {10.1109/NSSMIC.2004.1466750},
	abstract = {In this paper we describe two ray tracing algorithms for images represented using spherically symmetric basis functions (blobs) on regular grids. The method presented here allows more realistic modeling of the forward projection by considering tube shaped kernels, rather than simple lines. Each kernel is a function of the radial distance r from its center and can vary with the position l along the projection line. The forward projections are computed by convolutions of the kernel with the blob line integrals. Both ray tracing procedures presented incrementally compute the square distance r2 for each visited blob enabling the appropriate resolution kernel to be used. The second variant also computes the l coordinate along the line of response axis allowing for longitudinal variations of the resolution kernel to be considered as well as time-of-ﬂight (TOF) modeling.},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {{IEEE} {Symposium} {Conference} {Record} {Nuclear} {Science} 2004.},
	publisher = {IEEE},
	author = {Popescu, L.M. and Lewitt, R.M.},
	year = {2004},
	pages = {3983--3986},
	file = {Popescu and Lewitt - 2004 - Ray tracing through a grid of blobs.pdf:/home/david/Zotero/storage/SZY9DRKS/Popescu and Lewitt - 2004 - Ray tracing through a grid of blobs.pdf:application/pdf},
}

@inproceedings{momey_new_2011,
	address = {Valencia, Spain},
	title = {A new representation and projection model for tomography, based on separable {B}-splines},
	isbn = {978-1-4673-0120-6 978-1-4673-0118-3 978-1-4673-0119-0},
	url = {http://ieeexplore.ieee.org/document/6152700/},
	doi = {10.1109/NSSMIC.2011.6152700},
	abstract = {Data modelization in tomography is a key point for iterative reconstruction. The design of the projector, i.e. the numerical model of projection, is mostly inﬂuenced by the representation of the object of interest, decomposed on a discrete basis of functions.},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {2011 {IEEE} {Nuclear} {Science} {Symposium} {Conference} {Record}},
	publisher = {IEEE},
	author = {Momey, Fabien and Denis, Loic and Mennessier, Catherine and Thiebaut, Eric and Becker, Jean-Marie and Desbat, Laurent},
	month = oct,
	year = {2011},
	pages = {2602--2609},
	file = {Momey et al. - 2011 - A new representation and projection model for tomo.pdf:/home/david/Zotero/storage/GFS8TT3D/Momey et al. - 2011 - A new representation and projection model for tomo.pdf:application/pdf},
}

@inproceedings{zhang_box_2019,
	address = {Venice, Italy},
	title = {Box {Spline} {Projection} in {Non}-{Parallel} {Geometry}},
	isbn = {978-1-5386-3641-1},
	url = {https://ieeexplore.ieee.org/document/8759327/},
	doi = {10.1109/ISBI.2019.8759327},
	abstract = {The pixel- and voxel-basis are common choices for image discretization in the context of computed tomography (CT). They can also be viewed as ﬁrst-order box splines – a class of functions with closed-form X-ray and Radon transforms that can be computed efﬁciently. In this paper we derive a method for exact projection of box splines in a non-parallel geometry that can be used in fan-beam and cone-beam tomographic image reconstruction algorithms. We also provide efﬁcient computational procedures for evaluation of the basis function in the projection domain.},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {2019 {IEEE} 16th {International} {Symposium} on {Biomedical} {Imaging} ({ISBI} 2019)},
	publisher = {IEEE},
	author = {Zhang, Kai and Entezari, Alireza},
	month = apr,
	year = {2019},
	pages = {1844--1847},
	file = {Zhang and Entezari - 2019 - Box Spline Projection in Non-Parallel Geometry.pdf:/home/david/Zotero/storage/L2VHGIHT/Zhang and Entezari - 2019 - Box Spline Projection in Non-Parallel Geometry.pdf:application/pdf},
}

@inproceedings{lasser_elsa_2019,
	address = {Philadelphia, United States},
	title = {elsa - an elegant framework for tomographic reconstruction},
	isbn = {978-1-5106-2837-3 978-1-5106-2838-0},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11072/2534833/elsa---an-elegant-framework-for-tomographic-reconstruction/10.1117/12.2534833.full},
	doi = {10.1117/12.2534833},
	abstract = {Software for tomographic reconstruction has been around for decades now. So why yet another software framework for tomographic reconstruction? Because we needed a ﬂexible, operator- and optimization-based framework in C++ for our own target applications, we developed our own some years ago. As our framework has been applied to many tomographic problems by now, ranging from optical tomography, lightﬁeld tomography, SPECT, to various X-ray based imaging modalities (absorption contrast, differential phase contrast and anisotropic dark-ﬁeld contrast), we decided to open source a modernized version of it. The framework elsa is written in platform-independent modern C++17 using the CMake build system, with high unit-test coverage and continuous integration to ascertain reliability and correctness, as well as a Python interface for easy and rapid prototyping. Our intent in open sourcing the framework and presenting it here is three-fold, ﬁrst for easier reproducibility of our own research, second for use in teaching, and last but not least, in the hopes that some of you also ﬁnd some usefulness in it for your own tasks.},
	language = {en},
	urldate = {2021-04-13},
	booktitle = {15th {International} {Meeting} on {Fully} {Three}-{Dimensional} {Image} {Reconstruction} in {Radiology} and {Nuclear} {Medicine}},
	publisher = {SPIE},
	author = {Lasser, Tobias and Hornung, Maximilian and Frank, David},
	editor = {Matej, Samuel and Metzler, Scott D.},
	month = may,
	year = {2019},
	pages = {69},
	file = {Lasser et al. - 2019 - elsa - an elegant framework for tomographic recons.pdf:/home/david/Zotero/storage/KBNCTUTY/Lasser et al. - 2019 - elsa - an elegant framework for tomographic recons.pdf:application/pdf},
}

@article{kim_optimized_2016,
	title = {Optimized first-order methods for smooth convex minimization},
	volume = {159},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/s10107-015-0949-3},
	doi = {10.1007/s10107-015-0949-3},
	abstract = {We introduce new optimized ﬁrst-order methods for smooth unconstrained convex minimization. Drori and Teboulle (Math Program 145(1–2):451–482, 2014. doi:10.1007/s10107-013-0653-0) recently described a numerical method for computing the N -iteration optimal step coefﬁcients in a class of ﬁrst-order algorithms that includes gradient methods, heavy-ball methods (Polyak in USSR Comput Math Math Phys 4(5):1–17, 1964. doi:10.1016/0041-5553(64)90137-5), and Nesterov’s fast gradient methods (Nesterov in Sov Math Dokl 27(2):372–376, 1983; Math Program 103(1):127–152, 2005. doi:10.1007/s10107-004-0552-5). However, the numerical method in Drori and Teboulle (2014) is computationally expensive for large N , and the corresponding numerically optimized ﬁrst-order algorithm in Drori and Teboulle (2014) requires impractical memory and computation for large-scale optimization problems. In this paper, we propose optimized ﬁrst-order algorithms that achieve a convergence bound that is two times smaller than for Nesterov’s fast gradient methods; our bound is found analytically and reﬁnes the numerical bound in Drori and Teboulle (2014). Furthermore, the proposed optimized ﬁrst-order methods have efﬁcient forms that are remarkably similar to Nesterov’s fast gradient methods.},
	language = {en},
	number = {1-2},
	urldate = {2021-04-15},
	journal = {Mathematical Programming},
	author = {Kim, Donghwan and Fessler, Jeffrey A.},
	month = sep,
	year = {2016},
	pages = {81--107},
	file = {Kim and Fessler - 2016 - Optimized first-order methods for smooth convex mi.pdf:/home/david/Zotero/storage/REIHELDD/Kim and Fessler - 2016 - Optimized first-order methods for smooth convex mi.pdf:application/pdf;Kim and Fessler - 2016 - Optimized first-order methods for smooth convex mi.pdf:/home/david/Zotero/storage/WJXYZPC5/Kim and Fessler - 2016 - Optimized first-order methods for smooth convex mi.pdf:application/pdf},
}

@article{wang_image_2011,
	title = {Image representation by blob and its application in {CT} reconstruction from few projections},
	doi = {10.1109/NSSMIC.2011.6153755},
	abstract = {The localized radial symmetric function, or blob, is an ideal alternative to the pixel basis for X-ray computed tomography (CT) image reconstruction. In this paper we develop image representation models using blob, and propose reconstruction methods for few projections data. The image is represented in a shift invariant space generated by a Gaussian blob or a multiscale blob system of different frequency selectivity, and the reconstruction is done through minimizing the Total Variation or the 1 norm of blob coefficients. Some 2D numerical results are presented, where we use GPU platform for accelerating the X-ray projection and back-projection, the interpolation and the gradient computations.},
	author = {Wang, Han and Desbat, Laurent and Legoupil, Samuel},
	month = jul,
	year = {2011},
}

@article{briand_theory_2018,
	title = {Theory and {Practice} of {Image} {B}-{Spline} {Interpolation}},
	volume = {8},
	url = {https://doi.org/10.5201%2Fipol.2018.221},
	doi = {10.5201/ipol.2018.221},
	journal = {Image Processing On Line},
	author = {Briand, Thibaud and Monasse, Pascal},
	month = jul,
	year = {2018},
	note = {Publisher: Image Processing On Line},
	pages = {99--141},
	file = {Briand and Monasse - 2018 - Theory and Practice of Image B-Spline Interpolatio.pdf:/home/david/Zotero/storage/R3AH248T/Briand and Monasse - 2018 - Theory and Practice of Image B-Spline Interpolatio.pdf:application/pdf},
}

@article{li_optimization_2018,
	title = {Optimization for {Blob}-{Based} {Image} {Reconstruction} {With} {Generalized} {Kaiser}–{Bessel} {Basis} {Functions}},
	volume = {4},
	url = {https://doi.org/10.1109%2Ftci.2018.2796302},
	doi = {10.1109/tci.2018.2796302},
	number = {2},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Li, Yusheng},
	month = jun,
	year = {2018},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	keywords = {Image reconstruction, blob, body-centered cubic (BCC) lattice, face-centered cubic (FCC) lattice, FCC, Image quality, Kaiser–Bessel radial basis function, lattice, Lattices, optimization, Optimization, simple cubic (SC) lattice, tomographic reconstruction, Tomography},
	pages = {257--270},
	file = {Li - 2018 - Optimization for Blob-Based Image Reconstruction W.pdf:/home/david/Zotero/storage/LK6X4YEC/Li - 2018 - Optimization for Blob-Based Image Reconstruction W.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/david/Zotero/storage/GFPKWTXR/Li - 2018 - Optimization for Blob-Based Image Reconstruction W.pdf:application/pdf},
}

@article{nilchian_optimized_2015,
	title = {Optimized {Kaiser}–{Bessel} {Window} {Functions} for {Computed} {Tomography}},
	volume = {24},
	url = {https://doi.org/10.1109%2Ftip.2015.2451955},
	doi = {10.1109/tip.2015.2451955},
	number = {11},
	journal = {IEEE Transactions on Image Processing},
	author = {Nilchian, Masih and Ward, John Paul and Vonesch, Cedric and Unser, Michael},
	month = nov,
	year = {2015},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {3826--3833},
	file = {Nilchian et al. - 2015 - Optimized Kaiser–Bessel Window Functions for Compu.pdf:/home/david/Zotero/storage/AGAU67MZ/Nilchian et al. - 2015 - Optimized Kaiser–Bessel Window Functions for Compu.pdf:application/pdf},
}

@article{pendrill_full_2021,
	title = {Full {Issue} {Download} {Vol}. 13 {No}. 1 2021 {The} {Importance} of the {Measurement} {Infrastructure} in {Economic} {Recovery} from the {COVID}-19 {Pandemic} {Richard} {J}. {C}. {Brown} , {Fiona} {Auty}, {Eugenio} {Renedo}, {Mike} {King} {NCSLI} {Measure} {\textbar} {Vol}. 13 {No}. 1 (2021) {\textbar} doi.org/10.51843/measure.13.1.1 {Publisher} {NCSL} {International} {\textbar} {Published} {February} 2021 {\textbar} {Pages} 18-21 {Abstract}: {This} paper describes the many, evidenced-based benefits to the economy of a well-developed measurement infrastructure. {In} particular, it explains how assuring confidence in measurement may be used to accelerate economic recovery from the {COVID}-19 pandemic including in emerging sectors such as the digital economy. {Recommendations} are made for providing near term support for national economic recovery whilst also demonstrating the advantages of sustained development of the measurement infrastructure in the medium-term to maximize the potential of future innovative and disruptive technologies. {These} recommendations, whilst focused on consideration of the {UK}, should apply globally. {References}: [1] {G}. {Tassey}, "{Underinvestment} in public good technologies," {J} {Technol}. {Transfer}, {Vol}. 30, pp. 89-113, 2004. https://doi.org/10.1007/s10961-004-4360-0 [2] {M}. {King}, and {E}. {Renedo}, "{Achieving} the 2.4\% {GDP} target: {The} role of measurement in increasing investment in {R}\&{D} and innovation," {NPL} {Report} {IEA} 3, {NPL}, {Teddington}, {UK}, {March} 2020. [3] {M}. {King} and {G}. {Tellett}, "{The} {National} {Measurement} {System}: {A} {Customer} {Survey} for {Three} of the {Core} {Labs} in the {National} {Measurement} {System}," {NMS} {Customer} {Survey} {Report} 2018, {NPL} {Teddington}, {UK}, {April} 2020 [4] {H}. {Kunzmann}, {T}. {Pfeifer}, {R}. {Schmitt}, {H}. {Schwenke}, and {A}.{Weckenmann}, "{Productive} metrology-adding value to manufacture," {CIRP} {Annals}, vol. 54, pp. 155-168, 2005. https://doi.org/10.1016/{S0007}-8506(07)60024-9 [5] {N}. {G}. {Orji}, {R}. {G}. {Dixson}, {A}. {Cordes}, {B}. {D}. {Bunday}, and {J}. {A}. {Allgair}, "{Measurement} traceability and quality assurance in a nanomanufacturing environment," {Instrumentation}, {Metrology}, and {Standards} for {Nanomanufacturing} {III}, {Proceedings} {Vol}. 7405, 740505, {August} 2009. https://doi.org/10.1117/12.826606 [6] {Belmana}, {Analysis} for {Policy} "{Public} {Support} for {Innovation} and {Business} {Outcomes}," {Belmana}: {London}, {UK}, 2020. [7] {R}. {Hawkins}, {Standards}, systems of innovation and policy in {Handbook} of {Innovation} and {Standards}. {Cheltenham}, {UK}: {Edward} {Elgar}, 2019. [8] {N}. {Nwaigbo}, and {M}. {King}, "{Evaluating} the {Impact} of the {NMS} {Consultancy} {Projects} on {Supported} {Firms} ({Working} {Paper})" {NPL}, {Teddington}, {UK}, 2020. [9] {M}. {King}, {R}. {Lambert}, and {P}. {Temple}, {Measurement}, standards and productivity spillovers in {Handbook} of {Innovation} and {Standards}. {Cheltenham}, {UK}: {Edward} {Elgar}, 2017, p. 162. https://doi.org/10.4337/9781783470082.00016 [10] {A}. {Font}, {K}. de {Hoogh}, {M}. {Leal}-{Sanchez}, {D}. {C}. {Ashworth}, {R}. {J}. {C}. {Brown}, {A}. {L}. {Hansell}, and {G}. {W}. {Fuller}, "{Using} metal ratios to detect emissions from municipal waste incinerators in ambient air pollution data," {Atmos}. {Environ}., vol. 113, pp. 177-186, {July} 2015. https://doi.org/10.1016/j.atmosenv.2015.05.002 [11] {S}. {Giannis}, {M}. {R}. {L}. {Gower}, {G}. {D}. {Sims}, {G}. {Pask}, and {G}. {Edwards}, "{Increasing} {UK} competitiveness by enhancing the composite materials regulatory infrastructure," {NPL} {Report} {MAT} 90, {NPL}, {Teddington}, {UK}, {October} 2019. [12] {HM} {Government}, {UK} {Research} and {Development} {Roadmap}, {BEIS}, {London}, {July} 2020. [13] {M}. {R}. {Mehra}, {S}. {S}. {Desai}, {F}. {Ruschitzka}, and {A}. {N}. {Patel}, "{Hydroxychloroquine} or chloroquine with or without a macrolide for treatment of {COVID}-19: a multinational registry analysis," {Lancet}, 2020, https://doi.org/10.1016/{S0140}-6736(20)31180-6 ({Print}: {ISSN} 1931-5775) ({Online}: {ISSN} 2381-0580) ©2021 {NCSL} {International} {Smart} {Power} {Supply} {Calibration} {System} {Iraj} {Vasaeli} , {Brandon} {Umansky} {NCSLI} {Measure} {\textbar} {Vol}. 13 {No}. 1 (2021) {\textbar} doi.org/10.51843/measure.13.1.2 {Publisher}: {NCSL} {International} {\textbar} {Published} {February} 2021 {\textbar} {Pages} 22-27 {Abstract}: {This} paper details the development of an automated procedure to conduct calibrations of power supplies at {Jet} {Propulsion} {Laboratory}, {California} {Institute} of {Technology} ({JPL}). {The} fundamentals of power supply calibrations are given, and discussion on the method by which this custom software handles that calibration. {Additionally}, this technique provides real time uncertainty quantification of the calibrations. {This} automated system has demonstrated a time savings over existing automated techniques in use today. {References}: [1] {Keysight}, "{Low}-{Profile} {Modular} {Power} {System} {Series} {N6700} {Service} {Guide}", {Part} {Number}: 5969 2938, {Edition} 7, {January} 2015. [2] {B}. {N}. {Taylor} and {C}. {E}. {Kuyatt}, "{Guidelines} for {Evaluating} and {Expressing} the {Uncertainty} of {NIST} {Measurement} {Results}", {NIST} {Technical} {Note} 1297, 1994. https://doi.org/10.6028/{NIST}.{TN}.1297 [3] {JCGM}, "{Evaluation} of measurement data - {Guide} to the expression of uncertainty in measurement," first edition ({GUM} 1995 with minor corrections)," {JCGM} 100, 2008. ({Print}: {ISSN} 1931-5775) ({Online}: {ISSN} 2381-0580) © 2021 {NCSL} {International} {Computer} {Aided} {Verification} of {Voltage} {Dips} and {Short} {Interruption} {Generators} for {Electromagnetic} {Compatibility} {Immunity} {Test} in {Accordance} with {IEC} 61000-4-11: 2004 + {AMD}: 2017 {Hau} {Wah} {Lai} , {Cho} {Man} {Tsui} , {Hing} {Wah} {Li} {NCSLI} {Measure} {\textbar} {Vol}. 13 {No}. 1 (2021) {\textbar} doi.org/10.51843/measure.13.1.3 {Publisher}: {NCSL} {International} {\textbar} {Published} {February} 2021 {\textbar} {Pages} 28-39 {Abstract}: {This} paper describes a procedure and a computer-aided system developed by the {Standards} and {Calibration} {Laboratory} ({SCL}) for verification of voltage dip and short interruption generators in accordance with the international standard {IEC} 61000-4-11:2004+{AMD1}:2017. {The} verification is done by calibrating the specified parameters and comparing with the requirements stated in the standard. {The} parameters that should be calibrated are the ratios of the residual voltages to the rated voltage, the accuracy of the phase angle at switching, and the rise time, fall time, overshoot and undershoot of the switching waveform. {A} specially built adapter is used to convert the high voltage output waveforms of the generators to lower level signals to be acquired by a digital oscilloscope. {The} other circuits required for the testing are also provided. {In} addition, the paper discusses the uncertainty evaluations for the measured parameters. {References}: [1] {T}. {Williams}, and {K}. {Armstrong}, "{EMC} for {Systems} and {Installations} {Part} 6 - {Low}-{Frequency} {Magnetics} {Fields} ({Emissions} and {Immunity}) {Mains} {Dips}, {Dropouts}, {Interruptions}, {Sags}, {Brownouts} and {Swells}," {EMC} {Compliance} {Journal}, {August} 2000. [2] {M}.{I}. {Montrose}, and {E}. {M}. {Nakauchi}, {Testing} for {EMC} {Compliance}: {Approaches} and {Techniques}, {Wiley} {Interscience}, 2004. https://doi.org/10.1002/{047164465X} [3] {International} {Standard} {IEC} 61000-4-11:2004+{AMD1}:2017:{Electromagnetic} {Compatibility} ({EMC}) {Part} 4-11: {Testing} and measurement techniques - {Voltage} dips, short interruptions and voltage variations immunity tests. [4] {Evaluation} of measurement data - {Guide} to the expression of uncertainty in measurement, {First} {Edition} {JCGM} 100:2008. ({Print}: {ISSN} 1931-5775) ({Online}: {ISSN} 2381-0580) © 2021 {NCSL} {International} {Validation} of the {Photometric} {Method} {Used} for {Micropipette} {Calibration} {Elsa} {Batista} , {Isabel} {Godinho}, {George} {Rodrigues}, {Doreen} {Rumery} {NCSLI} {Measure} {\textbar} {Vol}. 13 {No}. 1 (2021) {\textbar} doi.org/10.51843/measure.13.1.4 {Publisher}: {NCSL} {International} {\textbar} {Published} {February} 2021 {\textbar} {Pages} 40-45 {Abstract}: {There} are two methods generally used for calibration of micropipettes: the gravimetric method described in {ISO} 8655-6:2002 and the photometric method described in {ISO} 8655-7:2005. {In} order to validate the photometric method, several micropipettes of different capacities from 0.1 µ{L} to 1000 µ{L} were calibrated using both methods (gravimetric and photometric) in two different laboratories, {IPQ} ({Portuguese} {Institute} for {Quality}) and {Artel}. {These} tests were performed by six different operators. {The} uncertainty for both methods was determined and it was verified that the uncertainty component that has a higher contribution to the final uncertainty budget depends on the volume delivered. {In} the photometric method for small volumes, the repeatability of the pipette is the largest uncertainty component, but for volumes, larger than 100 µ{L}, the photometric instrument is the most significant source of uncertainty. {Based} on all the results obtained with this study, one may consider the photometric method validated. {References}: [1] {ISO} 8655-1/2/6/7, {Piston}-operated volumetric apparatus, 2002. [2] {BIPM}, {International} {Vocabulary} of {Metrology}, 3rd edition, {JCGM} 200:2012. [3] {George} {Rodrigues}, {Bias} and transferability in standards methods of pipette calibration, {Artel}, {June} 2003. [4] {Taylor}, et.al. {The} definition of primary method of measurement ({PMM}) of the 'highest metrological quality': a challenge in understanding and communication, {Accred}. {Qual}.{Assur} (2001) 6:103-106. https://doi.org/10.1007/{PL00010444} [5] {EURAMET} project 1353, {Volume} comparison on {Calibration} of micropipettes - {Gravimetric} and photometric methods. [6] {ASTM} {E542}: {Standard} {Practice} for {Calibration} of laboratory {Volumetric} {Apparatus}, 2000. [7] {ISO} 4787; {Laboratory} glassware - {Volumetric} glassware - {Methods} for use and testing of capacity, 2010 . [8] {ISO} 13528:2005 - {Statistical} methods used in proficiency testing by interlaboratory comparisons. [9] {BIPM} et al, {Guide} to the {Expression} of {Uncertainty} in {Measurement} ({GUM}), 2nd ed., {International} {Organization} for {Standardization}, {Genève}, 1995. [10] {EURAMET} guide, cg 19, - {Guidelines} on the determination of uncertainty in gravimetric volume calibration, version 3.0, 2012. [11] {E}. {Batista} et all, {A} {Study} of {Factors} that {Influence} {Micropipette} {Calibrations}, {Measure} {Vol}. 10 {No}. 1, 2015 https://doi.org/10.1080/19315775.2015.11721717 [12] www.{BIPM}.org. ({Print}: {ISSN} 1931-5775) ({Online}: {ISSN} 2381-0580) © 2021 {NCSL} {International} {Material} {Flow} {Rate} {Estimation} in {Material} {Extrusion} {Additive} {Manufacturing} {G}. {P}. {Greeff} {NCSLI} {Measure} {\textbar} {Vol}. 13 {No}. 1 (2021) {\textbar} doi.org/10.51843/measure.13.1.5 {Publisher}: {NCSL} {International} {\textbar} {Published} {February} 2021 {\textbar} {Pages} 46-56 {Abstract}: {The} additive manufacturing of products promises exciting possibilities. {Measurement} methodologies, which measure an in-process dataset of these products and interpret the results, are essential. {However}, before developing such a level of quality assurance several in-process measurands must be realized. {One} of these is the material flow rate, or rate of adding material during the additive manufacturing process. {Yet}, measuring this rate directly in material extrusion additive manufacturing presents challenges. {This} work presents two indirect methods to estimate the volumetric flow rate at the liquefier exit in material extrusion, specifically in {Fused} {Deposition} {Modeling} or {Fused} {Filament} {Fabrication}. {The} methods are cost effective and may be applied in future sensor integration. {The} first method is an optical filament feed rate and width measurement and the second is based on the liquefier pressure. {Both} are used to indirectly estimate the volumetric flow rate. {The} work also includes a description of linking the {G}-code command to the final print result, which may be used to create a per extrusion command model of the part. {References}: [1] {T}. {Wohlers}, {I}. {Campbell}, {O}. {Diegel}, {J}. {Kowen}, {I}. {Fidan}, and {D}.{L}. {Bourell}, "{Wohlers} {Report} 2017: {3D} {Printing} and {Additive} {Manufacturing} {State} of the {Industry} {Annual} {Worldwide} {Progress} {Report}," 2017. [2] {Additive} manufacturing – {General} principles – {Terminology}. {Geneva}, {CH}: {International} {Organization} for {Standardization}, 2015. [3] {R}. {Jones} et al., "{Reprap} - {The} replicating rapid prototyper," {Robotica}, vol. 29, no. 1 {SPEC}. {ISSUE}, pp. 177-191, 2011, https://doi.org/10.1017/{S026357471000069X} [4] {T}. {Wohlers} and {T}. {Gornet}, "{History} of {Additive} {Manufacturing} 2017," 2017. [5] {S}. {A}. {M}. {Tofail}, {E}. {P}. {Koumoulos}, {A}. {Bandyopadhyay}, {S}. {Bose}, {L}. {O}'{Donoghue}, and {C}. {Charitidis}, "{Additive} manufacturing: scientific and technological challenges, market uptake and opportunities, "{Materials} {Today}, vol. 21, no. 1, pp. 22-37, {Jan}. 2018, https://doi.org/10.1016/j.mattod.2017.07.001 [6] {G}. {Moroni} and {S}. {Petrò}, "{Managing} uncertainty in the new manufacturing era," {Procedia} {CIRP}, vol. 75, pp. 1-2, 2018, https://doi.org/10.1016/j.procir.2018.07.001 [7] {R}. {Leach} et al., "{Information}-rich manufacturing metrology,"in {Eighth} {International} {Precision} {Assembly} {Seminar} ({IPAS}), 2018, no. {January}. https://doi.org/10.1007/978-3-030-05931-6\_14 [8] {S}. {Moylan}, {J}. {Slotwinski}, {A}. {Cooke}, {K}. {Jurrens}, {M}. {A}. {Donmez}, and {A}. {Donmez}, "{Proposal} for a {Standardized} {Test} {Artifact} for {Additive} {Manufacturing} {Machines} and {Processes}," {Solid} {Freeform} {Fabrication} {Symposium} {Proceedings}, pp. 902-920, 2012. https://doi.org/10.6028/{NIST}.{IR}.7858 [9] {ASME} {Y14}.46-2017 {Product} {Definition} for {Additive} {Manufacturing}. {New} {York}:{The} {American} {Society} of {Mechanical} {Engineers}, 2017. [10] {H}. {Li}, {T}. {Wang}, {J}. {Sun}, and {Z}. {Yu}, "{The} effect of process parameters in fused deposition modelling on bonding degree and mechanical properties," {Rapid} {Prototyping} {Journal}, vol. 24, no. 1, pp. 80-92, {Jan}. 2018, https://doi.org/10.1108/{RPJ}-06-2016-0090 [11] {A}. {W}. {Gebisa} and {H}. {G}. {Lemu}, "{Investigating} effects of {Fused}-deposition modeling ({FDM}) processing parameters on flexural properties of {ULTEM} 9085 using designed experiment, "{Materials}, vol.11, no. 4, pp. 1-23, 2018, https://doi.org/10.3390/ma11040500 {PMid}:29584674 {PMCid}:{PMC5951346} [12] {B}. {Wittbrodt} and {J}. {M}. {Pearce}, "{The} effects of {PLA} color on material properties of 3-{D} printed components," {Additive} {Manufacturing}, vol. 8, pp. 110-116, 2015, https://doi.org/10.1016/j.addma.2015.09.006 [13] {O}. {A}. {Mohamed}, {S}. {H}. {Masood}, and {J}. {L}. {Bhowmik}, "{Optimization} of fused deposition modeling process parameters: a review of current research and future prospects," {Advances} in {Manufacturing}, vol. 3, no. 1, pp. 42-53, {Mar}. 2015, https://doi.org/10.1007/s40436-014-0097-7 [14] {S}. {K}. {Everton}, {M}. {Hirsch}, {P}. {Stravroulakis}, {R}. {K}. {Leach} and {A}. {T}. {Clare}, "{Review} of in-situ process monitoring and in-situ metrology for metal additive manufacturing," {Materials} and {Design}, vol. 95, pp. 431-445, 2016, https://doi.org/10.1016/j.matdes.2016.01.099 [15] {P}. {K}. {Rao}, {J}. {P}. {Liu}, {D}. {Roberson}, {Z}. {J}. {Kong}, and {C}. {Williams},"{Online} {Real}-{Time} {Quality} {Monitoring} in {Additive} {Manufacturing} {Processes} {Using} {Heterogeneous} {Sensors}," {Journal} of {Manufacturing} {Science} and {Engineering}, vol. 137, no. 6, p.061007, {Sep}. 2015, https://doi.org/10.1115/1.4029823 [16] {J}. {Pellegrino}, {T}. {Makila}, {S}. {McQueen}, and {E}. {Taylor}, "{Measurement} science roadmap for polymer-based additive manufacturing," {Gaithersburg}, {MD}, {Dec}. 2016. https://doi.org/10.6028/{NIST}.{AMS}.100-5 [17] {T}. {R}. {Kramer}, {F}. {M}. {Proctor}, and {E}. {Messina}, "{The} {NIST} {RS274NGC} {Interpreter} -{Version} 3," {Gaithersburg}, {Maryland}, 2000. https://doi.org/10.6028/{NIST}.{IR}.6556 [18] {B}. {N}. {Turner}, {R}. {Strong}, and {S}. {A}. {Gold}, "{A} review of melt extrusion additive manufacturing processes: {I}. {Process} design and modeling," {Rapid} {Prototyping} {Journal}, vol. 20, no. 3, pp.192-204, {Apr}. 2014, https://doi.org/10.1108/{RPJ}-01-2013-0012 [19] {Conrad} {Electronic}, "{Renkforce} {RF1000} {3D} {Drucker}," 2016. https://www.conrad.de/de/renkforce-rf1000-3d-drucker-single-extruder-inkl-software-franzis-designcad-v24-3d-printrenkforce-edition-1007508.html (accessed {Sep}. 20, 2016). [20] {G}. {Hodgson}, {A}. {Ranellucci}, and {J}. {Moe}, "{Slic3r} {Manual} - {Flow} {Math}," 2016. http://manual.slic3r.org/advanced/flow-math (accessed {Jun}. 21, 2016). [21] {Repetier}, "{Repetier}-{Firmware} {Documentation}." https://www.repetier.com/documentation/repetier firmware/repetier-firmware-introduction/ (accessed {Apr}. 17, 2018). [22] {B}. {Weiss}, {D}. {W}. {Storti}, and {M}. {A}. {Ganter}, "{Low}-cost closedloop control of a {3D} printer gantry," {Rapid} {Prototyping} {Journal}, vol. 21, no. 5, pp. 482-490, {Aug}. 2015, https://doi.org/10.1108/{RPJ}-09-2014-0108 [23] {R}. {L}. {Zinniel} and {J}. {S}. {Batchelder}, "{Volumetric} {Feed} {Control} for {Flexible} {Filament}," {US} 6085957, 2000. [24] {W}. {J}. {Heij}, {Applied} {Metrology} in {Additive} {Manufacturing}. {Delft}: {Delft} {University} of {Technology}, 2016. [25] {G}. {P}. {Greeff} and {M}. {Schilling}, "{Closed} loop control of slippage during filament transport in molten material extrusion," {Additive} {Manufacturing}, vol. 14, pp. 31-38, 2017, https://doi.org/10.1016/j.addma.2016.12.005 [26] {G}. {P}. {Greeff}, {Applied} {Metrology} in {Additive} {Manufacturing}, vol. 60. {Berlin}: {Mensch} und {Buch}, 2019. [27] {G}. {P}. {Greeff} and {M}. {Schilling}, "{Comparing} {Retraction} {Methods} with {Volumetric} {Exit} {Flow} {Measurement} in {Molten} {Material} {Extrusion}," in {Special} {Interest} {Group} meeting on {Dimensional} {Accuracy} and {Surface} {Finish} in {Additive} {Manufacturing}, 2017, no. {October}, pp. 70-74. [28] {G}. {P}. {Greeff} and {M}. {Schilling}, "{Single} print optimisation of fused filament fabrication parameters," {The} {International} {Journal} of {Advanced} {Manufacturing} {Technology}, {Aug}. 2018, https://doi.org/10.1007/s00170-018-2518-4 [29] {A}. {Bellini}, {S}. {Güçeri}, and {M}. {Bertoldi}, "{Liquefier} {Dynamics} in {Fused} {Deposition}," {Journal} of {Manufacturing} {Science} and {Engineering}, vol. 126, no. 2, p. 237, 2004, https://doi.org/10.1115/1.1688377 [30] {P}. {Virtanen} et al., "{SciPy} 1.0: fundamental algorithms for scientific computing in {Python}," {Nature} {Methods}, vol. 17, no. 3, pp. 261-272, {Mar}. 2020, https://doi.org/10.1038/s41592-019-0686-2 {PMid}:32015543 {PMCid}:{PMC7056644} ({Print}: {ISSN} 1931-5775) ({Online}: {ISSN} 2381-0580) © 2021 {NCSL} {International} {Software} to {Maximize} {End}-{User} {Uptake} of {Conformity} {Assessment} with {Measurement} {Uncertainty}, {Including} {Bivariate} {Cases}. {The} {European} {EMPIR} {CASoft} {Project}},
	volume = {13},
	url = {http://dx.doi.org/10.51843/measure.13.1.6},
	doi = {10.51843/measure.13.1.6},
	number = {1},
	journal = {NCSL International measure},
	author = {Pendrill, L.R. and Allard, A. and Fischer, N. and Harris, P.M. and Nguyen, J. and Smith, I.M.},
	month = jan,
	year = {2021},
	note = {Publisher: NCSL International},
	pages = {58--69},
	file = {Pendrill et al. - 2021 - Full Issue Download Vol. 13 No. 1 2021 The Importa.pdf:/home/david/Zotero/storage/NP73N643/Pendrill et al. - 2021 - Full Issue Download Vol. 13 No. 1 2021 The Importa.pdf:application/pdf},
}

@article{unser_fast_1991,
	title = {Fast {B}-spline transforms for continuous image representation and interpolation},
	volume = {13},
	url = {https://doi.org/10.1109%2F34.75515},
	doi = {10.1109/34.75515},
	number = {3},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Unser, M. and Aldroubi, A. and Eden, M.},
	month = mar,
	year = {1991},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {277--285},
	file = {Unser et al. - 1991 - Fast B-spline transforms for continuous image repr.pdf:/home/david/Zotero/storage/23CG7G43/Unser et al. - 1991 - Fast B-spline transforms for continuous image repr.pdf:application/pdf},
}

@article{unser_b-spline_1993,
	title = {B-spline signal processing. {II}. {Efficiency} design and applications},
	volume = {41},
	url = {http://dx.doi.org/10.1109/78.193221},
	doi = {10.1109/78.193221},
	number = {2},
	journal = {IEEE Transactions on Signal Processing},
	author = {Unser, M. and Aldroubi, A. and Eden, M.},
	year = {1993},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {834--848},
	file = {Unser et al. - 1993 - B-spline signal processing. II. Efficiency design .pdf:/home/david/Zotero/storage/J3RL864C/Unser et al. - 1993 - B-spline signal processing. II. Efficiency design .pdf:application/pdf},
}

@article{unser_b-spline_1993-1,
	title = {B-spline signal processing. {I}. {Theory}},
	volume = {41},
	url = {http://dx.doi.org/10.1109/78.193220},
	doi = {10.1109/78.193220},
	number = {2},
	journal = {IEEE Transactions on Signal Processing},
	author = {Unser, M. and Aldroubi, A. and Eden, M.},
	year = {1993},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {821--833},
	file = {Unser et al. - 1993 - B-spline signal processing. I. Theory.pdf:/home/david/Zotero/storage/YJN9BZ62/Unser et al. - 1993 - B-spline signal processing. I. Theory.pdf:application/pdf},
}

@article{kogel_fast_2011,
	title = {A {Fast} {Gradient} method for embedded linear predictive control},
	volume = {44},
	issn = {14746670},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1474667016437997},
	doi = {10.3182/20110828-6-IT-1002.03322},
	abstract = {This work considers the fast solution of model predictive control problems for linear systems with input constraints and a quadratic cost criterion. If the resulting optimization problem arising from the model predictive control is solved online using the Fast Gradient method one needs to determine the gradient of the cost function. We propose a method, tailored for embedded control purposes, that eﬃciently calculates the gradient taking the underlying structure of the system into account. Moreover, we discuss how the stability of the plant inﬂuences the required number of iterations to obtain a solution within a prescribed accuracy.},
	language = {en},
	number = {1},
	urldate = {2021-12-12},
	journal = {IFAC Proceedings Volumes},
	author = {Kögel, Markus and Findeisen, Rolf},
	month = jan,
	year = {2011},
	pages = {1362--1367},
	file = {Kögel and Findeisen - 2011 - A Fast Gradient method for embedded linear predict.pdf:/home/david/Zotero/storage/3QNSJV36/Kögel and Findeisen - 2011 - A Fast Gradient method for embedded linear predict.pdf:application/pdf},
}

@book{nesterov_introductory_2004,
	address = {Boston, MA},
	series = {Applied {Optimization}},
	title = {Introductory {Lectures} on {Convex} {Optimization}},
	volume = {87},
	isbn = {978-1-4613-4691-3 978-1-4419-8853-9},
	url = {http://link.springer.com/10.1007/978-1-4419-8853-9},
	language = {en},
	urldate = {2021-12-12},
	publisher = {Springer US},
	author = {Nesterov, Yurii},
	editor = {Pardalos, Panos M. and Hearn, Donald W.},
	year = {2004},
	doi = {10.1007/978-1-4419-8853-9},
	file = {Nesterov - 2004 - Introductory Lectures on Convex Optimization.pdf:/home/david/Zotero/storage/AA9LNYKW/Nesterov - 2004 - Introductory Lectures on Convex Optimization.pdf:application/pdf},
}

@article{xu_investigation_2012,
	title = {Investigation of discrete imaging models and iterative image reconstruction in differential {X}-ray phase-contrast tomography},
	volume = {20},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/oe/abstract.cfm?uri=oe-20-10-10724},
	doi = {10.1364/OE.20.010724},
	abstract = {Differential X-ray phase-contrast tomography (DPCT) refers to a class of promising methods for reconstructing the X-ray refractive index distribution of materials that present weak X-ray absorption contrast. The tomographic projection data in DPCT, from which an estimate of the refractive index distribution is reconstructed, correspond to onedimensional (1D) derivatives of the two-dimensional (2D) Radon transform of the refractive index distribution. There is an important need for the development of iterative image reconstruction methods for DPCT that can yield useful images from few-view projection data, thereby mitigating the long data-acquisition times and large radiation doses associated with use of analytic reconstruction methods. In this work, we analyze the numerical and statistical properties of two classes of discrete imaging models that form the basis for iterative image reconstruction in DPCT. We also investigate the use of one of the models with a modern image reconstruction algorithm for performing few-view image reconstruction of a tissue specimen.},
	language = {en},
	number = {10},
	urldate = {2021-12-13},
	journal = {Optics Express},
	author = {Xu, Qiaofeng and Sidky, Emil Y. and Pan, Xiaochuan and Stampanoni, Marco and Modregger, Peter and Anastasio, Mark A.},
	month = may,
	year = {2012},
	pages = {10724},
	file = {Xu et al. - 2012 - Investigation of discrete imaging models and itera.pdf:/home/david/Zotero/storage/E4F9TVK6/Xu et al. - 2012 - Investigation of discrete imaging models and itera.pdf:application/pdf},
}

@misc{noauthor_why_nodate,
	title = {why is {BSpline}() only working for regular grids? · {Issue} \#131 · {JuliaMath}/{Interpolations}.jl},
	shorttitle = {why is {BSpline}() only working for regular grids?},
	url = {https://github.com/JuliaMath/Interpolations.jl/issues/131},
	abstract = {I was wondering how hard it would be to support irregular grids for BSpline interpolation. I am aware that you have Gridded for this case, however, I often end up missing features of Gridded which ...},
	language = {en},
	urldate = {2021-12-13},
	journal = {GitHub},
	file = {Snapshot:/home/david/Zotero/storage/M6KNQ676/Interpolations.html:text/html},
}

@article{thevenaz_interpolation_2000,
	title = {Interpolation revisited [medical images application]},
	volume = {19},
	issn = {1558-254X},
	doi = {10.1109/42.875199},
	abstract = {Based on the theory of approximation, this paper presents a unified analysis of interpolation and resampling techniques. An important issue is the choice of adequate basis functions. The authors show that, contrary to the common belief, those that perform best are not interpolating. By opposition to traditional interpolation, the authors call their use generalized interpolation; they involve a prefiltering step when correctly applied. The authors explain why the approximation order inherent in any basis function is important to limit interpolation artifacts. The decomposition theorem states that any basis function endowed with approximation order ran be expressed as the convolution of a B spline of the same order with another function that has none. This motivates the use of splines and spline-based functions as a tunable way to keep artifacts in check without any significant cost penalty. The authors discuss implementation and performance issues, and they provide experimental evidence to support their claims.},
	number = {7},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Thevenaz, P. and Blu, T. and Unser, M.},
	month = jul,
	year = {2000},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Biomedical imaging, Convolution, Cost function, Heart, Interpolation, Kernel, Performance analysis, Sampling methods, Spline},
	pages = {739--758},
	file = {IEEE Xplore Full Text PDF:/home/david/Zotero/storage/9VM4R4YE/Thevenaz et al. - 2000 - Interpolation revisited [medical images applicatio.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/9VWGRF2K/875199.html:text/html;Thevenaz et al. - 2000 - Interpolation revisited [medical images applicatio.pdf:/home/david/Zotero/storage/5I9E2DQJ/Thevenaz et al. - 2000 - Interpolation revisited [medical images applicatio.pdf:application/pdf},
}

@misc{noauthor_spline_nodate,
	title = {Spline {Interpolation}},
	url = {http://bigwww.epfl.ch/thevenaz/interpolation/},
	urldate = {2021-12-13},
	file = {Spline Interpolation:/home/david/Zotero/storage/PWU9L84S/interpolation.html:text/html},
}

@article{ratnani_b-splines_nodate,
	title = {B-{Splines} and {IsoGeometric} {Analysis}},
	language = {en},
	author = {Ratnani, A and Sonnendrücker, E},
	pages = {15},
	file = {Ratnani and Sonnendrücker - B-Splines and IsoGeometric Analysis.pdf:/home/david/Zotero/storage/JQVDYASZ/Ratnani and Sonnendrücker - B-Splines and IsoGeometric Analysis.pdf:application/pdf},
}

@article{mccann_fast_2016,
	title = {Fast {3D} reconstruction method for differential phase contrast {X}-ray {CT}},
	volume = {24},
	issn = {1094-4087},
	url = {https://www.osapublishing.org/abstract.cfm?URI=oe-24-13-14564},
	doi = {10.1364/OE.24.014564},
	abstract = {We present a fast algorithm for fully 3D regularized X-ray tomography reconstruction for both traditional and differential phase contrast measurements. In many applications, it is critical to reduce the X-ray dose while producing high-quality reconstructions. Regularization is an excellent way to do this, but in the differential phase contrast case it is usually applied in a slice-by-slice manner. We propose using fully 3D regularization to improve the dose/quality trade-off beyond what is possible using slice-by-slice regularization. To make this computationally feasible, we show that the two computational bottlenecks of our iterative optimization process can be expressed as discrete convolutions; the resulting algorithms for computation of the X-ray adjoint and normal operator are fast and simple alternatives to regridding. We validate this algorithm on an analytical phantom as well as conventional CT and differential phase contrast measurements from two real objects. Compared to the slice-by-slice approach, our algorithm provides a more accurate reconstruction of the analytical phantom and better qualitative appearance on one of the two real datasets.},
	language = {en},
	number = {13},
	urldate = {2021-12-13},
	journal = {Optics Express},
	author = {McCann, Michael T. and Nilchian, Masih and Stampanoni, Marco and Unser, Michael},
	month = jun,
	year = {2016},
	pages = {14564},
	file = {McCann et al. - 2016 - Fast 3D reconstruction method for differential pha.pdf:/home/david/Zotero/storage/BMGS9ZWI/McCann et al. - 2016 - Fast 3D reconstruction method for differential pha.pdf:application/pdf},
}

@article{sorzano_xmipp_2004,
	title = {{XMIPP}: a new generation of an open-source image processing package for electron microscopy},
	volume = {148},
	issn = {10478477},
	shorttitle = {{XMIPP}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047847704001261},
	doi = {10.1016/j.jsb.2004.06.006},
	abstract = {X-windows based microscopy image processing package (Xmipp) is a specialized suit of image processing programs, primarily aimed at obtaining the 3D reconstruction of biological specimens from large sets of projection images acquired by transmission electron microscopy. This public-domain software package was introduced to the electron microscopy ﬁeld eight years ago, and since then it has changed drastically. New methodologies for the analysis of single-particle projection images have been added to classiﬁcation, contrast transfer function correction, angular assignment, 3D reconstruction, reconstruction of crystals, etc. In addition, the package has been extended with functionalities for 2D crystal and electron tomography data. Furthermore, its current implementation in C++, with a highly modular design of well-documented data structures and functions, oﬀers a convenient environment for the development of novel algorithms. In this paper, we present a general overview of a new generation of Xmipp that has been re-engineered to maximize ﬂexibility and modularity, potentially facilitating its integration in future standardization eﬀorts in the ﬁeld. Moreover, by focusing on those developments that distinguish Xmipp from other packages available, we illustrate its added value to the electron microscopy community.},
	language = {en},
	number = {2},
	urldate = {2021-12-13},
	journal = {Journal of Structural Biology},
	author = {Sorzano, C.O.S. and Marabini, R. and Velázquez-Muriel, J. and Bilbao-Castro, J.R. and Scheres, S.H.W. and Carazo, J.M. and Pascual-Montano, A.},
	month = nov,
	year = {2004},
	pages = {194--204},
	file = {Sorzano et al. - 2004 - XMIPP a new generation of an open-source image pr.pdf:/home/david/Zotero/storage/4WWCHNQ6/Sorzano et al. - 2004 - XMIPP a new generation of an open-source image pr.pdf:application/pdf;Sorzano et al. - 2004 - XMIPP a new generation of an open-source image pr.pdf:/home/david/Zotero/storage/48JAP5NK/Sorzano et al. - 2004 - XMIPP a new generation of an open-source image pr.pdf:application/pdf},
}

@misc{noauthor_xmipp_2021,
	title = {Xmipp},
	copyright = {GPL-3.0},
	url = {https://github.com/I2PC/xmipp/blob/81681048bdc75911293b78fcb50c77c037688ba1/src/xmipp/libraries/data/blobs.cpp},
	abstract = {Xmipp is a suite of image processing programs, primarily aimed at single-particle 3D electron microscopy.},
	urldate = {2021-12-13},
	publisher = {Instruct Image Processing Center},
	month = dec,
	year = {2021},
	note = {original-date: 2018-06-11T13:30:44Z},
}

@incollection{herman_computerized_2015,
	title = {Computerized {Tomography} {Reconstruction} {Methods}},
	isbn = {978-0-12-397316-0},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780123970251002864},
	language = {en},
	urldate = {2021-12-13},
	booktitle = {Brain {Mapping}},
	publisher = {Elsevier},
	author = {Herman, G.T.},
	year = {2015},
	doi = {10.1016/B978-0-12-397025-1.00286-4},
	pages = {203--208},
	file = {Herman - 2015 - Computerized Tomography Reconstruction Methods.pdf:/home/david/Zotero/storage/SCFNNYII/Herman - 2015 - Computerized Tomography Reconstruction Methods.pdf:application/pdf},
}

@book{levakhina_three-dimensional_2014,
	address = {Wiesbaden},
	title = {Three-{Dimensional} {Digital} {Tomosynthesis}: {Iterative} {Reconstruction}, {Artifact} {Reduction} and {Alternative} {Acquisition} {Geometry}},
	isbn = {978-3-658-05696-4 978-3-658-05697-1},
	shorttitle = {Three-{Dimensional} {Digital} {Tomosynthesis}},
	url = {http://link.springer.com/10.1007/978-3-658-05697-1},
	language = {en},
	urldate = {2021-12-13},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Levakhina, Yulia},
	year = {2014},
	doi = {10.1007/978-3-658-05697-1},
	file = {Levakhina - 2014 - Three-Dimensional Digital Tomosynthesis Iterative.pdf:/home/david/Zotero/storage/TBFGYC39/Levakhina - 2014 - Three-Dimensional Digital Tomosynthesis Iterative.pdf:application/pdf;Levakhina - 2014 - Three-Dimensional Digital Tomosynthesis Iterative.pdf:/home/david/Zotero/storage/AWN9BCTH/Levakhina - 2014 - Three-Dimensional Digital Tomosynthesis Iterative.pdf:application/pdf},
}

@article{schmitt_analysis_nodate,
	title = {Analysis of bias induced by various forward projection models in iterative reconstruction},
	abstract = {Discrete representation of the CT image is a major step in the design of iterative reconstruction algorithms, particularly because the decision being made at this level affects both bias and noise properties of the reconstruction, in addition to choices made later in the algorithm design. In this work, we examine the bias induced by popular image representation models, namely Joseph’s method and the basis function approach relying on B-splines and blobs. Our preliminary results highlight a common weakness in terms of overshoot and undershoot artifacts at sharp boundaries. They also show that the Blobs may perform only as well as the B-spline of order two in terms of bias, and that Joseph’s method tends to produce results that are fairly comparable to the B-spline of order one, with a slight advantage in favor of the latter.},
	language = {en},
	author = {Schmitt, K and Schondube, H and Stierstorfer, K and Hornegger, J and Noo, F},
	pages = {5},
	file = {Schmitt et al. - Analysis of bias induced by various forward projec.pdf:/home/david/Zotero/storage/HBHTAIXL/Schmitt et al. - Analysis of bias induced by various forward projec.pdf:application/pdf},
}

@misc{noauthor_kaiser_nodate,
	title = {Kaiser window approximation},
	url = {https://dsp.stackexchange.com/questions/37714/kaiser-window-approximation},
	urldate = {2021-12-13},
	journal = {Signal Processing Stack Exchange},
}

@incollection{govil_fast_2006,
	title = {A {Fast} {Algorithm} for {Spherical} {Basis} {Approximation}},
	volume = {282},
	isbn = {978-1-58488-636-5 978-1-4200-1138-8},
	url = {http://www.crcnetbase.com/doi/abs/10.1201/9781420011388.ch13},
	abstract = {Radial basis functions appear in a wide ﬁeld of applications in numerical mathematics and computer science. We present a fast algorithm for scattered data interpolation and approximation on the sphere with spherical radial basis functions of diﬀerent spatial density. We discuss three settings, each leading to a special structure of the interpolation matrix allowing for an eﬃcient implementation using discrete Fourier transforms. A numerical example is given to show the advantages of spherical radial basis functions with diﬀerent spatial densities.},
	language = {en},
	urldate = {2021-12-13},
	booktitle = {Frontiers in {Interpolation} and {Approximation}},
	publisher = {Chapman and Hall/CRC},
	author = {Keiner, J and Prestin, J},
	collaborator = {Govil, N and Mhaskar, H and Mohapatra, Ram and Nashed, Zuhair and Szabados, J},
	month = jul,
	year = {2006},
	doi = {10.1201/9781420011388.ch13},
	note = {Series Title: Pure and Applied Mathematics},
	pages = {259--286},
	file = {Keiner and Prestin - 2006 - A Fast Algorithm for Spherical Basis Approximation.pdf:/home/david/Zotero/storage/QBMDC7UF/Keiner and Prestin - 2006 - A Fast Algorithm for Spherical Basis Approximation.pdf:application/pdf},
}

@inproceedings{levakhina_distance-driven_2010,
	address = {Knoxville, TN},
	title = {Distance-driven projection and backprojection for spherically symmetric basis functions in {CT}},
	isbn = {978-1-4244-9106-3},
	url = {http://ieeexplore.ieee.org/document/5874325/},
	doi = {10.1109/NSSMIC.2010.5874325},
	abstract = {Forward- and backprojecton pair plays an important role in computed tomography (CT). Since they are used in clinical routine for ﬁltered backprojection (FBP) reconstruction, in iterative reconstruction methods, for artifact correction and simulation purposes, they have to be fast, accurate and memory efﬁcient. Recently, a distance-driven approach for pixel basis functions has been proposed. At the moment, it is a stateof-the-art method that is almost artifact free, fast and has a predictable memory pattern access. In the work presented here, the distance-driven approach for the two-dimensional case is extended for spherically symmetric Kaiser-Bessel basis functions. Usage of these basis functions allows for constructing a smooth and continuous function for image representation.},
	language = {en},
	urldate = {2021-12-13},
	booktitle = {{IEEE} {Nuclear} {Science} {Symposuim} \& {Medical} {Imaging} {Conference}},
	publisher = {IEEE},
	author = {Levakhina, Y and Buzug, T M},
	month = oct,
	year = {2010},
	pages = {2894--2897},
	file = {Levakhina and Buzug - 2010 - Distance-driven projection and backprojection for .pdf:/home/david/Zotero/storage/7QQKY6AS/Levakhina and Buzug - 2010 - Distance-driven projection and backprojection for .pdf:application/pdf},
}

@article{levakhina_weighted_2013,
	title = {Weighted simultaneous algebraic reconstruction technique for tomosynthesis imaging of objects with high-attenuation features: \textbf{ \textit{ω} } {SART} for tomosynthesis of objects with high-attenuation features},
	volume = {40},
	issn = {00942405},
	shorttitle = {Weighted simultaneous algebraic reconstruction technique for tomosynthesis imaging of objects with high-attenuation features},
	url = {http://doi.wiley.com/10.1118/1.4789592},
	doi = {10.1118/1.4789592},
	abstract = {Purpose: This paper introduces a nonlinear weighting scheme into the backprojection operation within the simultaneous algebraic reconstruction technique (SART). It is designed for tomosynthesis imaging of objects with high-attenuation features in order to reduce limited angle artifacts.
Methods: The algorithm estimates which projections potentially produce artifacts in a voxel. The contribution of those projections into the updating term is reduced. In order to identify those projections automatically, a four-dimensional backprojected space representation is used. Weighting coefﬁcients are calculated based on a dissimilarity measure, evaluated in this space. For each combination of an angular view direction and a voxel position an individual weighting coefﬁcient for the updating term is calculated.
Results: The feasibility of the proposed approach is shown based on reconstructions of the following real three-dimensional tomosynthesis datasets: a mammography quality phantom, an apple with metal needles, a dried ﬁnger bone in water, and a human hand. Datasets have been acquired with a Siemens Mammomat Inspiration tomosynthesis device and reconstructed using SART with and without suggested weighting. Out-of-focus artifacts are described using line proﬁles and measured using standard deviation (STD) in the plane and below the plane which contains artifact-causing features. Artifacts distribution in axial direction is measured using an artifact spread function (ASF). The volumes reconstructed with the weighting scheme demonstrate the reduction of out-of-focus artifacts, lower STD (meaning reduction of artifacts), and narrower ASF compared to nonweighted SART reconstruction. It is achieved successfully for different kinds of structures: point-like structures such as phantom features, long structures such as metal needles, and ﬁne structures such as trabecular bone structures.
Conclusions: Results indicate the feasibility of the proposed algorithm to reduce typical tomosynthesis artifacts produced by high-attenuation features. The proposed algorithm assigns weighting coefﬁcients automatically and no segmentation or tissue-classiﬁcation steps are required. The algorithm can be included into various iterative reconstruction algorithms with an additive updating strategy. It can also be extended to computed tomography case with the complete set of angular data. © 2013 American Association of Physicists in Medicine. [http://dx.doi.org/10.1118/1.4789592]},
	language = {en},
	number = {3},
	urldate = {2021-12-13},
	journal = {Medical Physics},
	author = {Levakhina, Y. M. and Müller, J. and Duschka, R. L. and Vogt, F. and Barkhausen, J. and Buzug, T. M.},
	month = feb,
	year = {2013},
	pages = {031106},
	file = {Levakhina et al. - 2013 - Weighted simultaneous algebraic reconstruction tec.pdf:/home/david/Zotero/storage/FFCW9GUQ/Levakhina et al. - 2013 - Weighted simultaneous algebraic reconstruction tec.pdf:application/pdf},
}

@inproceedings{levakhina_two-step_2010,
	title = {Two-step metal artifact reduction using {2D}-{NFFT} and spherically symmetric basis functions},
	doi = {10.1109/NSSMIC.2010.5874424},
	abstract = {In computed tomography metal objects lead to inconsistencies in the acquired data which result in image artifacts after reconstruction. To enhance the image quality and allow for a more accurate diagnosis, a metal artifact reduction is required. Approaches may base on a recomputation of metal influenced values or use an alternative image reconstruction technique, which is less sensitive to inconsistent raw data than the standard filtered backprojection. Here, a two-step algorithm for metal artifact reduction is proposed, which combines a 2D NFFT-based interpolation and an MLEM reconstruction with spherically symmetric basis functions (blobs). Reconstructed images have been evaluated visually and quantitatively. Experiments show that combination of a 2D NFFT-based interpolation and blobs offers an effective strategy for enhanced metal artifacts suppression.},
	booktitle = {{IEEE} {Nuclear} {Science} {Symposuim} {Medical} {Imaging} {Conference}},
	author = {Levakhina, Yulia and Kratz, Baerbel and Buzug, Thorsten M.},
	month = oct,
	year = {2010},
	note = {ISSN: 1082-3654},
	keywords = {Biomedical imaging, Interpolation, Computed tomography, Image reconstruction, Pixel, Image edge detection, Metals},
	pages = {3343--3345},
	file = {Levakhina et al. - 2010 - Two-step metal artifact reduction using 2D-NFFT an.pdf:/home/david/Zotero/storage/34UPBSU5/Levakhina et al. - 2010 - Two-step metal artifact reduction using 2D-NFFT an.pdf:application/pdf},
}

@misc{noauthor_approximation_nodate,
	title = {Approximation of functions},
	url = {http://hplgit.github.io/INF5620/doc/pub/sphinx-fem/._main_fem002.html},
	urldate = {2021-12-13},
	file = {Approximation of functions.html:/home/david/Zotero/storage/JW3A2UCB/Approximation of functions.html:text/html},
}

@book{buzug_computed_2008,
	address = {Berlin, Heidelberg},
	edition = {1},
	title = {Computed {Tomography}: {From} {Photon} {Statistics} to {Modern} {Cone}-{Beam} {CT}},
	isbn = {978-3-540-39407-5 978-3-540-39408-2},
	url = {http://link.springer.com/10.1007/978-3-540-39408-2},
	abstract = {Tis book provides an overview of X-ray technology, the historic developmental milestones of modern CT systems, and gives a comprehensive insight into the main reconstruction methods used in computed tomography. Te basis of reconstr- tion is, undoubtedly, mathematics. However, the beauty of computed tomography cannot be understood without a detailed knowledge of X-ray generation, photon– matter interaction, X-ray detection, photon statistics, as well as fundamental signal processing concepts and dedicated measurement systems. Terefore, the reader will ?nd a number of references to these basic disciplines together with a brief introd- tion to the underlying principles of CT. Tis book is structured to cover the basics of CT: from photon statistics to m- ern cone-beam systems. However, the main focus of the book is concerned with - tailed derivations of reconstruction algorithms in ?D and modern ?D cone-beam systems. A thorough analysis of CT artifacts and a discussion of practical issues, such as dose considerations, provide further insight into modern CT systems. While mainly written for graduate students in biomedical engineering, medical engine- ing science, medical physics, medicine (radiology), mathematics, electrical eng- eering, and physics, experienced practitioners in these ?elds will bene?t from this book as well.},
	language = {en},
	urldate = {2021-12-13},
	publisher = {Springer Berlin Heidelberg},
	author = {Buzug, Thorsten M.},
	year = {2008},
	doi = {10.1007/978-3-540-39408-2},
	file = {Buzug - 2008 - Computed Tomography From Photon Statistics to Mod.pdf:/home/david/Zotero/storage/XQ3F48P9/Buzug - 2008 - Computed Tomography From Photon Statistics to Mod.pdf:application/pdf},
}

@misc{noauthor_toast_2021,
	title = {Toast++ - {Image} {Reconstruction} in {Optical} {Tomography}},
	copyright = {GPL-3.0},
	url = {https://github.com/toastpp/toastpp},
	abstract = {Toast++: Forward and inverse modelling in optical tomography},
	urldate = {2021-12-13},
	publisher = {Toast++},
	month = dec,
	year = {2021},
	note = {original-date: 2016-07-07T14:30:16Z},
}

@article{vrcej_efficient_2001,
	title = {Efficient implementation of all-digital interpolation},
	volume = {10},
	issn = {10577149},
	url = {http://ieeexplore.ieee.org/document/967392/},
	doi = {10.1109/83.967392},
	abstract = {B-splines are commonly used for continuous representation of discrete time signals. This kind of representation proves to be very useful in applications such as image interpolation, rotation and edge detection. In all these applications, the ﬁrst step is to compute the B-spline coeﬃcients of the signal, and this involves the use of an IIR noncausal ﬁlter called the direct B-spline ﬁlter. The signal reconstruction is achieved using the indirect B-spline ﬁlter, which in many applications operates at a higher rate.},
	language = {en},
	number = {11},
	urldate = {2021-12-14},
	journal = {IEEE Transactions on Image Processing},
	author = {Vrcej, B. and Vaidyanathan, P.P.},
	month = nov,
	year = {2001},
	pages = {1639--1646},
	file = {Vrcej and Vaidyanathan - 2001 - Efficient implementation of all-digital interpolat.pdf:/home/david/Zotero/storage/6RCG935B/Vrcej and Vaidyanathan - 2001 - Efficient implementation of all-digital interpolat.pdf:application/pdf},
}

@article{trampert_spherically_nodate,
	title = {Spherically symmetric volume elements as basis functions for image reconstructions in computed laminography},
	abstract = {BACKGROUND: Laminography is a tomographic technique that allows three-dimensional imaging of ﬂat, elongated objects that stretch beyond the extent of a reconstruction volume. Laminography datasets can be reconstructed using iterative algorithms based on the Kaczmarz method.
OBJECTIVE: The goal of this study is to develop a reconstruction algorithm that provides superior reconstruction quality for a challenging class of problems.
METHODS: Images are represented in computer memory using coefﬁcients over basis functions, typically piecewise constant functions (voxels). By replacing voxels with spherically symmetric volume elements (blobs) based on generalized KaiserBessel window functions, we obtained an adapted version of the algebraic reconstruction technique.
RESULTS: Band-limiting properties of blob functions are beneﬁcial particular in the case of noisy projections and if only a limited number of projections is available. In this case, using blob basis functions improved the full-width-at-half-maximum resolution from 10.2 ± 1.0 to 9.9 ± 0.9 (p value = 2.3·10−4). For the same dataset, the signal-to-noise ratio improved from 16.1 to 31.0. The increased computational demand per iteration is compensated for by a faster convergence rate, such that the overall performance is approximately identical for blobs and voxels.
CONCLUSIONS: Despite the higher complexity, tomographic reconstruction from computed laminography data should be implemented using blob basis functions, especially if noisy data is expected.},
	language = {en},
	author = {Trampert, Patrick and Vogelgesang, Jonas and Schorr, Christian and Maisl, Michael and Bogachev, Sviatoslav and Marniok, Nico and Louis, Alfred and Dahmen, Tim and Slusallek, Philipp},
	pages = {14},
	file = {Trampert et al. - Spherically symmetric volume elements as basis fun.pdf:/home/david/Zotero/storage/LRF6XNWR/Trampert et al. - Spherically symmetric volume elements as basis fun.pdf:application/pdf},
}

@book{prautzsch_bezier_2002,
	address = {Berlin, Heidelberg},
	series = {Mathematics and {Visualization}},
	title = {Bézier and {B}-{Spline} {Techniques}},
	isbn = {978-3-642-07842-2 978-3-662-04919-8},
	url = {http://link.springer.com/10.1007/978-3-662-04919-8},
	language = {en},
	urldate = {2021-12-14},
	publisher = {Springer Berlin Heidelberg},
	author = {Prautzsch, Hartmut and Boehm, Wolfgang and Paluszny, Marco},
	editor = {Farin, Gerald and Hege, Hans-Christian and Hoffman, David and Johnson, Christopher R. and Polthier, Konrad},
	year = {2002},
	doi = {10.1007/978-3-662-04919-8},
	file = {Prautzsch et al. - 2002 - Bézier and B-Spline Techniques.pdf:/home/david/Zotero/storage/ZKMQQT7S/Prautzsch et al. - 2002 - Bézier and B-Spline Techniques.pdf:application/pdf;Prautzsch et al. - 2002 - Bézier and B-Spline Techniques.pdf:/home/david/Zotero/storage/G56H24QZ/Prautzsch et al. - 2002 - Bézier and B-Spline Techniques.pdf:application/pdf},
}

@article{bilbaocastro_exploiting_2009,
	title = {Exploiting desktop supercomputing for three-dimensional electron microscopy reconstructions using {ART} with blobs},
	volume = {165},
	issn = {10478477},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1047847708002323},
	doi = {10.1016/j.jsb.2008.09.009},
	abstract = {Three-dimensional electron microscopy allows direct visualization of biological macromolecules close to their native state. The high impact of this technique in the structural biology ﬁeld is highly correlated with the development of new image processing algorithms. In order to achieve subnanometer resolution, the size and number of images involved in a three-dimensional reconstruction increase and so do computer requirements. New chips integrating multiple processors are hitting the market at a reduced cost. This high-integration, low-cost trend has just begun and is expected to bring real supercomputers to our laboratory desktops in the coming years. This paper proposes a parallel implementation of a computation-intensive algorithm for three-dimensional reconstruction, ART, that takes advantage of the computational power in modern multicore platforms. ART is a sophisticated iterative reconstruction algorithm that has turned out to be well suited for the conditions found in threedimensional electron microscopy. In view of the performance obtained in this work, these modern platforms are expected to play an important role to face the future challenges in three-dimensional electron microscopy.},
	language = {en},
	number = {1},
	urldate = {2021-12-14},
	journal = {Journal of Structural Biology},
	author = {Bilbaocastro, J and Marabini, R and Sorzano, C and Garcia, I and Carazo, J and Fernandez, J},
	month = jan,
	year = {2009},
	pages = {19--26},
	file = {Bilbaocastro et al. - 2009 - Exploiting desktop supercomputing for three-dimens.pdf:/home/david/Zotero/storage/25ZICI85/Bilbaocastro et al. - 2009 - Exploiting desktop supercomputing for three-dimens.pdf:application/pdf},
}

@article{eberly_b-spline_nodate,
	title = {B-{Spline} {Interpolation} on {Lattices}},
	language = {en},
	author = {Eberly, David},
	pages = {41},
	file = {Eberly - B-Spline Interpolation on Lattices.pdf:/home/david/Zotero/storage/7ETA2HKS/Eberly - B-Spline Interpolation on Lattices.pdf:application/pdf},
}

@article{prochazkova_derivative_nodate,
	title = {{DERIVATIVE} {OF} {B}-{SPLINE} {FUNCTION}},
	abstract = {Derivatives are very important in computation in engineering practice on graphics structures. B-spline functions are deﬁned recursive, so direct computation is very diﬃcult. In this article is shown the proof of formula for simpler direct computation of derivatives and its application for derivatives of NURBS curves.},
	language = {en},
	author = {Prochazkova, Jana},
	pages = {6},
	file = {Prochazkova - DERIVATIVE OF B-SPLINE FUNCTION.pdf:/home/david/Zotero/storage/H86WX7IR/Prochazkova - DERIVATIVE OF B-SPLINE FUNCTION.pdf:application/pdf},
}

@article{censor_developments_2021,
	title = {Developments in {Mathematical} {Algorithms} and {Computational} {Tools} for {Proton} {CT} and {Particle} {Therapy} {Treatment} {Planning}},
	issn = {2469-7303},
	doi = {10.1109/TRPMS.2021.3107322},
	abstract = {We summarize recent results and ongoing activities in mathematical algorithms and computer science methods related to proton computed tomography (pCT) and intensity-modulated particle therapy (IMPT) treatment planning. Proton therapy necessitates a high level of delivery accuracy to exploit the selective targeting imparted by the Bragg peak. For this purpose, pCT utilizes the proton beam itself to create images. The technique works by sending a low-intensity beam of protons through the patient and measuring the position, direction, and energy loss of each exiting proton. The pCT technique allows reconstruction of the volumetric distribution of the relative stopping power (RSP) of the patient tissues for use in treatment planning and pre-treatment range verification. We have investigated new ways to make the reconstruction both efficient and accurate. Better accuracy of RSP also enables more robust inverse approaches to IMPT. For IMPT, we developed a framework for performing intensity-modulation of the proton pencil beams. We expect that these developments will lead to additional project work in the years to come, which requires a regular exchange between experts in the fields of mathematics, computer science, and medical physics. We have initiated such an exchange by organizing annual workshops on pCT and IMPT algorithm and technology developments. This report is, admittedly, tilted toward our interdisciplinary work and methods. We offer a comprehensive overview of results, problems, and challenges in pCT and IMPT with the aim of making other scientists wanting to tackle such issues and to strengthen their interdisciplinary collaboration by bringing together cutting-edge know-how from medicine, computer science, physics, and mathematics to bear on medical physics problems at hand.},
	journal = {IEEE Transactions on Radiation and Plasma Medical Sciences},
	author = {Censor, Yair and Schubert, Keith E. and Schulte, Reinhard W.},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Radiation and Plasma Medical Sciences},
	keywords = {Image reconstruction, blob basis functions, data partitioning, digital phantoms, intensity-modulated therapy, Inverse problems, Medical treatment, Monte Carlo simulation, motion-adapted reconstruction., Perturbation methods, Planning, Plasmas, proton computed tomography, proton therapy, Protons, superiorization},
	pages = {1--1},
	file = {IEEE Xplore Full Text PDF:/home/david/Zotero/storage/I45JGSBD/Censor et al. - 2021 - Developments in Mathematical Algorithms and Comput.pdf:application/pdf},
}

@article{horbelt_discretization_2002,
	title = {Discretization of the radon transform and of its inverse by spline convolutions},
	volume = {21},
	issn = {1558-254X},
	doi = {10.1109/TMI.2002.1000260},
	abstract = {We present an explicit formula for B-spline convolution kernels; these are defined as the convolution of several B-splines of variable widths h/sub i/ and degrees n/sub i/. We apply our results to derive spline-convolution-based algorithms for two closely related problems: the computation of the Radon transform and of its inverse. First, we present an efficient discrete implementation of the Radon transform that is optimal in the least-squares sense. We then consider the reverse problem and introduce a new spline-convolution version of the filtered back-projection algorithm for tomographic reconstruction. In both cases, our explicit kernel formula allows for the use of high-degree splines; these offer better approximation performance than the conventional lower-degree formulations (e.g., piecewise constant or piecewise linear models). We present multiple experiments to validate our approach and to find the parameters that give the best tradeoff between image quality and computational complexity. In particular, we find that it can be computationally more efficient to increase the approximation degree than to increase the sampling rate.},
	number = {4},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Horbelt, S. and Liebling, M. and Unser, M.},
	month = apr,
	year = {2002},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Kernel, Spline, Image reconstruction, Image quality, Tomography, Computational complexity, Discrete transforms, Image sampling, Piecewise linear approximation, Piecewise linear techniques},
	pages = {363--376},
	file = {Horbelt et al. - 2002 - Discretization of the radon transform and of its i.pdf:/home/david/Zotero/storage/HUAUNN4V/Horbelt et al. - 2002 - Discretization of the radon transform and of its i.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/HHGPFXCE/1000260.html:text/html},
}

@misc{noauthor_b-spline_nodate,
	title = {B-{Spline} {Convolution}-based {Radon} and {Inverse} {Radon} {Transforms}},
	url = {http://sybil.ece.ucsb.edu/pages/splineradon/splineradon.html},
	urldate = {2021-12-15},
	file = {B-Spline Convolution-based Radon and Inverse Radon.html:/home/david/Zotero/storage/NS55MF6W/B-Spline Convolution-based Radon and Inverse Radon.html:text/html},
}

@book{richter_inverse_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Geosystems} {Mathematics} and {Computing}},
	title = {Inverse {Problems}: {Basics}, {Theory} and {Applications} in {Geophysics}},
	isbn = {978-3-030-59316-2 978-3-030-59317-9},
	shorttitle = {Inverse {Problems}},
	url = {https://link.springer.com/10.1007/978-3-030-59317-9},
	language = {en},
	urldate = {2021-12-18},
	publisher = {Springer International Publishing},
	author = {Richter, Mathias},
	year = {2020},
	doi = {10.1007/978-3-030-59317-9},
	file = {Richter - 2020 - Inverse Problems Basics, Theory and Applications .pdf:/home/david/Zotero/storage/ZBBTFXUR/Richter - 2020 - Inverse Problems Basics, Theory and Applications .pdf:application/pdf},
}

@book{vogel_computational_2002,
	title = {Computational {Methods} for {Inverse} {Problems}},
	isbn = {978-0-89871-550-7 978-0-89871-757-0},
	url = {http://epubs.siam.org/doi/book/10.1137/1.9780898717570},
	language = {en},
	urldate = {2021-12-18},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Vogel, Curtis R.},
	month = jan,
	year = {2002},
	doi = {10.1137/1.9780898717570},
	file = {Vogel - 2002 - Computational Methods for Inverse Problems - 9 Non.pdf:/home/david/Zotero/storage/NRGYWZBK/Vogel - 2002 - Computational Methods for Inverse Problems - 9 Non.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 8 Tot.pdf:/home/david/Zotero/storage/XSQBCD2M/Vogel - 2002 - Computational Methods for Inverse Problems - 8 Tot.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 6 Par.pdf:/home/david/Zotero/storage/4FZGLZUN/Vogel - 2002 - Computational Methods for Inverse Problems - 6 Par.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 7 Reg.pdf:/home/david/Zotero/storage/2MN6YHPI/Vogel - 2002 - Computational Methods for Inverse Problems - 7 Reg.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 4 Sta.pdf:/home/david/Zotero/storage/LIYLI3NK/Vogel - 2002 - Computational Methods for Inverse Problems - 4 Sta.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 3 Num.pdf:/home/david/Zotero/storage/BTKSSJBY/Vogel - 2002 - Computational Methods for Inverse Problems - 3 Num.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 5 Ima.pdf:/home/david/Zotero/storage/56VE67RI/Vogel - 2002 - Computational Methods for Inverse Problems - 5 Ima.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 2 Ana.pdf:/home/david/Zotero/storage/S5RRT4FC/Vogel - 2002 - Computational Methods for Inverse Problems - 2 Ana.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems - 1 Int.pdf:/home/david/Zotero/storage/T9A4SIW5/Vogel - 2002 - Computational Methods for Inverse Problems - 1 Int.pdf:application/pdf;Vogel - 2002 - Computational Methods for Inverse Problems.pdf:/home/david/Zotero/storage/NL73W2WJ/Vogel - 2002 - Computational Methods for Inverse Problems.pdf:application/pdf},
}

@book{kirsch_introduction_2021,
	address = {Cham},
	series = {Applied {Mathematical} {Sciences}},
	title = {An {Introduction} to the {Mathematical} {Theory} of {Inverse} {Problems}},
	volume = {120},
	isbn = {978-3-030-63342-4 978-3-030-63343-1},
	url = {http://link.springer.com/10.1007/978-3-030-63343-1},
	language = {en},
	urldate = {2021-12-18},
	publisher = {Springer International Publishing},
	author = {Kirsch, Andreas},
	year = {2021},
	doi = {10.1007/978-3-030-63343-1},
	file = {Kirsch - 2021 - An Introduction to the Mathematical Theory of Inve.pdf:/home/david/Zotero/storage/BQR246X7/Kirsch - 2021 - An Introduction to the Mathematical Theory of Inve.pdf:application/pdf},
}

@article{hanson_local_1985,
	title = {Local basis-function approach to computed tomography},
	volume = {24},
	issn = {0003-6935, 1539-4522},
	url = {https://www.osapublishing.org/abstract.cfm?URI=ao-24-23-4028},
	doi = {10.1364/AO.24.004028},
	language = {en},
	number = {23},
	urldate = {2021-12-19},
	journal = {Applied Optics},
	author = {Hanson, Kenneth M. and Wecksung, George W.},
	month = dec,
	year = {1985},
	pages = {4028},
	file = {Hanson and Wecksung - 1985 - Local basis-function approach to computed tomograp.pdf:/home/david/Zotero/storage/S2GK5W4M/Hanson and Wecksung - 1985 - Local basis-function approach to computed tomograp.pdf:application/pdf},
}

@article{unser_splines_1999,
	title = {Splines: a perfect fit for signal and image processing},
	volume = {16},
	issn = {10535888},
	shorttitle = {Splines},
	url = {http://ieeexplore.ieee.org/document/799930/},
	doi = {10.1109/79.799930},
	language = {en},
	number = {6},
	urldate = {2021-12-19},
	journal = {IEEE Signal Processing Magazine},
	author = {Unser, M.},
	month = nov,
	year = {1999},
	pages = {22--38},
	file = {Unser - 1999 - Splines a perfect fit for signal and image proces.pdf:/home/david/Zotero/storage/PPM7DBKS/Unser - 1999 - Splines a perfect fit for signal and image proces.pdf:application/pdf},
}

@incollection{hawkes_brief_2002,
	series = {Advances in {Imaging} and {Electron} {Physics}},
	title = {A {Brief} {Walk} {Through} {Sampling} {Theory}},
	volume = {124},
	url = {https://www.sciencedirect.com/science/article/pii/S1076567002800428},
	publisher = {Elsevier},
	author = {García, Antonio G.},
	editor = {Hawkes, Peter W.},
	year = {2002},
	doi = {https://doi.org/10.1016/S1076-5670(02)80042-8},
	note = {ISSN: 1076-5670},
	pages = {63--137},
}

@article{unser_sampling-50_2000,
	title = {Sampling-50 years after {Shannon}},
	volume = {88},
	issn = {0018-9219, 1558-2256},
	url = {http://ieeexplore.ieee.org/document/843002/},
	doi = {10.1109/5.843002},
	language = {en},
	number = {4},
	urldate = {2021-12-19},
	journal = {Proceedings of the IEEE},
	author = {Unser, M.},
	month = apr,
	year = {2000},
	pages = {569--587},
	file = {Unser - 2000 - Sampling-50 years after Shannon.pdf:/home/david/Zotero/storage/TEZLLYM7/Unser - 2000 - Sampling-50 years after Shannon.pdf:application/pdf},
}

@article{harauz_interpolation_1983,
	title = {Interpolation in computing forward projections in direct three-dimensional reconstruction},
	volume = {28},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/0031-9155/28/12/007},
	doi = {10.1088/0031-9155/28/12/007},
	language = {en},
	number = {12},
	urldate = {2021-12-19},
	journal = {Physics in Medicine and Biology},
	author = {Harauz, G and Ottensmeyer, F P},
	month = dec,
	year = {1983},
	pages = {1419--1427},
	file = {Harauz and Ottensmeyer - 1983 - Interpolation in computing forward projections in .pdf:/home/david/Zotero/storage/67GNPXG6/Harauz and Ottensmeyer - 1983 - Interpolation in computing forward projections in .pdf:application/pdf},
}

@article{peters_algorithms_1981,
	title = {Algorithms for {Fast} {Back}- and {Re}-{Projection} in {Computed} {Tomography}},
	volume = {28},
	issn = {0018-9499},
	url = {http://ieeexplore.ieee.org/document/4331812/},
	doi = {10.1109/TNS.1981.4331812},
	abstract = {While the computation time for reconstructing images in C.T. is not a problem in commercial systems, there are many experimental and developmental applications where resources are limited and image reconstruction places a heavy burden on the computer system. This paper describes a very efficient backI projection algorithm which results in large time savings when implemented in machine code. Also described is a minor modification to this algorithm which converts it to a re-projection procedure with comparable efficiency.},
	language = {en},
	number = {4},
	urldate = {2021-12-19},
	journal = {IEEE Transactions on Nuclear Science},
	author = {Peters, T. M.},
	year = {1981},
	pages = {3641--3647},
	file = {Peters - 1981 - Algorithms for Fast Back- and Re-Projection in Com.pdf:/home/david/Zotero/storage/AV4FBMUV/Peters - 1981 - Algorithms for Fast Back- and Re-Projection in Com.pdf:application/pdf},
}

@article{joseph_improved_1982,
	title = {An {Improved} {Algorithm} for {Reprojecting} {Rays} through {Pixel} {Images}},
	volume = {1},
	issn = {0278-0062, 1558-254X},
	url = {http://ieeexplore.ieee.org/document/4307572/},
	doi = {10.1109/TMI.1982.4307572},
	abstract = {It is often desired to calculate line integrals through a field of reconstructed CT density pixels for the purpose of improving CT image quality. Two algorithms widely published and discussed in the past are known to either degrade spatial resolution or generate errors in the results due to the discontinuous "square pixel" modeling of the reconstructed image. An algorithm is described, based on linear interpolation between pixels, which provides superior accuracy without unnecessary loss of resolution. It was tested on simulated data for a head section and on a narrow Gaussian density distribution. The experimental results demonstrated improved performance. The method is expected to prove useful for many types of post-reconstruction processing, including beam hardening, missing data, and noise supression algorithms.},
	language = {en},
	number = {3},
	urldate = {2021-12-19},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Joseph, Peter M.},
	month = nov,
	year = {1982},
	pages = {192--196},
	file = {Joseph - 1982 - An Improved Algorithm for Reprojecting Rays throug.pdf:/home/david/Zotero/storage/TWI9GP6K/Joseph - 1982 - An Improved Algorithm for Reprojecting Rays throug.pdf:application/pdf},
}

@article{siddon_fast_1985,
	title = {Fast calculation of the exact radiological path for a three-dimensional {CT} array},
	volume = {12},
	issn = {2473-4209},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1118/1.595715},
	doi = {10.1118/1.595715},
	abstract = {Ready availability has prompted the use of computed tomography (CT) data in various applications in radiation therapy. For example, some radiation treatment planning systems now utilize CT data in heterogeneous dose calculation algorithms. In radiotherapy imaging applications, CT data are projected onto specified planes, thus producing “radiographs,” which are compared with simulator radiographs to assist in proper patient positioning and delineation of target volumes. All these applications share the common geometric problem of evaluating the radiological path through the CT array. Due to the complexity of the three-dimensional geometry and the enormous amount of CT data, the exact evaluation of the radiological path has proven to be a time consuming and difficult problem. This paper identifies the inefficient aspect of the traditional exact evaluation of the radiological path as that of treating the CT data as individual voxels. Rather than individual voxels, a new exact algorithm is presented that considers the CT data as consisting of the intersection volumes of three orthogonal sets of equally spaced, parallel planes. For a three-dimensional CT array of N3 voxels, the new exact algorithm scales with 3N, the number of planes, rather than N3, the number of voxels. Coded in fortran-77 on a VAX 11/780 with a floating point option, the algorithm requires approximately 5 ms to calculate an average radiological path in a 1003 voxel array.},
	language = {en},
	number = {2},
	urldate = {2021-12-19},
	journal = {Medical Physics},
	author = {Siddon, Robert L.},
	year = {1985},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1118/1.595715},
	keywords = {Biomedical imaging, Computed tomography, BIOMEDICAL RADIOGRAPHY, COMPUTERIZED TOMOGRAPHY, DIAGNOSTIC TECHNIQUES, Dosimetry, INHOMOGENEITY, Medical imaging, Non-ionizing radiation equipment and techniques, Radiation therapy, Radiation treatment, Radiography, RADIOTHERAPY},
	pages = {252--255},
	file = {Siddon - 1985 - Fast calculation of the exact radiological path fo.pdf:/home/david/Zotero/storage/YD5NEAPA/Siddon - 1985 - Fast calculation of the exact radiological path fo.pdf:application/pdf},
}

@inproceedings{zhao_fast_2004,
	address = {Portland, OR, USA},
	title = {Fast ray-tracing technique to calculate line integral paths in voxel arrays},
	isbn = {978-0-7803-8257-2},
	url = {http://ieeexplore.ieee.org/document/1352469/},
	doi = {10.1109/NSSMIC.2003.1352469},
	abstract = {The ray-driven projection and back-projection methods, frequently represented as calculating the path of line integration through a pixel or voxel space, are widely applied in various imaging research ﬁelds such as positron emission tomography (PET), computerized tomography (CT) and other volumetric ray tracing studies. For high resolution iterative image reconstruction with large amount of sample events, computing the projections event-by-event is an extremely time consuming task. This paper presents a novel ray-tracing calculation technique applying to a list-mode EM image reconstruction algorithm as a part of the system model to accelerate its projection operations. Compared to both the conventional Siddon algorithm and its accelerated methods, the new algorithm has less average computation operation time on each voxel. The results show that the new algorithm signiﬁcantly improves the calculation speed up to twice as fast than the incremental Siddon algorithm.},
	language = {en},
	urldate = {2021-12-19},
	booktitle = {2003 {IEEE} {Nuclear} {Science} {Symposium}. {Conference} {Record} ({IEEE} {Cat}. {No}.{03CH37515})},
	publisher = {IEEE},
	author = {Zhao, Huaxia and Reader, A.J.},
	year = {2004},
	pages = {2808--2812},
	file = {Zhao and Reader - 2004 - Fast ray-tracing technique to calculate line integ.pdf:/home/david/Zotero/storage/3NUNEXV8/Zhao and Reader - 2004 - Fast ray-tracing technique to calculate line integ.pdf:application/pdf},
}

@article{gullberg_attenuated_1985,
	title = {An attenuated projector-backprojector for iterative {SPECT} reconstruction},
	volume = {30},
	issn = {0031-9155},
	url = {https://iopscience.iop.org/article/10.1088/0031-9155/30/8/004},
	doi = {10.1088/0031-9155/30/8/004},
	abstract = {A new ray-driuen projector-backprojector which can easily be adapted for hardware implementation is described and simulated in software. The projector-backprcjector discretely models the attenuated Radon transform of a source distributed within an attenuating medium as line integrals of discrete pixels, obtained using the standard sampling technique of averaging the emission source or attenuation distribution over small\$square regions. Attenuation factors are calculated for each pixel during the projection and backprojection operations instead of using precalculated values. The calculation of the factors requires a specification of the attenuation distribution, estimated either from an assumed constant distribution and an approximate body outline or from transmission measurements. The distribution of attenuation coefficientsis stored in memory for efficient access during the projection and backprojection operations. The reconstruction of the source distribution is obtained by using a conjugate gradient or SIRTtype iterative algorithm which requires one projection and one backprojection operation for each iteration.},
	language = {en},
	number = {8},
	urldate = {2021-12-19},
	journal = {Physics in Medicine and Biology},
	author = {Gullberg, G T and Huesman, R H and Malko, J A and Pelc, N J and Budinger, T F},
	month = aug,
	year = {1985},
	pages = {799--816},
	file = {Gullberg et al. - 1985 - An attenuated projector-backprojector for iterativ.pdf:/home/david/Zotero/storage/DSMCP9TB/Gullberg et al. - 1985 - An attenuated projector-backprojector for iterativ.pdf:application/pdf},
}

@article{christiaens_fast_1999,
	title = {A fast, cache-aware algorithm for the calculation of radiological paths exploiting subword parallelism},
	volume = {45},
	issn = {13837621},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1383762198000381},
	doi = {10.1016/S1383-7621(98)00038-1},
	language = {en},
	number = {10},
	urldate = {2021-12-19},
	journal = {Journal of Systems Architecture},
	author = {Christiaens, Mark and De Sutter, Bjorn and De Bosschere, Koen and Van Campenhout, Jan and Lemahieu, Ignace},
	month = apr,
	year = {1999},
	pages = {781--790},
	file = {Christiaens et al. - 1999 - A fast, cache-aware algorithm for the calculation .pdf:/home/david/Zotero/storage/8RB4RBWU/Christiaens et al. - 1999 - A fast, cache-aware algorithm for the calculation .pdf:application/pdf},
}

@article{de_man_distance-driven_2004,
	title = {Distance-driven projection and backprojection in three dimensions},
	volume = {49},
	issn = {0031-9155, 1361-6560},
	url = {https://iopscience.iop.org/article/10.1088/0031-9155/49/11/024},
	doi = {10.1088/0031-9155/49/11/024},
	abstract = {Projection and backprojection are operations that arise frequently in tomographic imaging. Recently, we proposed a new method for projection and backprojection, which we call distance-driven, and that offers low arithmetic cost and a highly sequential memory access pattern. Furthermore, distance-driven projection and backprojection avoid several artefact-inducing approximations characteristic of some other methods. We have previously demonstrated the application of this method to parallel and fan beam geometries. In this paper, we extend the distance-driven framework to three dimensions and demonstrate its application to cone beam reconstruction. We also present experimental results to demonstrate the computational performance, the artefact characteristics and the noise-resolution characteristics of the distance-driven method in three dimensions.},
	language = {en},
	number = {11},
	urldate = {2021-12-19},
	journal = {Physics in Medicine and Biology},
	author = {De Man, B. and Basu, S.},
	month = jun,
	year = {2004},
	pages = {2463--2475},
	file = {De Man and Basu - 2004 - Distance-driven projection and backprojection in t.pdf:/home/david/Zotero/storage/NVBE3FUL/De Man and Basu - 2004 - Distance-driven projection and backprojection in t.pdf:application/pdf},
}

@inproceedings{de_man_distance-driven_2002,
	title = {Distance-driven projection and backprojection},
	volume = {3},
	doi = {10.1109/NSSMIC.2002.1239600},
	abstract = {Projection and backprojection are important processes in computed tomography (CT). They are used in iterative reconstruction, simulation, and artifact correction, as well as routine (filtered-backprojection based) reconstruction. Existing methods either have poor performance or result in artifacts. A new method for projecting and backprojecting rays through pixels is presented that has good performance and eliminates artifacts, and could potentially enable routine iterative reconstruction in clinical CT systems. The new method, which we call distance-driven, reconciles the advantages of the common pixel-driven and ray-driven methods. It avoids an artifact-inducing approximation made by the previous methods and has very favorable computational properties. The method is applicable to parallel-beam, fanbeam, and cone-beam geometries. Its performance and artifact behavior are evaluated on a two-dimensional fan-beam geometry with flat detector and compared to the pixel-driven and ray-driven approaches. The distance-driven method prevents the artifacts that are generated in the pixel-driven projection and in the ray-driven backprojection. It outperforms pixel-driven and ray-driven methods from a computational standpoint and is amenable to hardware implementation.},
	booktitle = {2002 {IEEE} {Nuclear} {Science} {Symposium} {Conference} {Record}},
	author = {De Man, B. and Basu, S.},
	month = nov,
	year = {2002},
	keywords = {Computed tomography, Detectors, Image reconstruction, Computational modeling, Geometry, Hardware, Image converters, Image generation, Iterative methods, X-ray imaging},
	pages = {1477--1480 vol.3},
	file = {De Man and Basu - 2002 - Distance-driven projection and backprojection.pdf:/home/david/Zotero/storage/YFYHSSJK/De Man and Basu - 2002 - Distance-driven projection and backprojection.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/2GMTKNYD/1239600.html:text/html},
}

@article{liu_gpu-based_2017,
	title = {{GPU}-{Based} {Branchless} {Distance}-{Driven} {Projection} and {Backprojection}},
	volume = {3},
	issn = {2333-9403},
	doi = {10.1109/TCI.2017.2675705},
	abstract = {Projection and backprojection operations are essential in a variety of image reconstruction and physical correction algorithms in computed tomography (CT). The distance-driven (DD) projection and backprojection are widely used for their favorable image quality properties, highly sequential memory access pattern and low arithmetic cost. However, a typical DD implementation has an inner loop that adjusts the calculation depending on the relative position between voxel and detector cell boundaries. The irregularity of the branch behavior makes it inefficient to be implemented on massively parallel computing devices, such as graphics processing units (GPUs). Such irregular branch behaviors can be eliminated by factorizing the DD operation as three branchless steps: integration, linear interpolation, and differentiation, all of which are highly amenable to massive vectorization. In this paper, we implement and evaluate a highly parallel branchless DD algorithm for three-dimensional cone beam CT. The algorithm utilizes the texture memory and hardware interpolation on GPUs to achieve fast computational speed. The developed branchless DD algorithm achieved 137-fold speedup for forward projection and 188-fold speedup for backprojection relative to a single-thread CPU implementation. Compared with a state-of-the-art 32-thread CPU implementation, the proposed branchless DD achieved eight-fold acceleration for forward projection and ten-fold acceleration for backprojection. The GPU-based branchless DD method was evaluated by iterative reconstruction algorithms with both simulation and real datasets. It obtained visually identical images as the CPU reference algorithm.},
	number = {4},
	journal = {IEEE Transactions on Computational Imaging},
	author = {Liu, Rui and Fu, Lin and De Man, Bruno and Yu, Hengyong},
	month = dec,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Computational Imaging},
	keywords = {Computed tomography, Detectors, Image reconstruction, Computational modeling, Algorithm design and analysis, backprojection, Branchless distance-driven, computed tomography, GPU, Graphics processing units, projection, reconstruction},
	pages = {617--632},
	file = {Liu et al. - 2017 - GPU-Based Branchless Distance-Driven Projection an.pdf:/home/david/Zotero/storage/2SUS8GEE/Liu et al. - 2017 - GPU-Based Branchless Distance-Driven Projection an.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/GGRE8SD7/7866886.html:text/html},
}

@article{long_3d_2010,
	title = {{3D} {Forward} and {Back}-{Projection} for {X}-{Ray} {CT} {Using} {Separable} {Footprints}},
	volume = {29},
	issn = {1558-254X},
	doi = {10.1109/TMI.2010.2050898},
	abstract = {Iterative methods for 3D image reconstruction have the potential to improve image quality over conventional filtered back projection (FBP) in X-ray computed tomography (CT). However, the computation burden of 3D cone-beam forward and back-projectors is one of the greatest challenges facing practical adoption of iterative methods for X-ray CT. Moreover, projector accuracy is also important for iterative methods. This paper describes two new separable footprint (SF) projector methods that approximate the voxel footprint functions as 2D separable functions. Because of the separability of these footprint functions, calculating their integrals over a detector cell is greatly simplified and can be implemented efficiently. The SF-TR projector uses trapezoid functions in the transaxial direction and rectangular functions in the axial direction, whereas the SF-TT projector uses trapezoid functions in both directions. Simulations and experiments showed that both SF projector methods are more accurate than the distance-driven (DD) projector, which is a current state-of-the-art method in the field. The SF-TT projector is more accurate than the SF-TR projector for rays associated with large cone angles. The SF-TR projector has similar computation speed with the DD projector and the SF-TT projector is about two times slower.},
	number = {11},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Long, Yong and Fessler, Jeffrey A. and Balter, James M.},
	month = nov,
	year = {2010},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Computed tomography, Detectors, Image reconstruction, Image quality, Iterative methods, Argon, Cone-beam tomography, forward and back-projection, iterative tomographic image reconstruction, Permission, Postal services, Reconstruction algorithms, USA Councils},
	pages = {1839--1850},
	file = {Long et al. - 2010 - 3D Forward and Back-Projection for X-Ray CT Using .pdf:/home/david/Zotero/storage/KZKMICNW/Long et al. - 2010 - 3D Forward and Back-Projection for X-Ray CT Using .pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/4BP54L79/5482021.html:text/html},
}

@article{long_3d_nodate,
	title = {{3D} {Forward} and {Back}-{Projection} for {X}-{Ray} {CT} {Using} {Separable} {Footprints} with {Trapezoid} {Functions}},
	abstract = {The greatest impediment to practical adoption of iterative methods for X-ray CT is the computation burden of cone-beam forward and back-projectors. Moreover, forward and back-projector accuracy is also crucial to iterative reconstruction methods. We previously described a computationally efﬁcient projector that approximates the voxel footprint functions by the 2D separable products of trapezoid functions in the transaxial plane and rectangular functions in the axial direction [1], [2]. The separability of these footprint functions simpliﬁes calculating their integrals over rectangular detector cells. We showed that this separable footprint (SF-TR) method was more accurate than the distance-driven (DD) method but with comparable computation time. This paper describes a new extension of that projector, called the SF-TT projector, that uses trapezoid functions in both directions. We show that using a trapezoid along the axial direction improves projector accuracy for voxels associated with larger cone angles. However, this improved accuracy requires increased computation compared to the rectangular approximation. Having both options available facilitates evaluation of the trade offs between accuracy and computation for different cone-beam geometries.},
	language = {en},
	author = {Long, Yong and Fessler, Jeffrey A},
	pages = {4},
	file = {Long and Fessler - 3D Forward and Back-Projection for X-Ray CT Using .pdf:/home/david/Zotero/storage/EB74DSN6/Long and Fessler - 3D Forward and Back-Projection for X-Ray CT Using .pdf:application/pdf},
}

@article{ziegler_efficient_2006,
	title = {Efficient projection and backprojection scheme for spherically symmetric basis functions in divergent beam geometry: {Efficient} projection and backprojection scheme},
	volume = {33},
	issn = {00942405},
	shorttitle = {Efficient projection and backprojection scheme for spherically symmetric basis functions in divergent beam geometry},
	url = {http://doi.wiley.com/10.1118/1.2388570},
	doi = {10.1118/1.2388570},
	language = {en},
	number = {12},
	urldate = {2021-12-19},
	journal = {Medical Physics},
	author = {Ziegler, Andy and Köhler, Thomas and Nielsen, Tim and Proksa, Roland},
	month = nov,
	year = {2006},
	pages = {4653--4663},
	file = {Ziegler et al. - 2006 - Efficient projection and backprojection scheme for.pdf:/home/david/Zotero/storage/9YQV7PGE/Ziegler et al. - 2006 - Efficient projection and backprojection scheme for.pdf:application/pdf},
}

@article{jacobs_fast_1998,
	title = {A {Fast} {Algorithm} to {Calculate} the {Exact} {Radiological} {Path} through a {Pixel} or {Voxel} {Space}},
	volume = {6},
	abstract = {Calculating the exact radiological path through a pixel or voxel space is a frequently encountered problem in medical image reconstruction from projections and greatly in uences the reconstruction time. Currently, one of the fastest algorithms designed for this purpose was published in 1985 by Robert L. Siddon 1]. In this paper, we propose an improved version of Siddon's algorithm, resulting in a considerable speedup.},
	language = {en},
	number = {1},
	journal = {Journal of computing and information technology},
	author = {Jacobs, Filip and Sundermann, Erik and Sutter, Bjorn De and Christiaens, Mark and Lemahieu, Ignace},
	year = {1998},
	pages = {14},
	file = {Jacobs et al. - 1998 - A Fast Algorithm to Calculate the Exact Radiologic.pdf:/home/david/Zotero/storage/DKCJQJTR/Jacobs et al. - 1998 - A Fast Algorithm to Calculate the Exact Radiologic.pdf:application/pdf},
}

@article{gao_fast_2012,
	title = {Fast parallel algorithms for the x-ray transform and its adjoint: {Fast} parallel x-ray transform and its adjoint},
	volume = {39},
	issn = {00942405},
	shorttitle = {Fast parallel algorithms for the x-ray transform and its adjoint},
	url = {http://doi.wiley.com/10.1118/1.4761867},
	doi = {10.1118/1.4761867},
	abstract = {Purpose: Iterative reconstruction methods often offer better imaging quality and allow for reconstructions with lower imaging dose than classical methods in computed tomography. However, the computational speed is a major concern for these iterative methods, for which the x-ray transform and its adjoint are two most time-consuming components. The speed issue becomes even notable for the 3D imaging such as cone beam scans or helical scans, since the x-ray transform and its adjoint are frequently computed as there is usually not enough computer memory to save the corresponding system matrix. The purpose of this paper is to optimize the algorithm for computing the x-ray transform and its adjoint, and their parallel computation.
Methods: The fast and highly parallelizable algorithms for the x-ray transform and its adjoint are proposed for the inﬁnitely narrow beam in both 2D and 3D. The extension of these fast algorithms to the ﬁnite-size beam is proposed in 2D and discussed in 3D.
Results: The CPU and GPU codes are available at https://sites.google.com/site/fastxraytransform. The proposed algorithm is faster than Siddon’s algorithm for computing the x-ray transform. In particular, the improvement for the parallel computation can be an order of magnitude.
Conclusions: The authors have proposed fast and highly parallelizable algorithms for the x-ray transform and its adjoint, which are extendable for the ﬁnite-size beam. The proposed algorithms are suitable for parallel computing in the sense that the computational cost per parallel thread is O(1). © 2012 American Association of Physicists in Medicine. [http://dx.doi.org/10.1118/1.4761867]},
	language = {en},
	number = {11},
	urldate = {2021-12-19},
	journal = {Medical Physics},
	author = {Gao, Hao},
	month = nov,
	year = {2012},
	pages = {7110--7120},
	file = {Gao - 2012 - Fast parallel algorithms for the x-ray transform a.pdf:/home/david/Zotero/storage/N5RT6RMA/Gao - 2012 - Fast parallel algorithms for the x-ray transform a.pdf:application/pdf},
}

@inproceedings{wu_gpu_2011,
	title = {{GPU} acceleration of {3D} forward and backward projection using separable footprints for {X}-ray {CT} image reconstruction},
	volume = {6},
	booktitle = {Proc. {Intl}. {Mtg}. on {Fully} {3D} {Image} {Recon}. in {Rad}. and {Nuc}. {Med}},
	publisher = {Citeseer},
	author = {Wu, Meng and Fessler, Jeffrey A},
	year = {2011},
	pages = {021911},
	file = {Wu and Fessler - 2011 - GPU acceleration of 3D forward and backward projec.pdf:/home/david/Zotero/storage/LQHXSY2T/Wu and Fessler - 2011 - GPU acceleration of 3D forward and backward projec.pdf:application/pdf},
}

@book{carpio_inverse_2008,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Mathematics}},
	title = {Inverse {Problems} and {Imaging}},
	volume = {1943},
	isbn = {978-3-540-78545-3 978-3-540-78547-7},
	url = {http://link.springer.com/10.1007/978-3-540-78547-7},
	language = {en},
	urldate = {2021-12-19},
	publisher = {Springer Berlin Heidelberg},
	author = {Carpio, Ana and Dorn, Oliver and Moscoso, Miguel and Natterer, Frank and Papanicolaou, George C. and Rapún, Maria Luisa and Teta, Alessandro},
	editor = {Bonilla, Luis L. and Morel, J. -M. and Takens, F. and Teissier, B.},
	year = {2008},
	doi = {10.1007/978-3-540-78547-7},
	file = {Carpio et al. - 2008 - Inverse Problems and Imaging.pdf:/home/david/Zotero/storage/WVVKLV8P/Carpio et al. - 2008 - Inverse Problems and Imaging.pdf:application/pdf},
}

@article{kaipio_statistical_2007,
	title = {Statistical inverse problems: {Discretization}, model reduction and inverse crimes},
	volume = {198},
	issn = {03770427},
	shorttitle = {Statistical inverse problems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0377042705007296},
	doi = {10.1016/j.cam.2005.09.027},
	abstract = {The article discusses the discretization of linear inverse problems. When an inverse problem is formulated in terms of inﬁnitedimensional function spaces and then discretized for computational purposes, a discretization error appears. Since inverse problems are typically ill-posed, neglecting this error may have serious consequences to the quality of the reconstruction. The Bayesian paradigm provides tools to estimate the statistics of the discretization error that is made part of the measurement and modelling errors of the estimation problem. This approach also provides tools to reduce the dimensionality of inverse problems in a controlled manner. The ideas are demonstrated with a computed example.},
	language = {en},
	number = {2},
	urldate = {2021-12-19},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Kaipio, Jari and Somersalo, Erkki},
	month = jan,
	year = {2007},
	pages = {493--504},
	file = {Kaipio and Somersalo - 2007 - Statistical inverse problems Discretization, mode.pdf:/home/david/Zotero/storage/3ZV3QANY/Kaipio and Somersalo - 2007 - Statistical inverse problems Discretization, mode.pdf:application/pdf},
}

@book{kaipio_statistical_2005,
	address = {New York},
	series = {Applied mathematical sciences},
	title = {Statistical and computational inverse problems},
	isbn = {978-0-387-22073-4},
	language = {en},
	number = {v. 160},
	publisher = {Springer},
	author = {Kaipio, Jari and Somersalo, Erkki},
	year = {2005},
	keywords = {Inverse problems (Differential equations), Numerical solutions},
	file = {Kaipio and Somersalo - 2005 - Statistical and computational inverse problems.pdf:/home/david/Zotero/storage/U5SPINME/Kaipio and Somersalo - 2005 - Statistical and computational inverse problems.pdf:application/pdf},
}

@article{wirgin_inverse_2004,
	title = {The inverse crime},
	url = {http://arxiv.org/abs/math-ph/0401050},
	abstract = {The inverse crime occurs when the same (or very nearly the same) theoretical ingredients are employed to synthesize as well as to invert data in an inverse problem. This act has been qualified as trivial and therefore to be avoided by Colton and Kress.},
	language = {en},
	urldate = {2021-12-19},
	journal = {arXiv:math-ph/0401050},
	author = {Wirgin, Armand},
	month = jan,
	year = {2004},
	note = {arXiv: math-ph/0401050},
	keywords = {Mathematical Physics},
	file = {Wirgin - 2004 - The inverse crime.pdf:/home/david/Zotero/storage/EV2FD3WY/Wirgin - 2004 - The inverse crime.pdf:application/pdf},
}

@article{savanier_magnificationdriven_2021,
	title = {Magnification‐driven {B}‐spline interpolation for cone‐beam projection and backprojection},
	volume = {48},
	issn = {0094-2405, 2473-4209},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/mp.15179},
	doi = {10.1002/mp.15179},
	abstract = {Purpose: Discretizing tomographic forward and backward operations is a crucial step in the design of model-based reconstruction algorithms. Standard projectors rely on linear interpolation, whose adjoint introduces discretization errors during backprojection. More advanced techniques are obtained through geometric footprint models that may present a high computational cost and an inner logic that is not suitable for implementation on massively parallel computing architectures. In this work, we take a fresh look at the discretization of resampling transforms and focus on the issue of magniﬁcation-induced local sampling variations by introducing a new magniﬁcation-driven interpolation approach for tomography.
Methods: Starting from the existing literature on spline interpolation for magniﬁcation purposes, we provide a mathematical formulation for discretizing a one-dimensional homography. We then extend our approach to two-dimensional representations in order to account for the geometry of cone-beam computed tomography with a ﬂat panel detector. Our new method relies on the decomposition of signals onto a space generated by nonuniform B-splines so as to capture the spatially varying magniﬁcation that locally affects sampling. We propose various degrees of approximations for a rapid implementation of the proposed approach. Our framework allows us to deﬁne a novel family of projector/backprojector pairs parameterized by the order of the employed B-splines. The state-of -the-art distance-driven interpolation appears to ﬁt into this family thus providing new insight and computational layout for this scheme. The question of data resampling at the detector level is handled and integrated with reconstruction in a single framework.
Results: Results on both synthetic data and real data using a quality assurance phantom, were performed to validate our approach. We show experimentally that our approximate implementations are associated with reduced complexity while achieving a near-optimal performance. In contrast with linear interpolation, B-splines guarantee full usage of all data samples, and thus the X-ray dose, leading to more uniform noise properties. In addition, higher-order B-splines allow analytical and iterative reconstruction to reach higher resolution. These beneﬁts appear more signiﬁcant when downsampling frames acquired by X-ray ﬂat-panel detectors with small pixels.
Conclusions: Magniﬁcation-driven B-spline interpolation is shown to provide high-accuracy projection operators with good-quality adjoints for iterative reconstruction. It equally applies to backprojection for analytical reconstruction and detector data downsampling.},
	language = {en},
	number = {10},
	urldate = {2021-12-19},
	journal = {Medical Physics},
	author = {Savanier, Marion and Riddell, Cyril and Trousset, Yves and Chouzenoux, Emilie and Pesquet, Jean‐Christophe},
	month = oct,
	year = {2021},
	pages = {6339--6361},
	file = {Savanier et al. - 2021 - Magnification‐driven B‐spline interpolation for co.pdf:/home/david/Zotero/storage/2PJDR8ND/Savanier et al. - 2021 - Magnification‐driven B‐spline interpolation for co.pdf:application/pdf},
}

@inproceedings{fehringer_versatile_2014,
	title = {A versatile tomographic forward- and backprojection approach on {Multi}-{GPUs}},
	doi = {10.1117/12.2043860},
	author = {Fehringer, Andreas and Lasser, Tobias and Zanette, Irene and Noël, Peter and Pfeiffer, Franz},
	month = mar,
	year = {2014},
	pages = {90344F},
	file = {Fehringer et al. - 2014 - A versatile tomographic forward- and backprojectio.pdf:/home/david/Zotero/storage/ZZLAIZKE/Fehringer et al. - 2014 - A versatile tomographic forward- and backprojectio.pdf:application/pdf},
}

@article{fehringer_real-time_nodate,
	title = {Real-time iterative reconstruction for x-ray computed tomography},
	language = {en},
	author = {Fehringer, Andreas},
	pages = {150},
	file = {Fehringer - Real-time iterative reconstruction for x-ray compu.pdf:/home/david/Zotero/storage/XJX6P8FE/Fehringer - Real-time iterative reconstruction for x-ray compu.pdf:application/pdf},
}

@article{xie_effective_2015,
	title = {An {Effective} {CUDA} {Parallelization} of {Projection} in {Iterative} {Tomography} {Reconstruction}},
	volume = {10},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0142184},
	doi = {10.1371/journal.pone.0142184},
	abstract = {Projection and back-projection are the most computationally intensive parts in Computed Tomography (CT) reconstruction, and are essential to acceleration of CT reconstruction algorithms. Compared to back-projection, parallelization efficiency in projection is highly limited by racing condition and thread unsynchronization. In this paper, a strategy of Fixed Sampling Number Projection (FSNP) is proposed to ensure the operation synchronization in the ray-driven projection with Graphical Processing Unit (GPU). Texture fetching is also used utilized to further accelerate the interpolations in both projection and back-projection. We validate the performance of this FSNP approach using both simulated and real conebeam CT data. Experimental results show that compare to the conventional approach, the proposed FSNP method together with texture fetching is 10{\textasciitilde}16 times faster than the conventional approach based on global memory, and thus leads to more efficient iterative algorithm in CT reconstruction.},
	language = {en},
	number = {11},
	urldate = {2021-12-19},
	journal = {PLOS ONE},
	author = {Xie, Lizhe and Hu, Yining and Yan, Bin and Wang, Lin and Yang, Benqiang and Liu, Wenyuan and Zhang, Libo and Luo, Limin and Shu, Huazhong and Chen, Yang},
	editor = {Zhang, Qinghui},
	month = nov,
	year = {2015},
	pages = {e0142184},
	file = {Xie et al. - 2015 - An Effective CUDA Parallelization of Projection in.pdf:/home/david/Zotero/storage/YC2N49UR/Xie et al. - 2015 - An Effective CUDA Parallelization of Projection in.pdf:application/pdf},
}

@article{graetz_high_2020,
	title = {High performance volume ray casting: {A} branchless generalized {Joseph} projector},
	shorttitle = {High performance volume ray casting},
	url = {http://arxiv.org/abs/1609.00958},
	abstract = {A concise and highly performant branchless formulation of a Joseph-type interpolating ray-casting algorithm for the computation of X-ray projections is presented. It efﬁciently utilizes the hardware resources of modern graphics processing units at the scale of their theoretic maximum performance reaching access rates of 600 GB/s within read-and-write memory, and is further shown to do so without compromising on image quality. The computation of X-ray projections from discrete voxel grids is an ubiquitous task in many problems related to volume image processing, including tomographic reconstruction and visualization. Although its central role has given rise to numerous publications discussing the optimal modeling of rayvolume intersections, a unique benchmark in this respect does not exist. Here, a 3D Shepp-Logan phantom is used, which allows the computation of analytic reference projections that can further serve as input to iterative reconstructions without committing the inverse crime. The proposed algorithm (GJP) is compared to the competing and widely adopted digital differential analyzer (DDA), which computes exact line-box intersections. It is thereby found to outperform the DDA on recent graphics processors in all respects: Despite accessing twice as much memory, the GJP is still able to calculate projections twice as fast. It further exhibits considerably less discretization artifacts, and neither oversampling of the DDA nor a smooth interpolation kernel within the GJP are able to improve on these results in any respect.},
	language = {en},
	urldate = {2021-12-19},
	journal = {arXiv:1609.00958 [physics]},
	author = {Graetz, Jonas},
	month = aug,
	year = {2020},
	note = {arXiv: 1609.00958},
	keywords = {Physics - Medical Physics, Computer Science - Graphics},
	file = {Graetz - 2020 - High performance volume ray casting A branchless .pdf:/home/david/Zotero/storage/L4G45GGK/Graetz - 2020 - High performance volume ray casting A branchless .pdf:application/pdf},
}

@inproceedings{flohr_accelerating_2017,
	address = {Orlando, Florida, United States},
	title = {Accelerating separable footprint ({SF}) forward and back projection on {GPU}},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2252010},
	doi = {10.1117/12.2252010},
	abstract = {Statistical image reconstruction (SIR) methods for X-ray CT can improve image quality and reduce radiation dosages over conventional reconstruction methods, such as ﬁltered back projection (FBP). However, SIR methods require much longer computation time. The separable footprint (SF) forward and back projection technique simpliﬁes the calculation of intersecting volumes of image voxels and ﬁnite-size beams in a way that is both accurate and eﬃcient for parallel implementation. We propose a new method to accelerate the SF forward and back projection on GPU with NVIDIA’s CUDA environment. For the forward projection, we parallelize over all detector cells. For the back projection, we parallelize over all 3D image voxels. The simulation results show that the proposed method is faster than the acceleration method of the SF projectors proposed by Wu and Fessler.13 We further accelerate the proposed method using multiple GPUs. The results show that the computation time is reduced approximately proportional to the number of GPUs.},
	language = {en},
	urldate = {2021-12-19},
	author = {Xie, Xiaobin and McGaffin, Madison G. and Long, Yong and Fessler, Jeffrey A. and Wen, Minhua and Lin, James},
	editor = {Flohr, Thomas G. and Lo, Joseph Y. and Gilat Schmidt, Taly},
	month = mar,
	year = {2017},
	pages = {101322S},
	file = {Xie et al. - 2017 - Accelerating separable footprint (SF) forward and .pdf:/home/david/Zotero/storage/FV6ULIGW/Xie et al. - 2017 - Accelerating separable footprint (SF) forward and .pdf:application/pdf},
}

@inproceedings{ha_efficient_2016,
	address = {Bamberg},
	title = {Efficient {Area}-{Based} {Ray} {Integration} {Using} {Summed} {Area} {Tables} and {Regression} {Models}},
	abstract = {The increasing popularity of iterative reconstruction algorithms has raised the attention onto how to build more accurate, realistic CT system models. In our work, we model the CT projectors based on volume integrals. The higher computational complexity in computing the exact volume integration is hidden by memory-efficient, fast, and accurate look-up tables. For further reductions we also derive a simple linear regression model from the table. We demonstrate our ideas with data obtained with a fan-beam flat-detector CT system. We observe speed-ups of up to 30\% while keeping a higher or at least similar image quality than existing advanced CT system models.},
	language = {en},
	author = {Ha, Sungsoo and Li, Heyi and Mueller, Klaus},
	year = {2016},
	pages = {4},
	file = {Ha et al. - 2016 - Efficient Area-Based Ray Integration Using Summed .pdf:/home/david/Zotero/storage/HS9Y4JLD/Ha et al. - 2016 - Efficient Area-Based Ray Integration Using Summed .pdf:application/pdf},
}

@article{ha_look-up_2018,
	title = {A {Look}-{Up} {Table}-{Based} {Ray} {Integration} {Framework} for 2-{D}/3-{D} {Forward} and {Back} {Projection} in {X}-{Ray} {CT}},
	volume = {37},
	issn = {0278-0062, 1558-254X},
	url = {http://ieeexplore.ieee.org/document/8013154/},
	doi = {10.1109/TMI.2017.2741781},
	abstract = {Iterative algorithms have become increasingly popular in Computed Tomography (CT) image reconstruction since they better deal with the adverse image artifacts arising from low radiation dose image acquisition. But iterative methods remain computationally expensive. The main cost emerges in the projection and backprojection operations where accurate CT system modeling can greatly improve the quality of the reconstructed image. We present a framework that improves upon one particular aspect – the accurate projection of the image basis functions. It differs from current methods in that it substitutes the high computational complexity associated with accurate voxel projection by a small number of memory operations. Coefﬁcients are computed in advance and stored in look-up tables parameterized by the CT system’s projection geometry. The look-up tables only require a few kilobytes of storage and can be efﬁciently accelerated on the GPU. We demonstrate our framework with both numerical and clinical experiments and compare its performance with the current state of the art scheme – the separable footprint method.},
	language = {en},
	number = {2},
	urldate = {2021-12-19},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Ha, Sungsoo and Mueller, Klaus},
	month = feb,
	year = {2018},
	pages = {361--371},
	file = {Ha and Mueller - 2018 - A Look-Up Table-Based Ray Integration Framework fo.pdf:/home/david/Zotero/storage/GCDF7THL/Ha and Mueller - 2018 - A Look-Up Table-Based Ray Integration Framework fo.pdf:application/pdf},
}

@inproceedings{ha_study_2015,
	address = {Newport},
	title = {A {Study} of {Volume} {Integration} {Models} for {Iterative} {Cone}-{Beam} {Computed} {Tomography}},
	abstract = {With the help of modern parallel computers, iterative reconstruction algorithms have become a feasible research topic in the field of CT. These types of algorithms can greatly benefit from an accurate, realistic CT system model. In our study, we model the CT projection as volume integrals and propose a set of methods that can compute the volume integrals either exactly or approximately. Our approximate volume integral methods have a much smaller complexity algorithmically than the exact method, but their accuracy is close to it. More importantly, the proposed approximate methods can be easily ported to modern parallel processors to utilize their massive computation powers.},
	language = {en},
	author = {Ha, Sungsoo and Kumar, Ayush and Mueller, Klaus},
	year = {2015},
	pages = {4},
	file = {Ha et al. - 2015 - A Study of Volume Integration Models for Iterative.pdf:/home/david/Zotero/storage/2GD9XFFT/Ha et al. - 2015 - A Study of Volume Integration Models for Iterative.pdf:application/pdf},
}

@inproceedings{shewchuk_introduction_1994,
	title = {An {Introduction} to the {Conjugate} {Gradient} {Method} {Without} the {Agonizing} {Pain}},
	url = {https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf},
	urldate = {2021-12-23},
	publisher = {Carnegie-Mellon University. Department of Computer Scienc},
	author = {Shewchuk, Jonathan Richard},
	year = {1994},
	file = {Shewchuk - 1994 - An Introduction to the Conjugate Gradient Method W.pdf:/home/david/Zotero/storage/TUAWAFB2/Shewchuk - 1994 - An Introduction to the Conjugate Gradient Method W.pdf:application/pdf},
}

@article{clason_regularization_2021,
	title = {Regularization of {Inverse} {Problems}},
	url = {http://arxiv.org/abs/2001.00617},
	abstract = {These lecture notes for a graduate class present the regularization theory for linear and nonlinear ill-posed operator equations in Hilbert spaces. Covered are the general framework of regularization methods and their analysis via spectral filters as well as the concrete examples of Tikhonov regularization, Landweber iteration, regularization by discretization for linear inverse problems. In the nonlinear setting, Tikhonov regularization and iterative regularization (Landweber, Levenberg-Marquardt, and iteratively regularized Gau\{{\textbackslash}ss\}-Newton methods) are discussed. The necessary background from functional analysis is also briefly summarized. The notes end with a brief outlook to statistical inverse problems from both a frequentist and a Bayesian point of view.},
	language = {en},
	urldate = {2021-12-27},
	journal = {arXiv:2001.00617 [cs, math]},
	author = {Clason, Christian},
	month = feb,
	year = {2021},
	note = {arXiv: 2001.00617},
	keywords = {Mathematics - Functional Analysis, Mathematics - Numerical Analysis},
	file = {Clason - 2021 - Regularization of Inverse Problems.pdf:/home/david/Zotero/storage/PGBIJLFG/Clason - 2021 - Regularization of Inverse Problems.pdf:application/pdf},
}

@article{tibshirani_lasso_2013,
	title = {The lasso problem and uniqueness},
	volume = {7},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-7/issue-none/The-lasso-problem-and-uniqueness/10.1214/13-EJS815.full},
	doi = {10.1214/13-EJS815},
	abstract = {The lasso is a popular tool for sparse linear regression, especially for problems in which the number of variables p exceeds the number of observations n. But when p {\textgreater} n, the lasso criterion is not strictly convex, and hence it may not have a unique minimizer. An important question is: when is the lasso solution well-deﬁned (unique)? We review results from the literature, which show that if the predictor variables are drawn from a continuous probability distribution, then there is a unique lasso solution with probability one, regardless of the sizes of n and p. We also show that this result extends easily to 1 penalized minimization problems over a wide range of loss functions.},
	language = {en},
	number = {none},
	urldate = {2021-12-27},
	journal = {Electronic Journal of Statistics},
	author = {Tibshirani, Ryan J.},
	month = jan,
	year = {2013},
	file = {Tibshirani - 2013 - The lasso problem and uniqueness.pdf:/home/david/Zotero/storage/EEJWPKG5/Tibshirani - 2013 - The lasso problem and uniqueness.pdf:application/pdf},
}

@article{tao_local_2015,
	title = {Local {Linear} {Convergence} of {ISTA} and {FISTA} on the {LASSO} {Problem}},
	url = {http://arxiv.org/abs/1501.02888},
	abstract = {We establish local linear convergence bounds for the ISTA and FISTA iterations on the model LASSO problem. We show that FISTA can be viewed as an accelerated ISTA process. Using a spectral analysis, we show that, when close enough to the solution, both iterations converge linearly, but FISTA slows down compared to ISTA, making it advantageous to switch to ISTA toward the end of the iteration processs. We illustrate the results with some synthetic numerical examples.},
	language = {en},
	urldate = {2021-12-27},
	journal = {arXiv:1501.02888 [math]},
	author = {Tao, Shaozhe and Boley, Daniel and Zhang, Shuzhong},
	month = jan,
	year = {2015},
	note = {arXiv: 1501.02888},
	keywords = {Mathematics - Optimization and Control},
	file = {Tao et al. - 2015 - Local Linear Convergence of ISTA and FISTA on the .pdf:/home/david/Zotero/storage/DEREK838/Tao et al. - 2015 - Local Linear Convergence of ISTA and FISTA on the .pdf:application/pdf},
}

@article{urimi_image_nodate,
	title = {{IMAGE} {RECONSTRUCTION} {TECHNIQUES} and {MEASURE} {OF} {QUALITY}: {CLASSICAL} vs. {MODERN} {APPROACHES}},
	language = {en},
	author = {Urimi, Lakshmi P},
	pages = {52},
	file = {Urimi - IMAGE RECONSTRUCTION TECHNIQUES and MEASURE OF QUA.pdf:/home/david/Zotero/storage/ANRHK82E/Urimi - IMAGE RECONSTRUCTION TECHNIQUES and MEASURE OF QUA.pdf:application/pdf},
}

@misc{noauthor_root-mean-square_2021,
	title = {Root-mean-square deviation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Root-mean-square_deviation&oldid=1037360077},
	abstract = {The root-mean-square deviation (RMSD) or root-mean-square error (RMSE) is a frequently used measure of the differences between values (sample or population values) predicted by a model or an estimator and the values observed. The RMSD represents the square root of the second sample moment of the differences between predicted values and observed values or the quadratic mean of these differences. These deviations are called residuals when the calculations are performed over the data sample that was used for estimation and are called errors (or prediction errors) when computed out-of-sample. The RMSD serves to aggregate the magnitudes of the errors in predictions for various data points into a single measure of predictive power. RMSD is a measure of accuracy, to compare forecasting errors of different models for a particular dataset and not between datasets, as it is scale-dependent.RMSD is always non-negative, and a value of 0 (almost never achieved in practice) would indicate a perfect fit to the data. In general, a lower RMSD is better than a higher one. However, comparisons across different types of data would be invalid because the measure is dependent on the scale of the numbers used.
RMSD is the square root of the average of squared errors. The effect of each error on RMSD is proportional to the size of the squared error; thus larger errors have a disproportionately large effect on RMSD. Consequently, RMSD is sensitive to outliers.},
	language = {en},
	urldate = {2022-01-04},
	journal = {Wikipedia},
	month = aug,
	year = {2021},
	note = {Page Version ID: 1037360077},
	file = {Snapshot:/home/david/Zotero/storage/GKPR4G23/index.html:text/html},
}

@misc{noauthor_peak_2021,
	title = {Peak signal-to-noise ratio},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Peak_signal-to-noise_ratio&oldid=1062145991},
	abstract = {Peak signal-to-noise ratio (PSNR) is an engineering term for the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation. Because many signals have a very wide dynamic range, PSNR is usually expressed as a logarithmic quantity using the decibel scale.
PSNR is commonly used to quantify reconstruction quality for images and video subject to lossy compression.},
	language = {en},
	urldate = {2022-01-04},
	journal = {Wikipedia},
	month = dec,
	year = {2021},
	note = {Page Version ID: 1062145991},
	file = {Snapshot:/home/david/Zotero/storage/P437AEZH/index.html:text/html},
}

@misc{noauthor_structural_2021,
	title = {Structural similarity},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Structural_similarity&oldid=1053007931},
	abstract = {The structural similarity index measure (SSIM) is a method for predicting the perceived quality of digital television and cinematic pictures, as well as other kinds of digital images and videos.  SSIM is used for measuring the similarity between two images. The SSIM index is a full reference metric; in other words, the measurement or prediction of image quality is based on an initial uncompressed or distortion-free image as reference.
SSIM is a perception-based model that considers image degradation as perceived change in structural information, while also incorporating important perceptual phenomena, including both luminance masking and contrast masking terms.  The difference with other techniques such as MSE or PSNR is that these approaches estimate absolute errors.  Structural information is the idea that the pixels have strong inter-dependencies especially when they are spatially close. These dependencies carry important information about the structure of the objects in the visual scene. Luminance masking is a phenomenon whereby image distortions (in this context) tend to be less visible in bright regions, while contrast masking is a phenomenon whereby distortions become less visible where there is significant activity or "texture" in the image.},
	language = {en},
	urldate = {2022-01-04},
	journal = {Wikipedia},
	month = nov,
	year = {2021},
	note = {Page Version ID: 1053007931},
	file = {Snapshot:/home/david/Zotero/storage/DJXTI8CV/index.html:text/html},
}

@article{lin_zhang_fsim_2011,
	title = {{FSIM}: {A} {Feature} {Similarity} {Index} for {Image} {Quality} {Assessment}},
	volume = {20},
	issn = {1057-7149, 1941-0042},
	shorttitle = {{FSIM}},
	url = {http://ieeexplore.ieee.org/document/5705575/},
	doi = {10.1109/TIP.2011.2109730},
	abstract = {Image quality assessment (IQA) aims to use computational models to measure the image quality consistently with subjective evaluations. The well-known structural-similarity (SSIM) index brings IQA from pixel-based stage to structure-based stage. In this paper, a novel feature-similarity (FSIM) index for full reference IQA is proposed based on the fact that human visual system (HVS) understands an image mainly according to its low-level features. Specifically, the phase congruency (PC), which is a dimensionless measure of the significance of a local structure, is used as the primary feature in FSIM. Considering that PC is contrast invariant while the contrast information does affect HVS’ perception of image quality, the image gradient magnitude (GM) is employed as the secondary feature in FSIM. PC and GM play complementary roles in characterizing the image local quality. After obtaining the local quality map, we use PC again as a weighting function to derive a single quality score. Extensive experiments performed on six benchmark IQA databases demonstrate that FSIM can achieve much higher consistency with the subjective evaluations than state-of-the-art IQA metrics.},
	language = {en},
	number = {8},
	urldate = {2022-01-04},
	journal = {IEEE Transactions on Image Processing},
	author = {{Lin Zhang} and {Lei Zhang} and {Xuanqin Mou} and Zhang, D.},
	month = aug,
	year = {2011},
	pages = {2378--2386},
	file = {Lin Zhang et al. - 2011 - FSIM A Feature Similarity Index for Image Quality.pdf:/home/david/Zotero/storage/N3WVMQ7Z/Lin Zhang et al. - 2011 - FSIM A Feature Similarity Index for Image Quality.pdf:application/pdf},
}

@misc{noauthor_image_2022,
	title = {Image {Similarity} {Measures}},
	copyright = {MIT},
	url = {https://github.com/up42/image-similarity-measures},
	abstract = {:chart\_with\_upwards\_trend: Implementation of eight evaluation metrics to access the similarity between two images. The eight metrics are as follows: RMSE, PSNR, SSIM, ISSM, FSIM, SRE, SAM, and UIQ.},
	urldate = {2022-01-04},
	publisher = {UP42},
	month = jan,
	year = {2022},
	note = {original-date: 2020-04-06T07:27:49Z},
	keywords = {evaluation-metrics, image, machine-learning, metrics},
}

@article{mittal_making_2013,
	title = {Making a “{Completely} {Blind}” {Image} {Quality} {Analyzer}},
	volume = {20},
	issn = {1070-9908, 1558-2361},
	url = {http://ieeexplore.ieee.org/document/6353522/},
	doi = {10.1109/LSP.2012.2227726},
	abstract = {An important aim of research on the blind image quality assessment (IQA) problem is to devise perceptual models that can predict the quality of distorted images with as little prior knowledge of the images or their distortions as possible. Current state-of-the-art ‘general purpose’ no reference (NR) IQA algorithms require knowledge about anticipated distortions in the form of training examples and corresponding human opinion scores. However we have recently derived a blind IQA model that only makes use of measurable deviations from statistical regularities observed in natural images, without training on human-rated distorted images, and, indeed without any exposure to distorted images. Thus, it is ‘completely blind.’ The new IQA model, which we call the Natural Image Quality Evaluator (NIQE) is based on the construction of a ‘quality aware’ collection of statistical features based on a simple and successful space domain natural scene statistic (NSS) model. These features are derived from a corpus of natural, undistorted images. Experimental results show that the new index delivers performance comparable to top performing NR IQA models that require training on large databases of human opinions of distorted images. A software release is available at:http://live.ece.utexas.edu/research/quality/niqe release.zip.},
	language = {en},
	number = {3},
	urldate = {2022-01-04},
	journal = {IEEE Signal Processing Letters},
	author = {Mittal, A. and Soundararajan, R. and Bovik, A. C.},
	month = mar,
	year = {2013},
	pages = {209--212},
	file = {Mittal et al. - 2013 - Making a “Completely Blind” Image Quality Analyzer.pdf:/home/david/Zotero/storage/J7ZH6ASK/Mittal et al. - 2013 - Making a “Completely Blind” Image Quality Analyzer.pdf:application/pdf},
}

@inproceedings{venkatanath_n_blind_2015,
	address = {Mumbai, India},
	title = {Blind image quality evaluation using perception based features},
	isbn = {978-1-4799-6619-6},
	url = {http://ieeexplore.ieee.org/document/7084843/},
	doi = {10.1109/NCC.2015.7084843},
	abstract = {This paper proposes a novel no-reference Perception-based Image QUality Evaluator (PIQUE) for realworld imagery. A majority of the existing methods for blind image quality assessment rely on opinion-based supervised learning for quality score prediction. Unlike these methods, we propose an opinion unaware methodology that attempts to quantify distortion without the need for any training data. Our method relies on extracting local features for predicting quality. Additionally, to mimic human behavior, we estimate quality only from perceptually signiﬁcant spatial regions. Further, the choice of our features enables us to generate a ﬁne-grained block level distortion map. Our algorithm is competitive with the state-of-the-art based on evaluation over several popular datasets including LIVE IQA, TID \& CSIQ. Finally, our algorithm has low computational complexity despite working at the block-level.},
	language = {en},
	urldate = {2022-01-04},
	booktitle = {2015 {Twenty} {First} {National} {Conference} on {Communications} ({NCC})},
	publisher = {IEEE},
	author = {{Venkatanath N} and {Praneeth D} and {Maruthi Chandrasekhar Bh} and Channappayya, Sumohana S. and Medasani, Swarup S.},
	month = feb,
	year = {2015},
	pages = {1--6},
	file = {Venkatanath N et al. - 2015 - Blind image quality evaluation using perception ba.pdf:/home/david/Zotero/storage/5W5E6EB7/Venkatanath N et al. - 2015 - Blind image quality evaluation using perception ba.pdf:application/pdf},
}

@inproceedings{samajdar_analysis_2015,
	address = {New Delhi},
	series = {Advances in {Intelligent} {Systems} and {Computing}},
	title = {Analysis and {Evaluation} of {Image} {Quality} {Metrics}},
	isbn = {978-81-322-2247-7},
	doi = {10.1007/978-81-322-2247-7_38},
	abstract = {Image Quality Assessment (IQA) is a very difficult task, yet highly important characteristic for evaluation of the image quality. Widely popular IQA techniques, belonging to objective fidelity, like Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR) or subjective fidelity which corresponds to the human visual system (HVS), like, Universal Quality Index (UQI), Structural SIMilarity (SSIM), Feature SIMilarity (FSIM), Feature SIMilarity for color images (FSIMc), Gradient Magnitude Similarity (GSM) have been discussed in this paper. Also quality measured on basis of degradation model and Noise Quality Measure (NQM) has been discussed. Experiments have been conducted on IVC database available online at http://www.irccyn.ec-nantes.fr/ivcdb/ and verified from the CSIQ database and LAR database available online at http://vision.okstate.edu/?loc=csiq and http://www.irccyn.ec-nantes.fr/{\textasciitilde}autrusse/Databases/LAR/. On the basis of the obtained values judgements about the image distortion and hence the optimum image quality metric has been decided. It has been found from all the experiments conducted that FSIM is the best metric for the JPEG, JPEG2000, blur and LAR whereas UQI failed to give better results for all except JPEG2000.},
	language = {en},
	booktitle = {Information {Systems} {Design} and {Intelligent} {Applications}},
	publisher = {Springer India},
	author = {Samajdar, Tina and Quraishi, Md. Iqbal},
	editor = {Mandal, J. K. and Satapathy, Suresh Chandra and Kumar Sanyal, Manas and Sarkar, Partha Pratim and Mukhopadhyay, Anirban},
	year = {2015},
	keywords = {FSIM, FSIMc, GSM, HVS, IQA, MSE, NQM, PSNR, SSIM, UQI},
	pages = {369--378},
}

@misc{ballard_making_2020,
	title = {Making {Matplotlib} {Beautiful} {By} {Default}},
	url = {https://towardsdatascience.com/making-matplotlib-beautiful-by-default-d0d41e3534fd},
	abstract = {Use Seaborn to control Matplotlib defaults (and forget that shade of blue forever)},
	language = {en},
	urldate = {2022-01-13},
	journal = {Medium},
	author = {Ballard, Callum},
	month = may,
	year = {2020},
}

@misc{boston_university_tutorial_2016,
	title = {Tutorial: {Basics} of {Information} {Design} for {Scientific} {Figures}},
	shorttitle = {Tutorial},
	url = {https://www.youtube.com/watch?v=Lb4uG4rIwPA},
	abstract = {In this video, Kelly Krause, Creative Director at Nature, presented a short tutorial session on best practices for design of scientific figures for publication. Kelly spoke at an event sponsored by the Office of the Vice President and Associate Provost for Research. For more information, please see the video from Kelly’s overview of strategies for communicating science through visualization in a publishing context.

February 26, 2016},
	urldate = {2022-01-13},
	author = {{Boston University}},
	month = mar,
	year = {2016},
}

@book{press_fortran_1996,
	address = {Cambridge [England] ; New York},
	edition = {2nd ed},
	title = {{FORTRAN} numerical recipes},
	isbn = {978-0-521-43064-7 978-0-521-57439-6},
	language = {en},
	publisher = {Cambridge University Press},
	editor = {Press, William H.},
	year = {1996},
	keywords = {Computer programs, FORTRAN (Computer program language), Mathematics Computer programs, Numerical analysis, Science},
	file = {Press - 1996 - FORTRAN numerical recipes.pdf:/home/david/Zotero/storage/P4IRRI7H/Press - 1996 - FORTRAN numerical recipes.pdf:application/pdf},
}

@article{vogelgesang_semi-discrete_nodate,
	title = {Semi-{Discrete} {Iteration} {Methods} in {X}-{Ray} {Tomography}},
	language = {en},
	author = {Vogelgesang, Jonas},
	pages = {114},
	file = {Vogelgesang - Semi-Discrete Iteration Methods in X-Ray Tomograph.pdf:/home/david/Zotero/storage/USKLE36L/Vogelgesang - Semi-Discrete Iteration Methods in X-Ray Tomograph.pdf:application/pdf},
}

@inproceedings{horbelt_spline_2000,
	address = {Istanbul, Turkey},
	title = {Spline kernels for continuous-space image processing},
	volume = {4},
	isbn = {978-0-7803-6293-2},
	url = {http://ieeexplore.ieee.org/document/859272/},
	doi = {10.1109/ICASSP.2000.859272},
	abstract = {We present an explicit formula for spline kernels; these are deﬁned as the convolution of several B-splines of variable widths hi and degrees ni. The spline kernels are useful for continuous signal processing algorithms that involve Bspline inner-products or the convolution of several spline basis functions. We apply our results to the derivation of spline-based algorithms for two classes of problems. The ﬁrst is the resizing of images with arbitrary scaling factors. The second is the computation of the Radon transform and of its inverse; in particular, we present a new spline-based version of the ﬁltered backprojection algorithm for tomographic reconstruction. In both cases, our explicit kernel formula allows for the use of high-degree splines; these oﬀer better approximation performance than the conventional lower-order formulations (e.g., piecewise constant or piecewise linear models).},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2000 {IEEE} {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing}. {Proceedings} ({Cat}. {No}.{00CH37100})},
	publisher = {IEEE},
	author = {Horbelt, S. and Munoz, A. and Blu, T. and Unser, M.},
	year = {2000},
	pages = {2191--2194},
	file = {Horbelt et al. - 2000 - Spline kernels for continuous-space image processi.pdf:/home/david/Zotero/storage/7279UY5X/Horbelt et al. - 2000 - Spline kernels for continuous-space image processi.pdf:application/pdf},
}

@inproceedings{horbelt_spline_2000-1,
	address = {Istanbul, Turkey},
	title = {Spline kernels for continuous-space image processing},
	volume = {4},
	isbn = {978-0-7803-6293-2},
	url = {http://ieeexplore.ieee.org/document/859272/},
	doi = {10.1109/ICASSP.2000.859272},
	abstract = {We present an explicit formula for spline kernels; these are deﬁned as the convolution of several B-splines of variable widths hi and degrees ni. The spline kernels are useful for continuous signal processing algorithms that involve Bspline inner-products or the convolution of several spline basis functions. We apply our results to the derivation of spline-based algorithms for two classes of problems. The ﬁrst is the resizing of images with arbitrary scaling factors. The second is the computation of the Radon transform and of its inverse; in particular, we present a new spline-based version of the ﬁltered backprojection algorithm for tomographic reconstruction. In both cases, our explicit kernel formula allows for the use of high-degree splines; these oﬀer better approximation performance than the conventional lower-order formulations (e.g., piecewise constant or piecewise linear models).},
	language = {en},
	urldate = {2022-01-31},
	booktitle = {2000 {IEEE} {International} {Conference} on {Acoustics}, {Speech}, and {Signal} {Processing}. {Proceedings} ({Cat}. {No}.{00CH37100})},
	publisher = {IEEE},
	author = {Horbelt, S. and Munoz, A. and Blu, T. and Unser, M.},
	year = {2000},
	pages = {2191--2194},
	file = {Horbelt et al. - 2000 - Spline kernels for continuous-space image processi.pdf:/home/david/Zotero/storage/ME9RIKEX/Horbelt et al. - 2000 - Spline kernels for continuous-space image processi.pdf:application/pdf},
}

@inproceedings{nilchian_differential_2012,
	title = {Differential phase-contrast {X}-ray computed tomography: {From} model discretization to image reconstruction},
	shorttitle = {Differential phase-contrast {X}-ray computed tomography},
	doi = {10.1109/ISBI.2012.6235491},
	abstract = {Our contribution in this paper is two fold. First, we propose a novel discretization of the forward model for differential phase-contrast imaging that uses B-spline basis functions. The approach yields a fast and accurate algorithm for implementing the forward model, which is based on the first derivative of the Radon transform. Second, as an alternative to the FBP-like approaches that are currently used in practice, we present an iterative reconstruction algorithm that remains more faithful to the data when the number of projections dwindles. Since the reconstruction is an ill-posed problem, we impose a total-variation (TV) regularization constraint. We propose to solve the reconstruction problem using the alternating direction method of multipliers (ADMM). A specificity of our system is the use of a preconditioner that improves the convergence rate of the linear solver in ADMM. Our experiments on test data suggest that our method can achieve the same quality as the standard direct reconstruction, while using only one-third of the projection data. We also find that the approach is much faster than the standard algorithms (ISTA and FISTA) that are typically used for solving linear inverse problems subject to the TV regularization constraint.},
	booktitle = {2012 9th {IEEE} {International} {Symposium} on {Biomedical} {Imaging} ({ISBI})},
	author = {Nilchian, Masih and Unser, Michael},
	month = may,
	year = {2012},
	note = {ISSN: 1945-8452},
	keywords = {Computed tomography, Image reconstruction, X-ray imaging, alternating direction method of multipliers (ADMM), differential phase-contrast imaging, filtered back projection (FBP), preconditioned conjugate gradient method, Radon transform, Splines (mathematics), Transforms, Vectors},
	pages = {90--93},
	file = {IEEE Xplore Full Text PDF:/home/david/Zotero/storage/YF9WSLLA/Nilchian and Unser - 2012 - Differential phase-contrast X-ray computed tomogra.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/Q99JW7GY/6235491.html:text/html},
}

@article{winkler_numerical_1993,
	title = {Numerical recipes in {C}: {The} art of scientific computing, second edition},
	volume = {17},
	issn = {01609327},
	shorttitle = {Numerical recipes in {C}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/016093279390069F},
	doi = {10.1016/0160-9327(93)90069-F},
	language = {en},
	number = {4},
	urldate = {2022-02-02},
	journal = {Endeavour},
	author = {Winkler, Joab R},
	month = jan,
	year = {1993},
	pages = {201},
	file = {Winkler - 1993 - Numerical recipes in C The art of scientific comp.pdf:/home/david/Zotero/storage/DNR7FMEP/Winkler - 1993 - Numerical recipes in C The art of scientific comp.pdf:application/pdf},
}

@misc{noauthor_libstdc_nodate,
	title = {libstdc++: modified\_bessel\_func.tcc {Source} {File}},
	url = {https://gcc.gnu.org/onlinedocs/libstdc++/libstdc++-html-USERS-4.3/a01938.html},
	urldate = {2022-02-02},
	file = {libstdc++\: modified_bessel_func.tcc Source File:/home/david/Zotero/storage/CQR84E5G/a01938.html:text/html},
}

@book{abramowitz_1_1972,
	address = {New York},
	edition = {Unabridged, unaltered and corr. republ. of the 1964 ed},
	series = {Dover books on advanced mathematics},
	title = {1: with formulas, graphs and mathematical tables [conference under the auspices of the {National} science foundation and the {Massachussetts} institute of technology]},
	isbn = {978-0-486-61272-0},
	shorttitle = {Handbook of mathematical functions},
	language = {eng},
	publisher = {Dover publ},
	author = {Abramowitz, Milton and Stegun, Irene A.},
	collaborator = {Conference on mathematical tables and National science foundation and Massachusetts institute of technology},
	year = {1972},
	file = {Abramowitz and Stegun - 1972 - Handbook of mathematical functions with formulas,.pdf:/home/david/Zotero/storage/7Y6SYIXP/Abramowitz and Stegun - 1972 - Handbook of mathematical functions with formulas,.pdf:application/pdf},
}

@misc{noauthor_xmipp_2022,
	title = {Xmipp},
	copyright = {GPL-3.0},
	url = {https://github.com/I2PC/xmipp/blob/57a4d8f7942dcd6cebcffaf7c6c664fdd0c5dbe8/src/xmipp/libraries/reconstruction_cuda/cuda_gpu_reconstruct_fourier.cpp},
	abstract = {Xmipp is a suite of image processing programs, primarily aimed at single-particle 3D electron microscopy.},
	urldate = {2022-02-02},
	publisher = {Instruct Image Processing Center},
	month = jan,
	year = {2022},
	note = {original-date: 2018-06-11T13:30:44Z},
}

@misc{noauthor_xmipp_2022-1,
	title = {Xmipp},
	copyright = {GPL-3.0},
	url = {https://github.com/I2PC/xmipp/blob/57a4d8f7942dcd6cebcffaf7c6c664fdd0c5dbe8/src/xmipp/libraries/reconstruction_starpu/reconstruct_fourier_codelet_reconstruct.cpp},
	abstract = {Xmipp is a suite of image processing programs, primarily aimed at single-particle 3D electron microscopy.},
	urldate = {2022-02-02},
	publisher = {Instruct Image Processing Center},
	month = jan,
	year = {2022},
	note = {original-date: 2018-06-11T13:30:44Z},
}

@article{felsner_phase-sensitive_2018,
	title = {Phase-{Sensitive} {Region}-of-{Interest} {Computed} {Tomography}},
	url = {http://arxiv.org/abs/1805.09528},
	abstract = {X-Ray Phase-Contrast Imaging (PCI) yields absorption, differential phase, and dark-ﬁeld images. Computed Tomography (CT) of grating-based PCI can in principle provide high-resolution soft-tissue contrast. Recently, grating-based PCI took several hurdles towards clinical implementation by addressing, for example, acquisition speed, high X-ray energies, and system vibrations. However, a critical impediment in all grating-based systems lies in limits that constrain the grating diameter to few centimeters.},
	language = {en},
	urldate = {2022-02-05},
	journal = {arXiv:1805.09528 [physics]},
	author = {Felsner, Lina and Berger, Martin and Kaeppler, Sebastian and Bopp, Johannes and Ludwig, Veronika and Weber, Thomas and Pelzer, Georg and Michel, Thilo and Maier, Andreas and Anton, Gisela and Riess, Christian},
	month = may,
	year = {2018},
	note = {arXiv: 1805.09528},
	keywords = {Physics - Medical Physics},
	file = {Felsner et al. - 2018 - Phase-Sensitive Region-of-Interest Computed Tomogr.pdf:/home/david/Zotero/storage/4AEJ7EWY/Felsner et al. - 2018 - Phase-Sensitive Region-of-Interest Computed Tomogr.pdf:application/pdf},
}

@article{bayer_reconstruction_2014,
	title = {Reconstruction of scalar and vectorial components in {X}-ray dark-field tomography},
	volume = {111},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1321080111},
	doi = {10.1073/pnas.1321080111},
	language = {en},
	number = {35},
	urldate = {2022-02-05},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bayer, F. L. and Hu, S. and Maier, A. and Weber, T. and Anton, G. and Michel, T. and Riess, C. P.},
	month = sep,
	year = {2014},
	pages = {12699--12704},
	file = {Bayer et al. - 2014 - Reconstruction of scalar and vectorial components .pdf:/home/david/Zotero/storage/G4UGQVME/Bayer et al. - 2014 - Reconstruction of scalar and vectorial components .pdf:application/pdf},
}

@article{lee_machine_2018,
	title = {Machine {Friendly} {Machine} {Learning}: {Interpretation} of {Computed} {Tomography} {Without} {Image} {Reconstruction}},
	shorttitle = {Machine {Friendly} {Machine} {Learning}},
	url = {http://arxiv.org/abs/1812.01068},
	abstract = {Recent advancements in deep learning for automated image processing and classiﬁcation have accelerated many new applications for medical image analysis. However, most deep learning applications have been developed using reconstructed, human-interpretable medical images. While image reconstruction from raw sensor data is required for the creation of medical images, the reconstruction process only uses a partial representation of all the data acquired. Here we report the development of a system to directly process raw computed tomography (CT) data in sinogram-space, bypassing the intermediary step of image reconstruction. Two classiﬁcation tasks were evaluated for their feasibility for sinogram-space machine learning: body region identiﬁcation and intracranial hemorrhage (ICH) detection. Our proposed SinoNet performed favorably compared to conventional reconstructed image-space-based systems for both tasks, regardless of scanning geometries in terms of projections or detectors. Further, SinoNet performed signiﬁcantly better when using sparsely sampled sinograms than conventional networks operating in image-space. As a result, sinogram-space algorithms could be used in ﬁeld settings for binary diagnosis testing, triage, and in clinical settings where low radiation dose is desired. These ﬁndings also demonstrate another strength of deep learning where it can analyze and interpret sinograms that are virtually impossible for human experts.},
	language = {en},
	urldate = {2022-02-05},
	journal = {arXiv:1812.01068 [cs]},
	author = {Lee, Hyunkwang and Huang, Chao and Yune, Sehyo and Tajmir, Shahein H. and Kim, Myeongchan and Do, Synho},
	month = dec,
	year = {2018},
	note = {arXiv: 1812.01068},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Lee et al. - 2018 - Machine Friendly Machine Learning Interpretation .pdf:/home/david/Zotero/storage/7XLGLB3Q/Lee et al. - 2018 - Machine Friendly Machine Learning Interpretation .pdf:application/pdf},
}

@inproceedings{modregger_artifacts_2011,
	address = {Chicago, Illinois, (USA)},
	title = {Artifacts in {X}-ray {Dark}-{Field} {Tomography}},
	url = {http://aip.scitation.org/doi/abs/10.1063/1.3625356},
	doi = {10.1063/1.3625356},
	abstract = {Grating-based x-ray imaging provides three principle kinds of contrast: absorption, phase, and dark-field. Due to the availability of tomographic reconstruction algorithms for the dark-field contrast, it is now possible to take advantage of quantitative scatter information. However, the published algorithm is based on several assumptions that might be violated in reality. We use numerical simulations in order to identify artifacts in the reconstructions, which is crucial for the interpretation of experimental data.},
	language = {en},
	urldate = {2022-02-05},
	author = {Modregger, P. and Wang, Z. and Thuering, T. and Pinzer, B. and Stampanoni, M. and McNulty, Ian and Eyberger, Catherine and Lai, Barry},
	year = {2011},
	pages = {269--272},
	file = {Modregger et al. - 2011 - Artifacts in X-ray Dark-Field Tomography.pdf:/home/david/Zotero/storage/EWSZKLRM/Modregger et al. - 2011 - Artifacts in X-ray Dark-Field Tomography.pdf:application/pdf},
}

@misc{noauthor_carbon_nodate,
	title = {Carbon},
	url = {https://carbon.now.sh/?bg=rgba%28171%2C+184%2C+195%2C+1%29&t=one-dark&wt=none&l=text%2Fx-c%2B%2Bsrc&width=680&ds=true&dsyoff=20px&dsblur=68px&wc=true&wa=true&pv=56px&ph=56px&ln=false&fl=1&fm=Hack&fs=14px&lh=133%25&si=false&es=2x&wm=false&code=template%253Ctypename%2520data_t%253E%250Adata_t%2520reduce%28const%2520DataConatiner%253Cdata_t%253E%2520a%29%2520%257B%250A%2520%2520%2520%2520data_t%2520sum%2520%253D%2520data_t%280%29%253B%250A%2520%2520%2520%2520for%28int%2520i%253D0%253B%2520i%253Ca.size%28%29%253B%2520%252B%252Bi%29%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520sum%2520%252B%253D%2520a%255Bi%255D%253B%250A%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520return%2520sum%253B%250A%257D},
	abstract = {Carbon is the easiest way to create and share beautiful images of your source code.},
	language = {en},
	urldate = {2022-02-06},
}

@misc{pine_octrefpolacode_2022,
	title = {octref/polacode},
	url = {https://github.com/octref/polacode},
	abstract = {📸 Polaroid for your code},
	urldate = {2022-02-06},
	author = {Pine},
	month = feb,
	year = {2022},
	note = {original-date: 2018-02-09T23:10:07Z},
	keywords = {screenshot, snippets, visual-studio-code, vscode},
}

@article{vogel_tomographic_nodate,
	title = {Tomographic {Reconstruction} beyond {Classical} {X}-ray {CT}},
	language = {de},
	author = {Vogel, Jakob},
	pages = {245},
	file = {Vogel - Tomographic Reconstruction beyond Classical X-ray .pdf:/home/david/Zotero/storage/S6NB8THJ/Vogel - Tomographic Reconstruction beyond Classical X-ray .pdf:application/pdf},
}

@misc{the_manim_community_developers_manim_2022,
	title = {Manim – {Mathematical} {Animation} {Framework}},
	copyright = {MIT},
	url = {https://www.manim.community/},
	abstract = {A community-maintained Python framework for creating mathematical animations.},
	urldate = {2022-02-11},
	author = {{The Manim Community Developers}},
	month = jan,
	year = {2022},
	note = {original-date: 2020-05-19T02:37:13Z},
}

@article{horacsek_evaluating_nodate,
	title = {Evaluating {Box} {Splines} with {Reduced} {Complexity}},
	abstract = {For the class of non-degenerate box splines, we present a set construction scheme that yields the explicit piecewise polynomial form for an arbitrary box spline. While it is possible to use the well known recursive formulation to obtain these polynomial pieces, this is quite expensive. Our construction is theoretically less expensive than the recursive formulation and allows us to evaluate box splines with more direction vectors than what would be feasible under the recursive scheme. Finally, using the explicit polynomials in each region of the box spline, we show how to create fast evaluation schemes using this explicit characterization and a spatial data structure.},
	language = {en},
	author = {Horacsek, Joshua and Alim, Usman},
	pages = {25},
	file = {Horacsek and Alim - Evaluating Box Splines with Reduced Complexity.pdf:/home/david/Zotero/storage/8KZVDAEF/Horacsek and Alim - Evaluating Box Splines with Reduced Complexity.pdf:application/pdf},
}

@misc{noauthor_boxspline1_2019,
	title = {boxspline1},
	copyright = {GPL-3.0},
	url = {https://github.com/CFD-GO/boxspline1/blob/90d7964bdb1999088b08e12ecf20adf263de6d8b/R/R/boxspline1.R},
	abstract = {1D box-spline library for limited spline parametrizations},
	urldate = {2022-02-26},
	publisher = {CFD on the GO},
	month = jun,
	year = {2019},
	note = {original-date: 2019-06-14T15:23:02Z},
}

@article{mccann_high-quality_2017,
	title = {High-{Quality} {Parallel}-{Ray} {X}-{Ray} {CT} {Back} {Projection} {Using} {Optimized} {Interpolation}},
	volume = {26},
	issn = {1941-0042},
	doi = {10.1109/TIP.2017.2706521},
	abstract = {We propose a new, cost-efficient method for computing back projections in parallel-ray X-ray CT. Forward and back projections are the basis of almost all X-ray CT reconstruction methods, but computing these accurately is costly. In the special case of parallel-ray geometry, it turns out that reconstruction requires back projection only. One approach to accelerate the back projection is through interpolation: fit a continuous representation to samples of the desired signal, then sample it at the required locations. Instead, we propose applying a prefilter that has the effect of orthogonally projecting the underlying signal onto the space spanned by the interpolator, which can significantly improve the quality of the interpolation. We then build on this idea by using oblique projection, which simplifies the computation while giving effectively the same improvement in quality. Our experiments on analytical phantoms show that this refinement can improve the reconstruction quality for both filtered back projection and iterative reconstruction in the high-quality regime, i.e., with low noise and many measurements.},
	number = {10},
	journal = {IEEE Transactions on Image Processing},
	author = {McCann, Michael T. and Unser, Michael},
	month = oct,
	year = {2017},
	note = {Conference Name: IEEE Transactions on Image Processing},
	keywords = {Interpolation, Kernel, Computed tomography, Image reconstruction, computed tomography, Transforms, Back, interpolation, reconstruction algorithms, Standards, X-ray tomography},
	pages = {4639--4647},
	file = {IEEE Xplore Full Text PDF:/home/david/Zotero/storage/HF4RDN6N/McCann and Unser - 2017 - High-Quality Parallel-Ray X-Ray CT Back Projection.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/GBNU3HCK/7932483.html:text/html},
}

@article{ma_improvements_nodate,
	title = {Improvements to the {Algorithm} that {Uses} {Divided} {Differences} to {Determine} the {Coefficients} in {B}-{Spline} {Interpolation}},
	abstract = {In numerical measuring processes the interpolation is an important part. Some algorithms of B-spline interpolation were developed along the time. Here are presented two additional methods to reduce the interpolation errors. These methods could be used in any case for uniformly spaced data. These interpolation processes requires supplementary numerical calculations. Always is to choose between a smallest amount of computation and better results of interpolation.},
	language = {en},
	author = {Mâ, Liliana},
	pages = {4},
	file = {Mâ - Improvements to the Algorithm that Uses Divided Di.pdf:/home/david/Zotero/storage/ID4GLSRM/Mâ - Improvements to the Algorithm that Uses Divided Di.pdf:application/pdf},
}

@article{takekawa_fast_2021,
	title = {Fast parallel calculation of modified {Bessel} function of the second kind and its derivatives},
	url = {http://arxiv.org/abs/2108.11560},
	abstract = {There are three main types of numerical computations for the Bessel function of the second kind: series expansion, continued fraction, and asymptotic expansion. In addition, they are combined in the appropriate domain for each. However, there are some regions where the combination of these types requires suﬃcient computation time to achieve suﬃcient accuracy, however, eﬃciency is signiﬁcantly reduced when parallelized. In the proposed method, we adopt a simple numerical integration concept of integral representation. We coarsely reﬁne the integration range beforehand, and stabilize the computation time by performing the integration calculation at a ﬁxed number of intervals. Experiments demonstrate that the proposed method can achieve the same level of accuracy as existing methods in less than half the computation time.},
	language = {en},
	urldate = {2022-03-12},
	journal = {arXiv:2108.11560 [cs, math]},
	author = {Takekawa, Takashi},
	month = sep,
	year = {2021},
	note = {arXiv: 2108.11560},
	keywords = {Mathematics - Numerical Analysis, 65D15, G.1.2, G.4},
	file = {Takekawa - 2021 - Fast parallel calculation of modified Bessel funct.pdf:/home/david/Zotero/storage/L6K2HGEU/Takekawa - 2021 - Fast parallel calculation of modified Bessel funct.pdf:application/pdf},
}

@article{gil_evaluation_2002,
	title = {Evaluation of the {Modified} {Bessel} {Function} of the {Third} {Kind} of {Imaginary} {Orders}},
	volume = {175},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999101968949},
	doi = {10.1006/jcph.2001.6894},
	language = {en},
	number = {2},
	urldate = {2022-03-12},
	journal = {Journal of Computational Physics},
	author = {Gil, Amparo and Segura, Javier and Temme, Nico M.},
	month = jan,
	year = {2002},
	pages = {398--411},
	file = {Gil et al. - 2002 - Evaluation of the Modified Bessel Function of the .pdf:/home/david/Zotero/storage/FRVRYISU/Gil et al. - 2002 - Evaluation of the Modified Bessel Function of the .pdf:application/pdf},
}

@article{temme_numerical_1975,
	title = {On the numerical evaluation of the modified bessel function of the third kind},
	volume = {19},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0021999175900820},
	doi = {10.1016/0021-9991(75)90082-0},
	language = {en},
	number = {3},
	urldate = {2022-03-12},
	journal = {Journal of Computational Physics},
	author = {Temme, N.M.},
	month = nov,
	year = {1975},
	pages = {324--337},
	file = {Temme - 1975 - On the numerical evaluation of the modified bessel.pdf:/home/david/Zotero/storage/JDEA9S49/Temme - 1975 - On the numerical evaluation of the modified bessel.pdf:application/pdf},
}

@misc{noauthor_r_nodate,
	title = {r - {Modified} {Bessel} functions of order (n)},
	url = {https://stackoverflow.com/questions/8797722/modified-bessel-functions-of-order-n},
	urldate = {2022-03-12},
	journal = {Stack Overflow},
	file = {Snapshot:/home/david/Zotero/storage/H2RRYICA/modified-bessel-functions-of-order-n.html:text/html},
}

@misc{noauthor_index_nodate,
	title = {Index of {Code} {Identifiers}},
	url = {https://www.astro.umd.edu/~ricotti/NEWWEB/teaching/ASTR415/InClassExamples/NR3/index_by_ident.htm},
	urldate = {2022-03-12},
	file = {Index of Code Identifiers:/home/david/Zotero/storage/RV4H9B4N/index_by_ident.html:text/html},
}

@misc{noauthor_notitle_nodate,
	url = {https://www.astro.umd.edu/~ricotti/NEWWEB/teaching/ASTR415/InClassExamples/NR3/code/bessel.h},
	urldate = {2022-03-12},
	file = {astro.umd.edu/~ricotti/NEWWEB/teaching/ASTR415/InClassExamples/NR3/code/bessel.h:/home/david/Zotero/storage/QW9ZHIZT/bessel.html:text/html},
}

@article{withers_x-ray_2021,
	title = {X-ray computed tomography},
	volume = {1},
	issn = {2662-8449},
	url = {http://www.nature.com/articles/s43586-021-00015-4},
	doi = {10.1038/s43586-021-00015-4},
	abstract = {X-r ay computed tomography (CT) can reveal the internal details of objects in three dimensions non-d estructively. In this Primer, we outline the basic principles of CT and describe the ways in which a CT scan can be acquired using X-r ay tubes and synchrotron sources, including the different possible contrast modes that can be exploited. We explain the process of computationally reconstructing three-d imensional (3D) images from 2D radiographs and how to segment the 3D images for subsequent visualization and quantification. Whereas CT is widely used in medical and heavy industrial contexts at relatively low resolutions, here we focus on the application of higher resolution X-r ay CT across science and engineering. We consider the application of X-ray CT to study subjects across the materials, metrology and manufacturing, engineering, food, biological, geological and palaeontological sciences. We examine how CT can be used to follow the structural evolution of materials in three dimensions in real time or in a time-lapse manner, for example to follow materials manufacturing or the in-s ervice behaviour and degradation of manufactured components. Finally, we consider the potential for radiation damage and common sources of imaging artefacts, discuss reproducibility issues and consider future advances and opportunities.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {Nature Reviews Methods Primers},
	author = {Withers, Philip J. and Bouman, Charles and Carmignato, Simone and Cnudde, Veerle and Grimaldi, David and Hagen, Charlotte K. and Maire, Eric and Manley, Marena and Du Plessis, Anton and Stock, Stuart R.},
	month = dec,
	year = {2021},
	pages = {18},
	file = {Withers et al. - 2021 - X-ray computed tomography.pdf:/home/david/Zotero/storage/AZGEZT7Y/Withers et al. - 2021 - X-ray computed tomography.pdf:application/pdf},
}

@article{der_sarkissian_cone-beam_2019,
	title = {A cone-beam {X}-ray computed tomography data collection designed for machine learning},
	volume = {6},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/s41597-019-0235-y},
	doi = {10.1038/s41597-019-0235-y},
	abstract = {Abstract
            Unlike previous works, this open data collection consists of X-ray cone-beam (CB) computed tomography (CT) datasets specifically designed for machine learning applications and high cone-angle artefact reduction. Forty-two walnuts were scanned with a laboratory X-ray set-up to provide not only data from a single object but from a class of objects with natural variability. For each walnut, CB projections on three different source orbits were acquired to provide CB data with different cone angles as well as being able to compute artefact-free, high-quality ground truth images from the combined data that can be used for supervised learning. We provide the complete image reconstruction pipeline: raw projection data, a description of the scanning geometry, pre-processing and reconstruction scripts using open software, and the reconstructed volumes. Due to this, the dataset can not only be used for high cone-angle artefact reduction but also for algorithm development and evaluation for other tasks, such as image reconstruction from limited or sparse-angle (low-dose) scanning, super resolution, or segmentation.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {Scientific Data},
	author = {Der Sarkissian, Henri and Lucka, Felix and van Eijnatten, Maureen and Colacicco, Giulia and Coban, Sophia Bethany and Batenburg, Kees Joost},
	month = dec,
	year = {2019},
	pages = {215},
	file = {Der Sarkissian et al. - 2019 - A cone-beam X-ray computed tomography data collect.pdf:/home/david/Zotero/storage/W7QC52EH/Der Sarkissian et al. - 2019 - A cone-beam X-ray computed tomography data collect.pdf:application/pdf},
}

@misc{der_sarkissian_cone-beam_2019-1,
	title = {Cone-{Beam} {X}-{Ray} {CT} {Data} {Collection} {Designed} for {Machine} {Learning}: {Samples} 1-8},
	shorttitle = {Cone-{Beam} {X}-{Ray} {CT} {Data} {Collection} {Designed} for {Machine} {Learning}},
	url = {https://zenodo.org/record/2686726},
	abstract = {This upload contains samples 1 - 8 from the data collection described in Henri Der Sarkissian, Felix Lucka, Maureen van Eijnatten, Giulia Colacicco, Sophia Bethany Coban, Kees Joost Batenburg, "A Cone-Beam X-Ray CT Data Collection Designed for Machine Learning", Sci Data 6, 215 (2019). https://doi.org/10.1038/s41597-019-0235-y or arXiv:1905.04787 (2019) Abstract: "Unlike previous works, this open data collection consists of X-ray cone-beam (CB) computed tomography (CT) datasets specifically designed for machine learning applications and high cone-angle artefact reduction: Forty-two walnuts were scanned with a laboratory X-ray setup to provide not only data from a single object but from a class of objects with natural variability. For each walnut, CB projections on three different orbits were acquired to provide CB data with different cone angles as well as being able to compute artefact-free, high-quality ground truth images from the combined data that can be used for supervised learning. We provide the complete image reconstruction pipeline: raw projection data, a description of the scanning geometry, pre-processing and reconstruction scripts using open software, and the reconstructed volumes. Due to this, the dataset can not only be used for high cone-angle artefact reduction but also for algorithm development and evaluation for other tasks, such as image reconstruction from limited or sparse-angle (low-dose) scanning, super resolution, or segmentation." The scans are performed using a custom-built, highly flexible X-ray CT scanner, the FleX-ray scanner, developed by XRE nvand located in the FleX-ray Lab at the Centrum Wiskunde \& Informatica (CWI) in Amsterdam, Netherlands. The general purpose of the FleX-ray Lab is to conduct proof of concept experiments directly accessible to researchers in the field of mathematics and computer science. The scanner consists of a cone-beam microfocus X-ray point source that projects polychromatic X-rays onto a 1536-by-1944 pixels, 14-bit flat panel detector (Dexella 1512NDT) and a rotation stage in-between, upon which a sample is mounted. All three components are mounted on translation stages which allow them to move independently from one another. Please refer to the paper for all further technical details. The complete data set can be found via the following links: 1-8, 9-16, 17-24, 25-32, 33-37, 38-42 The corresponding Python scripts for loading, pre-processing and reconstructing the projection data in the way described in the paper can be found on github For more information or guidance in using these dataset, please get in touch with henri.dersarkissian [at] gmail.com Felix.Lucka [at] cwi.nl},
	urldate = {2022-03-15},
	publisher = {Zenodo},
	author = {Der Sarkissian, Henri and Lucka, Felix and van Eijnatten, Maureen and Colacicco, Giulia and Coban, Sophia Bethany and Batenburg, K. Joost},
	month = may,
	year = {2019},
	doi = {10.5281/zenodo.2686726},
	note = {Type: dataset},
	keywords = {computed tomography, cone beam, deep learning, image reconstruction, machine learning, X-ray},
	file = {Zenodo Snapshot:/home/david/Zotero/storage/6VPDHAU3/2686726.html:text/html},
}

@inproceedings{gach_2d_2008,
	address = {Las Vegas, NV, USA},
	title = {{2D} \&\#x00026; {3D} {Shepp}-{Logan} {Phantom} {Standards} for {MRI}},
	isbn = {978-0-7695-3331-5},
	url = {http://ieeexplore.ieee.org/document/4616690/},
	doi = {10.1109/ICSEng.2008.15},
	abstract = {The Shepp-Logan phantom was created as a standard for computerized tomography (CT) image reconstruction simulations of the head. The phantom is also used frequently for magnetic resonance image (MRI) reconstruction and k-space simulations. However, while the CT version incorporated the radiation attenuation properties of the head and brain, the MRI version of the phantom was neither adapted to MR physics nor defined as a viable standard. As a result, it is not currently possible to compare and validate MR simulations from different research studies. In this paper, we present 2D and 3D SheppLogan MRI phantom standards and their analytic kspace representations based on existing CT standards after modification for MR physics. The standard includes T1 and T2 relaxation times for different fields strengths based on current literature.},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {2008 19th {International} {Conference} on {Systems} {Engineering}},
	publisher = {IEEE},
	author = {Gach, H. Michael and Tanase, Costin and Boada, Fernando},
	month = aug,
	year = {2008},
	pages = {521--526},
	file = {Gach et al. - 2008 - 2D &#x00026\; 3D Shepp-Logan Phantom Standards for .pdf:/home/david/Zotero/storage/GYBE7RNT/Gach et al. - 2008 - 2D &#x00026\; 3D Shepp-Logan Phantom Standards for .pdf:application/pdf},
}

@article{la_riviere_spline-based_1998,
	title = {Spline-based inverse {Radon} transform in two and three dimensions},
	volume = {45},
	issn = {0018-9499, 1558-1578},
	url = {https://ieeexplore.ieee.org/document/708352/},
	doi = {10.1109/23.708352},
	abstract = {While the exact inverse Radon transform is a continuous integral equation, the discrete nature of the data output by tomographic imaging systems generally demands that images be reconstructed using a discrete approximation to the transform. However, by fitting an analytic function to the projection data prior to reconstruction, one can avoid such approximations and preserve and exploit the continuous nature of the inverse transform.},
	language = {en},
	number = {4},
	urldate = {2022-03-18},
	journal = {IEEE Transactions on Nuclear Science},
	author = {La Riviere, P.J. and Pan, X.},
	month = aug,
	year = {1998},
	pages = {2224--2231},
	file = {La Riviere and Pan - 1998 - Spline-based inverse Radon transform in two and th.pdf:/home/david/Zotero/storage/4VSCFHND/La Riviere and Pan - 1998 - Spline-based inverse Radon transform in two and th.pdf:application/pdf},
}

@inproceedings{ye_box_2011,
	address = {Chicago, IL, USA},
	title = {Box spline based {3D} tomographic reconstruction of diffusion propagators from {MRI} data},
	isbn = {978-1-4244-4127-3},
	url = {http://ieeexplore.ieee.org/document/5872432/},
	doi = {10.1109/ISBI.2011.5872432},
	abstract = {This paper introduces a tomographic approach for reconstruction of diffusion propagators, P(r), in a box spline framework. Box splines are chosen as basis functions for high-order approximation of P(r) from the diffusion signal. Box splines are a generalization of B-splines to multivariate setting that are particularly useful in the context of tomographic reconstruction. The X-Ray or Radon transform of a (tensor-product B-spline or a non-separable) box spline is a box spline – the space of box splines is closed under the Radon transform.},
	language = {en},
	urldate = {2022-03-19},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Biomedical} {Imaging}: {From} {Nano} to {Macro}},
	publisher = {IEEE},
	author = {Ye, Wenxing and Portnoy, Sharon and Entezari, Alireza and Vemuri, Baba C. and Blackband, Stephen J.},
	month = mar,
	year = {2011},
	pages = {397--400},
	file = {Ye et al. - 2011 - Box spline based 3D tomographic reconstruction of .pdf:/home/david/Zotero/storage/4MPYPVU4/Ye et al. - 2011 - Box spline based 3D tomographic reconstruction of .pdf:application/pdf},
}

@inproceedings{mirzargar_spline_2013-1,
	title = {A spline framework for sparse tomographic reconstruction},
	doi = {10.1109/ISBI.2013.6556763},
	abstract = {We present a spline-based sparse tomographic reconstruction framework. The proposed method utilizes the closed-form analytical Radon transform of B-splines and box splines of any order and integrates the (transform-domain) sparsity of the image into the reconstruction algorithm. Our experiments show that the synergy of sparse reconstruction together with higher order basis functions (e.g., cubic B-splines) improves the accuracy of the reconstruction. This gain can also be exploited for reducing the number of projection angles in the data acquisition.},
	booktitle = {2013 {IEEE} 10th {International} {Symposium} on {Biomedical} {Imaging}},
	author = {Mirzargar, Mahsa and Sakhaee, Elham and Entezari, Alireza},
	month = apr,
	year = {2013},
	note = {ISSN: 1945-8452},
	keywords = {Image reconstruction, Tomography, Splines (mathematics), Transforms, Accuracy, Approximation methods, Signal to noise ratio, sparse approximation, splines, Tomographic reconstruction},
	pages = {1272--1275},
	file = {IEEE Xplore Full Text PDF:/home/david/Zotero/storage/AWNBSLVV/Mirzargar et al. - 2013 - A spline framework for sparse tomographic reconstr.pdf:application/pdf;IEEE Xplore Abstract Record:/home/david/Zotero/storage/GHXESPZT/6556763.html:text/html},
}

@article{wan_high-performance_2012,
	title = {High-performance blob-based iterative three-dimensional reconstruction in electron tomography using multi-{GPUs}},
	volume = {13},
	issn = {1471-2105},
	url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S10-S4},
	doi = {10.1186/1471-2105-13-S10-S4},
	abstract = {Background: Three-dimensional (3D) reconstruction in electron tomography (ET) has emerged as a leading technique to elucidate the molecular structures of complex biological specimens. Blob-based iterative methods are advantageous reconstruction methods for 3D reconstruction in ET, but demand huge computational costs. Multiple graphic processing units (multi-GPUs) offer an affordable platform to meet these demands. However, a synchronous communication scheme between multi-GPUs leads to idle GPU time, and a weighted matrix involved in iterative methods cannot be loaded into GPUs especially for large images due to the limited available memory of GPUs.
Results: In this paper we propose a multilevel parallel strategy combined with an asynchronous communication scheme and a blob-ELLR data structure to efficiently perform blob-based iterative reconstructions on multi-GPUs. The asynchronous communication scheme is used to minimize the idle GPU time so as to asynchronously overlap communications with computations. The blob-ELLR data structure only needs nearly 1/16 of the storage space in comparison with ELLPACK-R (ELLR) data structure and yields significant acceleration.
Conclusions: Experimental results indicate that the multilevel parallel scheme combined with the asynchronous communication scheme and the blob-ELLR data structure allows efficient implementations of 3D reconstruction in ET on multi-GPUs.},
	language = {en},
	number = {S10},
	urldate = {2022-03-19},
	journal = {BMC Bioinformatics},
	author = {Wan, Xiaohua and Zhang, Fa and Chu, Qi and Liu, Zhiyong},
	month = jun,
	year = {2012},
	pages = {S4},
	file = {Wan et al. - 2012 - High-performance blob-based iterative three-dimens.pdf:/home/david/Zotero/storage/U3JHAGCL/Wan et al. - 2012 - High-performance blob-based iterative three-dimens.pdf:application/pdf},
}

@phdthesis{erlandsson_positron_1996,
	address = {Lund},
	title = {Positron emission tomography with three-dimensional reconstruction},
	language = {en},
	author = {Erlandsson, Kjell},
	year = {1996},
	note = {ISBN: 9789162821890
OCLC: 186220689},
	file = {Erlandsson - 1996 - Positron emission tomography with three-dimensiona.pdf:/home/david/Zotero/storage/HCFMWIVN/Erlandsson - 1996 - Positron emission tomography with three-dimensiona.pdf:application/pdf},
}

@article{zhang_convolutional_2019,
	title = {A {Convolutional} {Forward} and {Back}-{Projection} {Model} for {Fan}-{Beam} {Geometry}},
	url = {http://arxiv.org/abs/1907.10526},
	abstract = {Iterative methods for tomographic image reconstruction have great potential for enabling high quality imaging from low-dose projection data. The computational burden of iterative reconstruction algorithms, however, has been an impediment in their adoption in practical CT reconstruction problems. We present an approach for highly efﬁcient and accurate computation of forward model for image reconstruction in fan-beam geometry in X-ray CT. The efﬁciency of computations makes this approach suitable for large-scale optimization algorithms with on-the-ﬂy, memory-less, computations of the forward and back-projection. Our experiments demonstrate the improvements in accuracy as well as efﬁciency of our model, speciﬁcally for ﬁrst-order box splines (i.e., pixel-basis) compared to recently developed methods for this purpose, namely Look-up Table-based Ray Integration (LTRI) and Separable Footprints (SF) in 2-D.},
	language = {en},
	urldate = {2022-03-19},
	journal = {arXiv:1907.10526 [cs, eess]},
	author = {Zhang, Kai and Entezari, Alireza},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.10526},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Distributed, Parallel, and Cluster Computing, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {Zhang and Entezari - 2019 - A Convolutional Forward and Back-Projection Model .pdf:/home/david/Zotero/storage/A96JJE6K/Zhang and Entezari - 2019 - A Convolutional Forward and Back-Projection Model .pdf:application/pdf},
}

@article{agulleiro_evaluation_2012,
	title = {Evaluation of a {Multicore}-{Optimized} {Implementation} for {Tomographic} {Reconstruction}},
	volume = {7},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0048261},
	doi = {10.1371/journal.pone.0048261},
	abstract = {Tomography allows elucidation of the three-dimensional structure of an object from a set of projection images. In life sciences, electron microscope tomography is providing invaluable information about the cell structure at a resolution of a few nanometres. Here, large images are required to combine wide fields of view with high resolution requirements. The computational complexity of the algorithms along with the large image size then turns tomographic reconstruction into a computationally demanding problem. Traditionally, high-performance computing techniques have been applied to cope with such demands on supercomputers, distributed systems and computer clusters. In the last few years, the trend has turned towards graphics processing units (GPUs). Here we present a detailed description and a thorough evaluation of an alternative approach that relies on exploitation of the power available in modern multicore computers. The combination of single-core code optimization, vector processing, multithreading and efficient disk I/O operations succeeds in providing fast tomographic reconstructions on standard computers. The approach turns out to be competitive with the fastest GPU-based solutions thus far.},
	language = {en},
	number = {11},
	urldate = {2022-03-19},
	journal = {PLoS ONE},
	author = {Agulleiro, Jose-Ignacio and Fernández, José Jesús},
	editor = {Frischknecht, Friedrich},
	month = nov,
	year = {2012},
	pages = {e48261},
	file = {Agulleiro and Fernández - 2012 - Evaluation of a Multicore-Optimized Implementation.pdf:/home/david/Zotero/storage/V4U5C5EH/Agulleiro and Fernández - 2012 - Evaluation of a Multicore-Optimized Implementation.pdf:application/pdf},
}

@book{bebis_advances_2014-1,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Advances in {Visual} {Computing}: 10th {International} {Symposium}, {ISVC} 2014, {Las} {Vegas}, {NV}, {USA}, {December} 8-10, 2014, {Proceedings}, {Part} {I}},
	volume = {8887},
	isbn = {978-3-319-14248-7 978-3-319-14249-4},
	shorttitle = {Advances in {Visual} {Computing}},
	url = {http://link.springer.com/10.1007/978-3-319-14249-4},
	language = {en},
	urldate = {2022-03-19},
	publisher = {Springer International Publishing},
	editor = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and McMahan, Ryan and Jerald, Jason and Zhang, Hui and Drucker, Steven M. and Kambhamettu, Chandra and El Choubassi, Maha and Deng, Zhigang and Carlson, Mark},
	year = {2014},
	doi = {10.1007/978-3-319-14249-4},
	file = {Bebis et al. - 2014 - Advances in Visual Computing 10th International S.pdf:/home/david/Zotero/storage/Q49UGWSI/Bebis et al. - 2014 - Advances in Visual Computing 10th International S.pdf:application/pdf},
}
